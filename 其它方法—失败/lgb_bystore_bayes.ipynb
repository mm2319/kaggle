{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "## Multiprocess Runs\n",
    "def df_parallelize_run(func, t_split):\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def get_data_by_store(store):\n",
    "    \n",
    "    # Read and contact basic feature\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # Leave only relevant store\n",
    "    df = df[df['store_id']==store]\n",
    "\n",
    "    # With memory limits we have to read \n",
    "    # lags and mean encoding features\n",
    "    # separately and drop items that we don't need.\n",
    "    # As our Features Grids are aligned \n",
    "    # we can use index to keep only necessary rows\n",
    "    # Alignment is good for us as concat uses less memory than merge.\n",
    "    df2 = pd.read_pickle(MEAN_ENC)[mean_features]\n",
    "    df2 = df2[df2.index.isin(df.index)]\n",
    "    \n",
    "    df3 = pd.read_pickle(LAGS).iloc[:,3:]\n",
    "    df3 = df3[df3.index.isin(df.index)]\n",
    "    \n",
    "    df = pd.concat([df, df2], axis=1)\n",
    "    del df2 # to not reach memory limit \n",
    "    \n",
    "    df = pd.concat([df, df3], axis=1)\n",
    "    del df3 # to not reach memory limit \n",
    "    \n",
    "    # Create features list\n",
    "    features = [col for col in list(df) if col not in remove_features]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    # Skipping first n rows\n",
    "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    return df, features\n",
    "\n",
    "# Recombine Test set after training\n",
    "def get_base_test():\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n",
    "\n",
    "\n",
    "########################### Helper to make dynamic rolling lags\n",
    "#################################################################################\n",
    "def make_lag(LAG_DAY):\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'sales_lag_'+str(LAG_DAY)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "    return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "def make_lag_roll(LAG_DAY):\n",
    "    shift_day = LAG_DAY[0]\n",
    "    roll_wind = LAG_DAY[1]\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "    return lag_df[[col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.5,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2**11-1,\n",
    "                    'min_data_in_leaf': 2**12-1,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 1400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                } \n",
    "\n",
    "# Let's look closer on params\n",
    "\n",
    "## 'boosting_type': 'gbdt'\n",
    "# we have 'goss' option for faster training\n",
    "# but it normally leads to underfit.\n",
    "# Also there is good 'dart' mode\n",
    "# but it takes forever to train\n",
    "# and model performance depends \n",
    "# a lot on random factor \n",
    "# https://www.kaggle.com/c/home-credit-default-risk/discussion/60921\n",
    "\n",
    "## 'objective': 'tweedie'\n",
    "# Tweedie Gradient Boosting for Extremely\n",
    "# Unbalanced Zero-inflated Data\n",
    "# https://arxiv.org/pdf/1811.10192.pdf\n",
    "# and many more articles about tweediie\n",
    "#\n",
    "# Strange (for me) but Tweedie is close in results\n",
    "# to my own ugly loss.\n",
    "# My advice here - make OWN LOSS function\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/140564\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/143070\n",
    "# I think many of you already using it (after poisson kernel appeared) \n",
    "# (kagglers are very good with \"params\" testing and tuning).\n",
    "# Try to figure out why Tweedie works.\n",
    "# probably it will show you new features options\n",
    "# or data transformation (Target transformation?).\n",
    "\n",
    "## 'tweedie_variance_power': 1.1\n",
    "# default = 1.5\n",
    "# set this closer to 2 to shift towards a Gamma distribution\n",
    "# set this closer to 1 to shift towards a Poisson distribution\n",
    "# my CV shows 1.1 is optimal \n",
    "# but you can make your own choice\n",
    "\n",
    "## 'metric': 'rmse'\n",
    "# Doesn't mean anything to us\n",
    "# as competition metric is different\n",
    "# and we don't use early stoppings here.\n",
    "# So rmse serves just for general \n",
    "# model performance overview.\n",
    "# Also we use \"fake\" validation set\n",
    "# (as it makes part of the training set)\n",
    "# so even general rmse score doesn't mean anything))\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\n",
    "\n",
    "## 'subsample': 0.5\n",
    "# Serves to fight with overfit\n",
    "# this will randomly select part of data without resampling\n",
    "# Chosen by CV (my CV can be wrong!)\n",
    "# Next kernel will be about CV\n",
    "\n",
    "##'subsample_freq': 1\n",
    "# frequency for bagging\n",
    "# default value - seems ok\n",
    "\n",
    "## 'learning_rate': 0.03\n",
    "# Chosen by CV\n",
    "# Smaller - longer training\n",
    "# but there is an option to stop \n",
    "# in \"local minimum\"\n",
    "# Bigger - faster training\n",
    "# but there is a chance to\n",
    "# not find \"global minimum\" minimum\n",
    "\n",
    "## 'num_leaves': 2**11-1\n",
    "## 'min_data_in_leaf': 2**12-1\n",
    "# Force model to use more features\n",
    "# We need it to reduce \"recursive\"\n",
    "# error impact.\n",
    "# Also it leads to overfit\n",
    "# that's why we use small \n",
    "\n",
    "# 'max_bin': 100\n",
    "## l1, l2 regularizations\n",
    "# https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    "# Good tiny explanation\n",
    "# l2 can work with bigger num_leaves\n",
    "# but my CV doesn't show boost\n",
    "                    \n",
    "## 'n_estimators': 1400\n",
    "# CV shows that there should be\n",
    "# different values for each state/store.\n",
    "# Current value was chosen \n",
    "# for general purpose.\n",
    "# As we don't use any early stopings\n",
    "# careful to not overfit Public LB.\n",
    "\n",
    "##'feature_fraction': 0.5\n",
    "# LightGBM will randomly select \n",
    "# part of features on each iteration (tree).\n",
    "# We have maaaany features\n",
    "# and many of them are \"duplicates\"\n",
    "# and many just \"noise\"\n",
    "# good values here - 0.5-0.7 (by CV)\n",
    "\n",
    "## 'boost_from_average': False\n",
    "# There is some \"problem\"\n",
    "# to code boost_from_average for \n",
    "# custom loss\n",
    "# 'True' makes training faster\n",
    "# BUT carefull use it\n",
    "# https://github.com/microsoft/LightGBM/issues/1514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 1                          # Our model version\n",
    "SEED = 42                        # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "lgb_params['seed'] = SEED        # as possible\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "#LIMITS and const\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913               # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "USE_AUX     = True               # Use or not pretrained models\n",
    "\n",
    "#FEATURES to remove\n",
    "## These features lead to overfit\n",
    "## or values not present in test set\n",
    "remove_features = ['id','state_id','store_id',\n",
    "                   'date','wm_yr_wk','d',TARGET]\n",
    "mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                   'enc_dept_id_mean','enc_dept_id_std',\n",
    "                   'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "#PATHS for Features\n",
    "BASE     = 'grid_part_1.pkl'\n",
    "PRICE    = 'grid_part_2.pkl'\n",
    "CALENDAR = 'grid_part_3.pkl'\n",
    "LAGS     = 'lags_df_28.pkl'\n",
    "MEAN_ENC = 'mean_encoding_df.pkl'\n",
    "\n",
    "\n",
    "# AUX(pretrained) Models paths\n",
    "\n",
    "#STORES ids\n",
    "STORES_IDS = pd.read_csv('sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "\n",
    "\n",
    "#SPLITS for lags creation\n",
    "SHIFT_DAY  = 28\n",
    "N_LAGS     = 15\n",
    "LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n",
    "ROLS_SPLIT = []\n",
    "for i in [1,7,14]:\n",
    "    for j in [7,14,30,60]:\n",
    "        ROLS_SPLIT.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_CA_1_validation  1814    0.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_CA_1_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_CA_1_validation  1814    0.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_CA_1_validation  1814    3.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_CA_1_validation  1814    0.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      224    8.257812   9.578125   8.257812  ...        0.714355   \n",
      "1  HOBBIES       20    3.970703   3.970703   3.970703  ...        1.428711   \n",
      "2  HOBBIES      300    2.970703   2.970703   2.970703  ...        1.857422   \n",
      "3  HOBBIES        5    4.640625   4.640625   4.339844  ...        1.713867   \n",
      "4  HOBBIES       16    2.880859   3.080078   2.480469  ...        2.572266   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       1.112305         0.643066        0.928711         0.600098   \n",
      "1       1.717773         1.071289        1.328125         0.700195   \n",
      "2       1.573242         1.928711        1.439453         1.533203   \n",
      "3       0.951172         1.286133        0.994629         1.866211   \n",
      "4       1.618164         1.928711        1.384766         1.400391   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.813477         0.549805        0.768555         0.638672   \n",
      "1        1.149414         0.583496        0.907227         0.449951   \n",
      "2        1.332031         0.950195        1.212891         0.622070   \n",
      "3        1.305664         1.750000        1.445312         1.849609   \n",
      "4        1.354492         1.400391        1.209961         1.294922   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.823730  \n",
      "1        0.792969  \n",
      "2        0.934570  \n",
      "3        2.130859  \n",
      "4        1.199219  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390239  FOODS_3_823_CA_1_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390240  FOODS_3_824_CA_1_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390241  FOODS_3_825_CA_1_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390242  FOODS_3_826_CA_1_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390243  FOODS_3_827_CA_1_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390239      127    2.980469   2.980469   2.480469  ...        1.286133   \n",
      "390240        0    2.480469   2.679688   2.470703  ...        0.856934   \n",
      "390241        1    3.980469   4.378906   3.980469  ...        1.142578   \n",
      "390242      211    1.280273   1.280273   1.280273  ...        1.000000   \n",
      "390243      403    1.000000   1.000000   1.000000  ...        7.000000   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390239       1.379883         1.571289        1.504883         0.733398   \n",
      "390240       0.899902         0.571289        0.755859         0.799805   \n",
      "390241       1.069336         1.286133        0.994629         1.133789   \n",
      "390242       1.291016         0.928711        1.328125         0.933105   \n",
      "390243       7.593750         7.214844        6.316406         5.535156   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390239        1.285156         0.683105        1.242188         1.555664   \n",
      "390240        1.562500         0.399902        1.166992         0.133301   \n",
      "390241        0.899414         1.099609        0.986328         0.850098   \n",
      "390242        1.412109         1.183594        1.396484         1.016602   \n",
      "390243        5.000000         4.816406        4.242188         4.035156   \n",
      "\n",
      "       rolling_std_180  \n",
      "390239        1.825195  \n",
      "390240        0.696289  \n",
      "390241        1.075195  \n",
      "390242        1.404297  \n",
      "390243        3.894531  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390244 entries, 0 to 390243\n",
      "Data columns (total 63 columns):\n",
      "id                  390244 non-null category\n",
      "d                   390244 non-null int16\n",
      "sales               304872 non-null float64\n",
      "item_id             390244 non-null category\n",
      "dept_id             390244 non-null category\n",
      "cat_id              390244 non-null category\n",
      "release             390244 non-null int16\n",
      "sell_price          390244 non-null float16\n",
      "price_max           390244 non-null float16\n",
      "price_min           390244 non-null float16\n",
      "price_std           390244 non-null float16\n",
      "price_mean          390244 non-null float16\n",
      "price_norm          390244 non-null float16\n",
      "price_nunique       390244 non-null float16\n",
      "item_nunique        390244 non-null int16\n",
      "price_momentum      390230 non-null float16\n",
      "price_momentum_m    390244 non-null float16\n",
      "price_momentum_y    390244 non-null float16\n",
      "event_name_1        39634 non-null category\n",
      "event_type_1        39634 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390244 non-null category\n",
      "snap_TX             390244 non-null category\n",
      "snap_WI             390244 non-null category\n",
      "tm_d                390244 non-null int8\n",
      "tm_w                390244 non-null int8\n",
      "tm_m                390244 non-null int8\n",
      "tm_y                390244 non-null int8\n",
      "tm_wm               390244 non-null int8\n",
      "tm_dw               390244 non-null int8\n",
      "tm_w_end            390244 non-null int8\n",
      "enc_cat_id_mean     390244 non-null float16\n",
      "enc_cat_id_std      390244 non-null float16\n",
      "enc_dept_id_mean    390244 non-null float16\n",
      "enc_dept_id_std     390244 non-null float16\n",
      "enc_item_id_mean    390244 non-null float16\n",
      "enc_item_id_std     390244 non-null float16\n",
      "sales_lag_28        390174 non-null float16\n",
      "sales_lag_29        390170 non-null float16\n",
      "sales_lag_30        390166 non-null float16\n",
      "sales_lag_31        390162 non-null float16\n",
      "sales_lag_32        390158 non-null float16\n",
      "sales_lag_33        390154 non-null float16\n",
      "sales_lag_34        390150 non-null float16\n",
      "sales_lag_35        390146 non-null float16\n",
      "sales_lag_36        390142 non-null float16\n",
      "sales_lag_37        390138 non-null float16\n",
      "sales_lag_38        390134 non-null float16\n",
      "sales_lag_39        390130 non-null float16\n",
      "sales_lag_40        390126 non-null float16\n",
      "sales_lag_41        390122 non-null float16\n",
      "sales_lag_42        390118 non-null float16\n",
      "rolling_mean_7      390150 non-null float16\n",
      "rolling_std_7       390150 non-null float16\n",
      "rolling_mean_14     390122 non-null float16\n",
      "rolling_std_14      390122 non-null float16\n",
      "rolling_mean_30     390058 non-null float16\n",
      "rolling_std_30      390058 non-null float16\n",
      "rolling_mean_60     389935 non-null float16\n",
      "rolling_std_60      389935 non-null float16\n",
      "rolling_mean_180    389344 non-null float16\n",
      "rolling_std_180     389344 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 2.02701\n",
      "[200]\tvalid_0's rmse: 2.00602\n",
      "[300]\tvalid_0's rmse: 1.99579\n",
      "[400]\tvalid_0's rmse: 1.98764\n",
      "[500]\tvalid_0's rmse: 1.98111\n",
      "[600]\tvalid_0's rmse: 1.9761\n",
      "[700]\tvalid_0's rmse: 1.96916\n",
      "[800]\tvalid_0's rmse: 1.96337\n",
      "[900]\tvalid_0's rmse: 1.9583\n",
      "[1000]\tvalid_0's rmse: 1.95346\n",
      "[1100]\tvalid_0's rmse: 1.94911\n",
      "[1200]\tvalid_0's rmse: 1.94432\n",
      "[1300]\tvalid_0's rmse: 1.9406\n",
      "[1400]\tvalid_0's rmse: 1.93576\n",
      "Train CA_2\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_CA_2_validation  1814    2.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_CA_2_validation  1814    1.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_CA_2_validation  1814    3.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_CA_2_validation  1814    4.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_CA_2_validation  1814    4.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      226    8.257812   8.382812   8.257812  ...        0.571289   \n",
      "1  HOBBIES        5    3.970703   3.970703   3.970703  ...        0.285645   \n",
      "2  HOBBIES      300    2.970703   2.970703   2.970703  ...        0.714355   \n",
      "3  HOBBIES        0    4.640625   4.640625   4.339844  ...        4.714844   \n",
      "4  HOBBIES       14    2.880859   3.080078   2.480469  ...        1.571289   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.786621         0.571289        0.755859         0.733398   \n",
      "1       0.755859         0.357178        0.745117         0.166626   \n",
      "2       1.496094         0.785645        1.250977         0.500000   \n",
      "3       4.500000         4.429688        4.703125         3.767578   \n",
      "4       1.397461         1.142578        1.231445         1.599609   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.980469         0.733398        0.989258         0.644531   \n",
      "1        0.530762         0.116638        0.415527         0.172241   \n",
      "2        0.973633         0.333252        0.751465         0.188843   \n",
      "3        3.654297         3.449219        3.191406         3.388672   \n",
      "4        1.567383         1.349609        1.350586         1.483398   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.931152  \n",
      "1        0.433594  \n",
      "2        0.526367  \n",
      "3        2.871094  \n",
      "4        1.375977  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390211  FOODS_3_823_CA_2_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390212  FOODS_3_824_CA_2_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390213  FOODS_3_825_CA_2_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390214  FOODS_3_826_CA_2_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390215  FOODS_3_827_CA_2_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390211       13    2.980469   2.980469   2.480469  ...        2.000000   \n",
      "390212        0    2.480469   2.679688   2.470703  ...        1.142578   \n",
      "390213        0    3.980469   4.378906   3.980469  ...        1.713867   \n",
      "390214      209    1.280273   1.280273   1.280273  ...        1.571289   \n",
      "390215      338    1.000000   1.000000   1.000000  ...        3.142578   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390211       1.154297         2.072266        1.328125         0.966797   \n",
      "390212       1.069336         1.000000        1.038086         0.799805   \n",
      "390213       2.289062         1.286133        1.815430         1.000000   \n",
      "390214       1.133789         1.428711        1.158203         1.033203   \n",
      "390215       2.478516         2.785156        2.224609         3.433594   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390211        1.376953         0.950195        1.455078         2.277344   \n",
      "390212        1.095703         0.399902        0.867676         0.133301   \n",
      "390213        1.414062         0.500000        1.112305         0.300049   \n",
      "390214        1.033203         1.016602        0.982910         0.794434   \n",
      "390215        3.673828         3.750000        4.449219         3.138672   \n",
      "\n",
      "       rolling_std_180  \n",
      "390211        2.457031  \n",
      "390212        0.532715  \n",
      "390213        0.824707  \n",
      "390214        1.055664  \n",
      "390215        4.269531  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390216 entries, 0 to 390215\n",
      "Data columns (total 63 columns):\n",
      "id                  390216 non-null category\n",
      "d                   390216 non-null int16\n",
      "sales               304844 non-null float64\n",
      "item_id             390216 non-null category\n",
      "dept_id             390216 non-null category\n",
      "cat_id              390216 non-null category\n",
      "release             390216 non-null int16\n",
      "sell_price          390216 non-null float16\n",
      "price_max           390216 non-null float16\n",
      "price_min           390216 non-null float16\n",
      "price_std           390216 non-null float16\n",
      "price_mean          390216 non-null float16\n",
      "price_norm          390216 non-null float16\n",
      "price_nunique       390216 non-null float16\n",
      "item_nunique        390216 non-null int16\n",
      "price_momentum      390195 non-null float16\n",
      "price_momentum_m    390216 non-null float16\n",
      "price_momentum_y    390216 non-null float16\n",
      "event_name_1        39631 non-null category\n",
      "event_type_1        39631 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390216 non-null category\n",
      "snap_TX             390216 non-null category\n",
      "snap_WI             390216 non-null category\n",
      "tm_d                390216 non-null int8\n",
      "tm_w                390216 non-null int8\n",
      "tm_m                390216 non-null int8\n",
      "tm_y                390216 non-null int8\n",
      "tm_wm               390216 non-null int8\n",
      "tm_dw               390216 non-null int8\n",
      "tm_w_end            390216 non-null int8\n",
      "enc_cat_id_mean     390216 non-null float16\n",
      "enc_cat_id_std      390216 non-null float16\n",
      "enc_dept_id_mean    390216 non-null float16\n",
      "enc_dept_id_std     390216 non-null float16\n",
      "enc_item_id_mean    390216 non-null float16\n",
      "enc_item_id_std     390216 non-null float16\n",
      "sales_lag_28        390111 non-null float16\n",
      "sales_lag_29        390105 non-null float16\n",
      "sales_lag_30        390099 non-null float16\n",
      "sales_lag_31        390093 non-null float16\n",
      "sales_lag_32        390087 non-null float16\n",
      "sales_lag_33        390081 non-null float16\n",
      "sales_lag_34        390075 non-null float16\n",
      "sales_lag_35        390069 non-null float16\n",
      "sales_lag_36        390063 non-null float16\n",
      "sales_lag_37        390057 non-null float16\n",
      "sales_lag_38        390051 non-null float16\n",
      "sales_lag_39        390045 non-null float16\n",
      "sales_lag_40        390039 non-null float16\n",
      "sales_lag_41        390033 non-null float16\n",
      "sales_lag_42        390027 non-null float16\n",
      "rolling_mean_7      390075 non-null float16\n",
      "rolling_std_7       390075 non-null float16\n",
      "rolling_mean_14     390033 non-null float16\n",
      "rolling_std_14      390033 non-null float16\n",
      "rolling_mean_30     389937 non-null float16\n",
      "rolling_std_30      389937 non-null float16\n",
      "rolling_mean_60     389613 non-null float16\n",
      "rolling_std_60      389613 non-null float16\n",
      "rolling_mean_180    385950 non-null float16\n",
      "rolling_std_180     385950 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 1.89284\n",
      "[200]\tvalid_0's rmse: 1.85131\n",
      "[300]\tvalid_0's rmse: 1.83969\n",
      "[400]\tvalid_0's rmse: 1.83187\n",
      "[500]\tvalid_0's rmse: 1.82598\n",
      "[600]\tvalid_0's rmse: 1.82106\n",
      "[700]\tvalid_0's rmse: 1.8151\n",
      "[800]\tvalid_0's rmse: 1.8101\n",
      "[900]\tvalid_0's rmse: 1.80468\n",
      "[1000]\tvalid_0's rmse: 1.80055\n",
      "[1100]\tvalid_0's rmse: 1.79617\n",
      "[1200]\tvalid_0's rmse: 1.79187\n",
      "[1300]\tvalid_0's rmse: 1.78823\n",
      "[1400]\tvalid_0's rmse: 1.78449\n",
      "Train CA_3\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_CA_3_validation  1814    0.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_CA_3_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_CA_3_validation  1814    2.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_CA_3_validation  1814    9.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_CA_3_validation  1814    1.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      225    8.257812   8.382812   8.257812  ...        0.856934   \n",
      "1  HOBBIES        6    3.970703   3.970703   2.000000  ...        0.142822   \n",
      "2  HOBBIES      347    2.970703   2.970703   2.970703  ...        0.571289   \n",
      "3  HOBBIES        1    4.640625   4.640625   4.339844  ...        5.855469   \n",
      "4  HOBBIES       13    2.880859   3.080078   2.480469  ...        1.286133   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.377930         0.785645        0.801758         0.966797   \n",
      "1       0.377930         0.214233        0.425781         0.133301   \n",
      "2       0.786621         0.357178        0.633301         0.466553   \n",
      "3       3.804688         5.214844        3.445312         5.566406   \n",
      "4       1.253906         1.286133        1.138672         1.700195   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        1.376953         0.933105        1.162109         0.833496   \n",
      "1        0.345703         0.083313        0.278809         0.216675   \n",
      "2        0.819336         0.416748        0.695801         0.350098   \n",
      "3        3.529297         6.000000        3.230469         6.183594   \n",
      "4        1.087891         1.750000        1.001953         1.722656   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        1.048828  \n",
      "1        0.498779  \n",
      "2        0.646973  \n",
      "3        3.183594  \n",
      "4        1.358398  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390197  FOODS_3_823_CA_3_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390198  FOODS_3_824_CA_3_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390199  FOODS_3_825_CA_3_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390200  FOODS_3_826_CA_3_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390201  FOODS_3_827_CA_3_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390197        0    2.980469   2.980469   2.480469  ...        2.285156   \n",
      "390198        0    2.480469   2.679688   2.000000  ...        1.000000   \n",
      "390199        2    3.980469   4.378906   2.000000  ...        2.572266   \n",
      "390200      211    1.280273   1.280273   1.280273  ...        1.286133   \n",
      "390201      308    1.000000   1.000000   1.000000  ...        5.429688   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390197       1.379883         2.714844        1.637695         1.266602   \n",
      "390198       1.414062         0.856934        1.231445         0.700195   \n",
      "390199       2.070312         2.214844        1.761719         2.566406   \n",
      "390200       1.253906         1.786133        1.717773         1.799805   \n",
      "390201       4.238281         5.500000        3.525391         5.234375   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390197        1.760742         2.849609        3.337891         2.482422   \n",
      "390198        0.987793         0.350098        0.777344         0.166626   \n",
      "390199        1.568359         2.183594        1.909180         2.033203   \n",
      "390200        1.583984         2.000000        1.377930         1.605469   \n",
      "390201        3.339844         9.351562        8.046875         7.332031   \n",
      "\n",
      "       rolling_std_180  \n",
      "390197        3.199219  \n",
      "390198        0.512207  \n",
      "390199        1.833984  \n",
      "390200        1.541016  \n",
      "390201        8.750000  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390202 entries, 0 to 390201\n",
      "Data columns (total 63 columns):\n",
      "id                  390202 non-null category\n",
      "d                   390202 non-null int16\n",
      "sales               304830 non-null float64\n",
      "item_id             390202 non-null category\n",
      "dept_id             390202 non-null category\n",
      "cat_id              390202 non-null category\n",
      "release             390202 non-null int16\n",
      "sell_price          390202 non-null float16\n",
      "price_max           390202 non-null float16\n",
      "price_min           390202 non-null float16\n",
      "price_std           390202 non-null float16\n",
      "price_mean          390202 non-null float16\n",
      "price_norm          390202 non-null float16\n",
      "price_nunique       390202 non-null float16\n",
      "item_nunique        390202 non-null int16\n",
      "price_momentum      390181 non-null float16\n",
      "price_momentum_m    390202 non-null float16\n",
      "price_momentum_y    390202 non-null float16\n",
      "event_name_1        39630 non-null category\n",
      "event_type_1        39630 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390202 non-null category\n",
      "snap_TX             390202 non-null category\n",
      "snap_WI             390202 non-null category\n",
      "tm_d                390202 non-null int8\n",
      "tm_w                390202 non-null int8\n",
      "tm_m                390202 non-null int8\n",
      "tm_y                390202 non-null int8\n",
      "tm_wm               390202 non-null int8\n",
      "tm_dw               390202 non-null int8\n",
      "tm_w_end            390202 non-null int8\n",
      "enc_cat_id_mean     390202 non-null float16\n",
      "enc_cat_id_std      390202 non-null float16\n",
      "enc_dept_id_mean    390202 non-null float16\n",
      "enc_dept_id_std     390202 non-null float16\n",
      "enc_item_id_mean    390202 non-null float16\n",
      "enc_item_id_std     390202 non-null float16\n",
      "sales_lag_28        390111 non-null float16\n",
      "sales_lag_29        390107 non-null float16\n",
      "sales_lag_30        390103 non-null float16\n",
      "sales_lag_31        390099 non-null float16\n",
      "sales_lag_32        390095 non-null float16\n",
      "sales_lag_33        390091 non-null float16\n",
      "sales_lag_34        390087 non-null float16\n",
      "sales_lag_35        390083 non-null float16\n",
      "sales_lag_36        390079 non-null float16\n",
      "sales_lag_37        390075 non-null float16\n",
      "sales_lag_38        390071 non-null float16\n",
      "sales_lag_39        390067 non-null float16\n",
      "sales_lag_40        390063 non-null float16\n",
      "sales_lag_41        390059 non-null float16\n",
      "sales_lag_42        390055 non-null float16\n",
      "rolling_mean_7      390087 non-null float16\n",
      "rolling_std_7       390087 non-null float16\n",
      "rolling_mean_14     390059 non-null float16\n",
      "rolling_std_14      390059 non-null float16\n",
      "rolling_mean_30     389995 non-null float16\n",
      "rolling_std_30      389995 non-null float16\n",
      "rolling_mean_60     389875 non-null float16\n",
      "rolling_std_60      389875 non-null float16\n",
      "rolling_mean_180    389277 non-null float16\n",
      "rolling_std_180     389277 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.5055\n",
      "[200]\tvalid_0's rmse: 2.46208\n",
      "[300]\tvalid_0's rmse: 2.43993\n",
      "[400]\tvalid_0's rmse: 2.42454\n",
      "[500]\tvalid_0's rmse: 2.41549\n",
      "[600]\tvalid_0's rmse: 2.40771\n",
      "[700]\tvalid_0's rmse: 2.40195\n",
      "[800]\tvalid_0's rmse: 2.39547\n",
      "[900]\tvalid_0's rmse: 2.38985\n",
      "[1000]\tvalid_0's rmse: 2.38472\n",
      "[1100]\tvalid_0's rmse: 2.38037\n",
      "[1200]\tvalid_0's rmse: 2.37576\n",
      "[1300]\tvalid_0's rmse: 2.37126\n",
      "[1400]\tvalid_0's rmse: 2.36679\n",
      "Train CA_4\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_CA_4_validation  1814    1.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_CA_4_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_CA_4_validation  1814    0.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_CA_4_validation  1814    0.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_CA_4_validation  1814    0.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      224    8.257812   9.578125   8.257812  ...        0.714355   \n",
      "1  HOBBIES       23    3.970703   3.970703   3.970703  ...        0.000000   \n",
      "2  HOBBIES      301    2.970703   2.970703   2.970703  ...        1.142578   \n",
      "3  HOBBIES        0    4.640625   4.640625   4.339844  ...        0.285645   \n",
      "4  HOBBIES       15    2.880859   2.980469   2.480469  ...        1.286133   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.755859         0.856934        0.864258         0.700195   \n",
      "1       0.000000         0.214233        0.579102         0.266602   \n",
      "2       1.069336         0.856934        1.099609         0.433350   \n",
      "3       0.488037         0.285645        0.468750         0.133301   \n",
      "4       0.951172         1.500000        1.224609         1.599609   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.749512         0.783203        0.903809         0.733398   \n",
      "1        0.583496         0.216675        0.490234         0.199951   \n",
      "2        0.858398         0.350098        0.708984         0.266602   \n",
      "3        0.345703         0.233276        0.592773         0.366699   \n",
      "4        1.101562         1.783203        1.451172         1.727539   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.942871  \n",
      "1        0.465576  \n",
      "2        0.575195  \n",
      "3        0.746582  \n",
      "4        1.452148  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390225  FOODS_3_823_CA_4_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390226  FOODS_3_824_CA_4_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390227  FOODS_3_825_CA_4_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390228  FOODS_3_826_CA_4_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390229  FOODS_3_827_CA_4_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390225        0    2.980469   2.980469   2.480469  ...        1.428711   \n",
      "390226        0    2.480469   2.679688   2.470703  ...        0.571289   \n",
      "390227        0    3.980469   4.378906   3.939453  ...        1.142578   \n",
      "390228      212    1.280273   1.280273   1.280273  ...        3.142578   \n",
      "390229      320    1.000000   1.000000   1.000000  ...        3.142578   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390225       1.272461         1.428711        1.089844         0.666504   \n",
      "390226       0.786621         0.571289        0.755859         0.333252   \n",
      "390227       1.069336         0.714355        0.994629         0.566895   \n",
      "390228       2.544922         2.500000        2.066406         2.333984   \n",
      "390229       2.794922         1.571289        2.501953         1.966797   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390225        1.028320         0.700195        1.045898         0.549805   \n",
      "390226        0.606445         0.166626        0.457275         0.055542   \n",
      "390227        0.817383         0.600098        0.847656         0.588867   \n",
      "390228        2.056641         2.199219        2.023438         1.750000   \n",
      "390229        3.316406         1.366211        2.556641         0.500000   \n",
      "\n",
      "       rolling_std_180  \n",
      "390225        1.058594  \n",
      "390226        0.274170  \n",
      "390227        0.782227  \n",
      "390228        1.723633  \n",
      "390229        1.622070  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390230 entries, 0 to 390229\n",
      "Data columns (total 63 columns):\n",
      "id                  390230 non-null category\n",
      "d                   390230 non-null int16\n",
      "sales               304858 non-null float64\n",
      "item_id             390230 non-null category\n",
      "dept_id             390230 non-null category\n",
      "cat_id              390230 non-null category\n",
      "release             390230 non-null int16\n",
      "sell_price          390230 non-null float16\n",
      "price_max           390230 non-null float16\n",
      "price_min           390230 non-null float16\n",
      "price_std           390230 non-null float16\n",
      "price_mean          390230 non-null float16\n",
      "price_norm          390230 non-null float16\n",
      "price_nunique       390230 non-null float16\n",
      "item_nunique        390230 non-null int16\n",
      "price_momentum      390216 non-null float16\n",
      "price_momentum_m    390230 non-null float16\n",
      "price_momentum_y    390230 non-null float16\n",
      "event_name_1        39633 non-null category\n",
      "event_type_1        39633 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390230 non-null category\n",
      "snap_TX             390230 non-null category\n",
      "snap_WI             390230 non-null category\n",
      "tm_d                390230 non-null int8\n",
      "tm_w                390230 non-null int8\n",
      "tm_m                390230 non-null int8\n",
      "tm_y                390230 non-null int8\n",
      "tm_wm               390230 non-null int8\n",
      "tm_dw               390230 non-null int8\n",
      "tm_w_end            390230 non-null int8\n",
      "enc_cat_id_mean     390230 non-null float16\n",
      "enc_cat_id_std      390230 non-null float16\n",
      "enc_dept_id_mean    390230 non-null float16\n",
      "enc_dept_id_std     390230 non-null float16\n",
      "enc_item_id_mean    390230 non-null float16\n",
      "enc_item_id_std     390230 non-null float16\n",
      "sales_lag_28        390139 non-null float16\n",
      "sales_lag_29        390134 non-null float16\n",
      "sales_lag_30        390129 non-null float16\n",
      "sales_lag_31        390124 non-null float16\n",
      "sales_lag_32        390119 non-null float16\n",
      "sales_lag_33        390114 non-null float16\n",
      "sales_lag_34        390109 non-null float16\n",
      "sales_lag_35        390104 non-null float16\n",
      "sales_lag_36        390099 non-null float16\n",
      "sales_lag_37        390094 non-null float16\n",
      "sales_lag_38        390089 non-null float16\n",
      "sales_lag_39        390084 non-null float16\n",
      "sales_lag_40        390079 non-null float16\n",
      "sales_lag_41        390074 non-null float16\n",
      "sales_lag_42        390069 non-null float16\n",
      "rolling_mean_7      390109 non-null float16\n",
      "rolling_std_7       390109 non-null float16\n",
      "rolling_mean_14     390074 non-null float16\n",
      "rolling_std_14      390074 non-null float16\n",
      "rolling_mean_30     389986 non-null float16\n",
      "rolling_std_30      389986 non-null float16\n",
      "rolling_mean_60     389790 non-null float16\n",
      "rolling_std_60      389790 non-null float16\n",
      "rolling_mean_180    388156 non-null float16\n",
      "rolling_std_180     388156 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 1.3326\n",
      "[200]\tvalid_0's rmse: 1.32555\n",
      "[300]\tvalid_0's rmse: 1.32091\n",
      "[400]\tvalid_0's rmse: 1.31693\n",
      "[500]\tvalid_0's rmse: 1.3135\n",
      "[600]\tvalid_0's rmse: 1.31045\n",
      "[700]\tvalid_0's rmse: 1.30736\n",
      "[800]\tvalid_0's rmse: 1.30489\n",
      "[900]\tvalid_0's rmse: 1.30197\n",
      "[1000]\tvalid_0's rmse: 1.29876\n",
      "[1100]\tvalid_0's rmse: 1.29612\n",
      "[1200]\tvalid_0's rmse: 1.29381\n",
      "[1300]\tvalid_0's rmse: 1.29141\n",
      "[1400]\tvalid_0's rmse: 1.28865\n",
      "Train TX_1\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_TX_1_validation  1814    0.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_TX_1_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_TX_1_validation  1814    0.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_TX_1_validation  1814    0.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_TX_1_validation  1814    0.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      224    8.257812   9.578125   5.000000  ...        0.285645   \n",
      "1  HOBBIES        5    3.970703   3.970703   2.970703  ...        0.142822   \n",
      "2  HOBBIES      302    2.970703   2.970703   2.970703  ...        0.142822   \n",
      "3  HOBBIES        0    4.640625   4.640625   4.339844  ...        0.856934   \n",
      "4  HOBBIES       14    2.730469   2.730469   2.480469  ...        0.285645   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.488037         0.214233        0.425781         0.266602   \n",
      "1       0.377930         0.142822        0.363037         0.166626   \n",
      "2       0.377930         0.071411        0.267334         0.199951   \n",
      "3       0.899902         0.928711        0.997070         1.099609   \n",
      "4       0.488037         0.357178        0.497314         0.333252   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.520996         0.233276        0.499756         0.222168   \n",
      "1        0.379150         0.099976        0.302490         0.066650   \n",
      "2        0.484131         0.300049        0.809082         0.222168   \n",
      "3        1.268555         1.049805        1.095703         1.105469   \n",
      "4        0.606445         0.583496        0.787598         0.477783   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.467529  \n",
      "1        0.250244  \n",
      "2        0.584473  \n",
      "3        1.235352  \n",
      "4        0.743164  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390267  FOODS_3_823_TX_1_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390268  FOODS_3_824_TX_1_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390269  FOODS_3_825_TX_1_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390270  FOODS_3_826_TX_1_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390271  FOODS_3_827_TX_1_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390267        0    2.980469   2.980469   0.990234  ...        0.142822   \n",
      "390268        0    2.480469   2.480469   2.179688  ...        0.142822   \n",
      "390269        0    3.980469   4.378906   1.990234  ...        0.285645   \n",
      "390270      211    1.280273   1.280273   1.000000  ...        0.571289   \n",
      "390271      306    1.000000   1.000000   1.000000  ...        0.714355   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390267       0.377930         0.214233        0.425781         0.099976   \n",
      "390268       0.377930         0.071411        0.267334         0.066650   \n",
      "390269       0.488037         0.357178        0.497314         0.399902   \n",
      "390270       0.534668         0.428467        0.645996         0.600098   \n",
      "390271       0.755859         1.786133        2.806641         1.700195   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390267        0.305176         0.216675        0.490234         0.933105   \n",
      "390268        0.253662         0.033325        0.181030         0.011108   \n",
      "390269        0.674805         0.466553        0.724121         0.350098   \n",
      "390270        0.894531         0.649902        0.777344         0.733398   \n",
      "390271        2.451172         1.233398        2.019531         0.661133   \n",
      "\n",
      "       rolling_std_180  \n",
      "390267        1.507812  \n",
      "390268        0.105103  \n",
      "390269        0.638184  \n",
      "390270        0.829590  \n",
      "390271        1.553711  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390272 entries, 0 to 390271\n",
      "Data columns (total 63 columns):\n",
      "id                  390272 non-null category\n",
      "d                   390272 non-null int16\n",
      "sales               304900 non-null float64\n",
      "item_id             390272 non-null category\n",
      "dept_id             390272 non-null category\n",
      "cat_id              390272 non-null category\n",
      "release             390272 non-null int16\n",
      "sell_price          390272 non-null float16\n",
      "price_max           390272 non-null float16\n",
      "price_min           390272 non-null float16\n",
      "price_std           390272 non-null float16\n",
      "price_mean          390272 non-null float16\n",
      "price_norm          390272 non-null float16\n",
      "price_nunique       390272 non-null float16\n",
      "item_nunique        390272 non-null int16\n",
      "price_momentum      390272 non-null float16\n",
      "price_momentum_m    390272 non-null float16\n",
      "price_momentum_y    390272 non-null float16\n",
      "event_name_1        39637 non-null category\n",
      "event_type_1        39637 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390272 non-null category\n",
      "snap_TX             390272 non-null category\n",
      "snap_WI             390272 non-null category\n",
      "tm_d                390272 non-null int8\n",
      "tm_w                390272 non-null int8\n",
      "tm_m                390272 non-null int8\n",
      "tm_y                390272 non-null int8\n",
      "tm_wm               390272 non-null int8\n",
      "tm_dw               390272 non-null int8\n",
      "tm_w_end            390272 non-null int8\n",
      "enc_cat_id_mean     390272 non-null float16\n",
      "enc_cat_id_std      390272 non-null float16\n",
      "enc_dept_id_mean    390272 non-null float16\n",
      "enc_dept_id_std     390272 non-null float16\n",
      "enc_item_id_mean    390272 non-null float16\n",
      "enc_item_id_std     390272 non-null float16\n",
      "sales_lag_28        390272 non-null float16\n",
      "sales_lag_29        390272 non-null float16\n",
      "sales_lag_30        390272 non-null float16\n",
      "sales_lag_31        390272 non-null float16\n",
      "sales_lag_32        390272 non-null float16\n",
      "sales_lag_33        390272 non-null float16\n",
      "sales_lag_34        390272 non-null float16\n",
      "sales_lag_35        390272 non-null float16\n",
      "sales_lag_36        390272 non-null float16\n",
      "sales_lag_37        390272 non-null float16\n",
      "sales_lag_38        390272 non-null float16\n",
      "sales_lag_39        390272 non-null float16\n",
      "sales_lag_40        390272 non-null float16\n",
      "sales_lag_41        390272 non-null float16\n",
      "sales_lag_42        390272 non-null float16\n",
      "rolling_mean_7      390272 non-null float16\n",
      "rolling_std_7       390272 non-null float16\n",
      "rolling_mean_14     390272 non-null float16\n",
      "rolling_std_14      390272 non-null float16\n",
      "rolling_mean_30     390257 non-null float16\n",
      "rolling_std_30      390257 non-null float16\n",
      "rolling_mean_60     390224 non-null float16\n",
      "rolling_std_60      390224 non-null float16\n",
      "rolling_mean_180    389661 non-null float16\n",
      "rolling_std_180     389661 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 1.60744\n",
      "[200]\tvalid_0's rmse: 1.58621\n",
      "[300]\tvalid_0's rmse: 1.57862\n",
      "[400]\tvalid_0's rmse: 1.57259\n",
      "[500]\tvalid_0's rmse: 1.56766\n",
      "[600]\tvalid_0's rmse: 1.56345\n",
      "[700]\tvalid_0's rmse: 1.55996\n",
      "[800]\tvalid_0's rmse: 1.55622\n",
      "[900]\tvalid_0's rmse: 1.55296\n",
      "[1000]\tvalid_0's rmse: 1.54973\n",
      "[1100]\tvalid_0's rmse: 1.54611\n",
      "[1200]\tvalid_0's rmse: 1.54261\n",
      "[1300]\tvalid_0's rmse: 1.53934\n",
      "[1400]\tvalid_0's rmse: 1.5354\n",
      "Train TX_2\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_TX_2_validation  1814    0.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_TX_2_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_TX_2_validation  1814    2.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_TX_2_validation  1814    1.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_TX_2_validation  1814    0.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      226    8.257812   9.578125   8.257812  ...        0.571289   \n",
      "1  HOBBIES       20    3.970703   3.970703   3.970703  ...        0.571289   \n",
      "2  HOBBIES      301    2.970703   2.970703   2.970703  ...        0.142822   \n",
      "3  HOBBIES        0    4.640625   4.640625   4.339844  ...        0.000000   \n",
      "4  HOBBIES       13    2.730469   2.730469   2.480469  ...        1.000000   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.534668         0.714355        0.726074         0.500000   \n",
      "1       0.786621         0.357178        0.633301         0.300049   \n",
      "2       0.377930         0.214233        0.425781         0.166626   \n",
      "3       0.000000         0.000000        0.000000         0.000000   \n",
      "4       1.291016         1.286133        1.490234         1.299805   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.682129         0.649902    7.988281e-01         0.505371   \n",
      "1        0.535156         0.250000    5.083008e-01         0.199951   \n",
      "2        0.379150         0.116638    3.237305e-01         0.138916   \n",
      "3        0.000000         0.000000    1.788139e-07         0.033325   \n",
      "4        1.178711         1.083008    1.062500e+00         0.861328   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.697266  \n",
      "1        0.465576  \n",
      "2        0.377686  \n",
      "3        0.256836  \n",
      "4        0.984375  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390260  FOODS_3_823_TX_2_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390261  FOODS_3_824_TX_2_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390262  FOODS_3_825_TX_2_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390263  FOODS_3_826_TX_2_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390264  FOODS_3_827_TX_2_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390260        0    2.980469   2.980469   1.990234  ...        0.285645   \n",
      "390261        0    2.480469   2.480469   2.179688  ...        0.428467   \n",
      "390262        0    3.980469   4.378906   3.980469  ...        0.285645   \n",
      "390263      211    1.280273   1.280273   1.280273  ...        0.714355   \n",
      "390264      312    1.000000   1.000000   1.000000  ...        1.713867   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390260       0.488037         0.214233        0.425781         0.099976   \n",
      "390261       0.786621         0.643066        0.745117         0.566895   \n",
      "390262       0.488037         0.714355        0.825195         0.966797   \n",
      "390263       1.112305         1.142578        1.511719         1.099609   \n",
      "390264       4.535156         0.856934        3.207031         0.399902   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390260        0.305176         0.199951        0.514160         0.555664   \n",
      "390261        1.040039         0.283447        0.783203         0.094421   \n",
      "390262        0.999512         0.850098        1.117188         0.672363   \n",
      "390263        1.398438         1.016602        1.228516         1.099609   \n",
      "390264        2.191406         0.199951        1.548828         0.066650   \n",
      "\n",
      "       rolling_std_180  \n",
      "390260        0.904297  \n",
      "390261        0.469238  \n",
      "390262        0.979492  \n",
      "390263        1.273438  \n",
      "390264        0.894531  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390265 entries, 0 to 390264\n",
      "Data columns (total 63 columns):\n",
      "id                  390265 non-null category\n",
      "d                   390265 non-null int16\n",
      "sales               304893 non-null float64\n",
      "item_id             390265 non-null category\n",
      "dept_id             390265 non-null category\n",
      "cat_id              390265 non-null category\n",
      "release             390265 non-null int16\n",
      "sell_price          390265 non-null float16\n",
      "price_max           390265 non-null float16\n",
      "price_min           390265 non-null float16\n",
      "price_std           390265 non-null float16\n",
      "price_mean          390265 non-null float16\n",
      "price_norm          390265 non-null float16\n",
      "price_nunique       390265 non-null float16\n",
      "item_nunique        390265 non-null int16\n",
      "price_momentum      390258 non-null float16\n",
      "price_momentum_m    390265 non-null float16\n",
      "price_momentum_y    390265 non-null float16\n",
      "event_name_1        39636 non-null category\n",
      "event_type_1        39636 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390265 non-null category\n",
      "snap_TX             390265 non-null category\n",
      "snap_WI             390265 non-null category\n",
      "tm_d                390265 non-null int8\n",
      "tm_w                390265 non-null int8\n",
      "tm_m                390265 non-null int8\n",
      "tm_y                390265 non-null int8\n",
      "tm_wm               390265 non-null int8\n",
      "tm_dw               390265 non-null int8\n",
      "tm_w_end            390265 non-null int8\n",
      "enc_cat_id_mean     390265 non-null float16\n",
      "enc_cat_id_std      390265 non-null float16\n",
      "enc_dept_id_mean    390265 non-null float16\n",
      "enc_dept_id_std     390265 non-null float16\n",
      "enc_item_id_mean    390265 non-null float16\n",
      "enc_item_id_std     390265 non-null float16\n",
      "sales_lag_28        390237 non-null float16\n",
      "sales_lag_29        390236 non-null float16\n",
      "sales_lag_30        390235 non-null float16\n",
      "sales_lag_31        390234 non-null float16\n",
      "sales_lag_32        390233 non-null float16\n",
      "sales_lag_33        390232 non-null float16\n",
      "sales_lag_34        390231 non-null float16\n",
      "sales_lag_35        390230 non-null float16\n",
      "sales_lag_36        390229 non-null float16\n",
      "sales_lag_37        390228 non-null float16\n",
      "sales_lag_38        390227 non-null float16\n",
      "sales_lag_39        390226 non-null float16\n",
      "sales_lag_40        390225 non-null float16\n",
      "sales_lag_41        390224 non-null float16\n",
      "sales_lag_42        390223 non-null float16\n",
      "rolling_mean_7      390231 non-null float16\n",
      "rolling_std_7       390231 non-null float16\n",
      "rolling_mean_14     390224 non-null float16\n",
      "rolling_std_14      390224 non-null float16\n",
      "rolling_mean_30     390193 non-null float16\n",
      "rolling_std_30      390193 non-null float16\n",
      "rolling_mean_60     390116 non-null float16\n",
      "rolling_std_60      390116 non-null float16\n",
      "rolling_mean_180    389641 non-null float16\n",
      "rolling_std_180     389641 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.71833\n",
      "[200]\tvalid_0's rmse: 1.69794\n",
      "[300]\tvalid_0's rmse: 1.68458\n",
      "[400]\tvalid_0's rmse: 1.67864\n",
      "[500]\tvalid_0's rmse: 1.67315\n",
      "[600]\tvalid_0's rmse: 1.66851\n",
      "[700]\tvalid_0's rmse: 1.66399\n",
      "[800]\tvalid_0's rmse: 1.66003\n",
      "[900]\tvalid_0's rmse: 1.65663\n",
      "[1000]\tvalid_0's rmse: 1.65273\n",
      "[1100]\tvalid_0's rmse: 1.64889\n",
      "[1200]\tvalid_0's rmse: 1.6459\n",
      "[1300]\tvalid_0's rmse: 1.64224\n",
      "[1400]\tvalid_0's rmse: 1.63887\n",
      "Train TX_3\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_TX_3_validation  1814    0.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_TX_3_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_TX_3_validation  1814    0.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_TX_3_validation  1814    1.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_TX_3_validation  1814    1.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      226    8.257812   8.617188   8.257812  ...        1.000000   \n",
      "1  HOBBIES        5    3.970703   3.970703   3.970703  ...        0.000000   \n",
      "2  HOBBIES      301    2.970703   2.970703   0.970215  ...        0.571289   \n",
      "3  HOBBIES        7    4.640625   4.640625   3.769531  ...        0.856934   \n",
      "4  HOBBIES       16    2.730469   2.980469   1.500000  ...        0.285645   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       1.154297         0.785645        0.892578         0.600098   \n",
      "1       0.000000         0.071411        0.267334         0.066650   \n",
      "2       1.133789         0.571289        0.937500         0.433350   \n",
      "3       1.463867         1.357422        1.549805         1.400391   \n",
      "4       0.488037         0.357178        0.633301         0.566895   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.770020         0.716797        0.845703         0.583496   \n",
      "1        0.253662         0.099976        0.302490         0.088867   \n",
      "2        0.773926         0.316650        0.676270         0.311035   \n",
      "3        1.428711         1.500000        1.610352         1.066406   \n",
      "4        0.773926         0.733398        0.971680         0.766602   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.753906  \n",
      "1        0.285400  \n",
      "2        0.600586  \n",
      "3        1.400391  \n",
      "4        0.958008  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390267  FOODS_3_823_TX_3_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390268  FOODS_3_824_TX_3_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390269  FOODS_3_825_TX_3_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390270  FOODS_3_826_TX_3_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390271  FOODS_3_827_TX_3_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390267        3    2.980469   2.980469   2.000000  ...        0.714355   \n",
      "390268        0    2.480469   2.679688   2.470703  ...        0.000000   \n",
      "390269        0    3.980469   4.378906   3.980469  ...        1.428711   \n",
      "390270      211    1.280273   1.280273   1.280273  ...        2.142578   \n",
      "390271      312    1.000000   1.000000   0.500000  ...        0.714355   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390267       0.951172         0.714355        0.726074         0.333252   \n",
      "390268       0.000000         0.142822        0.363037         0.166626   \n",
      "390269       1.618164         1.286133        1.138672         1.099609   \n",
      "390270       1.463867         1.500000        1.286133         1.466797   \n",
      "390271       1.112305         0.643066        1.007812         0.933105   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390267        0.606445         0.316650        0.596191         0.166626   \n",
      "390268        0.461182         0.083313        0.333984         0.027771   \n",
      "390269        0.959473         1.200195        1.161133         1.055664   \n",
      "390270        1.591797         1.599609        1.842773         1.183594   \n",
      "390271        1.595703         0.983398        1.651367         1.338867   \n",
      "\n",
      "       rolling_std_180  \n",
      "390267        0.454590  \n",
      "390268        0.195801  \n",
      "390269        1.117188  \n",
      "390270        1.364258  \n",
      "390271        2.074219  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390272 entries, 0 to 390271\n",
      "Data columns (total 63 columns):\n",
      "id                  390272 non-null category\n",
      "d                   390272 non-null int16\n",
      "sales               304900 non-null float64\n",
      "item_id             390272 non-null category\n",
      "dept_id             390272 non-null category\n",
      "cat_id              390272 non-null category\n",
      "release             390272 non-null int16\n",
      "sell_price          390272 non-null float16\n",
      "price_max           390272 non-null float16\n",
      "price_min           390272 non-null float16\n",
      "price_std           390272 non-null float16\n",
      "price_mean          390272 non-null float16\n",
      "price_norm          390272 non-null float16\n",
      "price_nunique       390272 non-null float16\n",
      "item_nunique        390272 non-null int16\n",
      "price_momentum      390272 non-null float16\n",
      "price_momentum_m    390272 non-null float16\n",
      "price_momentum_y    390272 non-null float16\n",
      "event_name_1        39637 non-null category\n",
      "event_type_1        39637 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390272 non-null category\n",
      "snap_TX             390272 non-null category\n",
      "snap_WI             390272 non-null category\n",
      "tm_d                390272 non-null int8\n",
      "tm_w                390272 non-null int8\n",
      "tm_m                390272 non-null int8\n",
      "tm_y                390272 non-null int8\n",
      "tm_wm               390272 non-null int8\n",
      "tm_dw               390272 non-null int8\n",
      "tm_w_end            390272 non-null int8\n",
      "enc_cat_id_mean     390272 non-null float16\n",
      "enc_cat_id_std      390272 non-null float16\n",
      "enc_dept_id_mean    390272 non-null float16\n",
      "enc_dept_id_std     390272 non-null float16\n",
      "enc_item_id_mean    390272 non-null float16\n",
      "enc_item_id_std     390272 non-null float16\n",
      "sales_lag_28        390272 non-null float16\n",
      "sales_lag_29        390272 non-null float16\n",
      "sales_lag_30        390272 non-null float16\n",
      "sales_lag_31        390272 non-null float16\n",
      "sales_lag_32        390272 non-null float16\n",
      "sales_lag_33        390272 non-null float16\n",
      "sales_lag_34        390272 non-null float16\n",
      "sales_lag_35        390272 non-null float16\n",
      "sales_lag_36        390272 non-null float16\n",
      "sales_lag_37        390272 non-null float16\n",
      "sales_lag_38        390272 non-null float16\n",
      "sales_lag_39        390272 non-null float16\n",
      "sales_lag_40        390272 non-null float16\n",
      "sales_lag_41        390272 non-null float16\n",
      "sales_lag_42        390272 non-null float16\n",
      "rolling_mean_7      390272 non-null float16\n",
      "rolling_std_7       390272 non-null float16\n",
      "rolling_mean_14     390272 non-null float16\n",
      "rolling_std_14      390272 non-null float16\n",
      "rolling_mean_30     390257 non-null float16\n",
      "rolling_std_30      390257 non-null float16\n",
      "rolling_mean_60     390180 non-null float16\n",
      "rolling_std_60      390180 non-null float16\n",
      "rolling_mean_180    388851 non-null float16\n",
      "rolling_std_180     388851 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 1.6915\n",
      "[200]\tvalid_0's rmse: 1.67829\n",
      "[300]\tvalid_0's rmse: 1.66938\n",
      "[400]\tvalid_0's rmse: 1.66486\n",
      "[500]\tvalid_0's rmse: 1.65994\n",
      "[600]\tvalid_0's rmse: 1.65542\n",
      "[700]\tvalid_0's rmse: 1.65145\n",
      "[800]\tvalid_0's rmse: 1.64732\n",
      "[900]\tvalid_0's rmse: 1.64368\n",
      "[1000]\tvalid_0's rmse: 1.63945\n",
      "[1100]\tvalid_0's rmse: 1.6353\n",
      "[1200]\tvalid_0's rmse: 1.63249\n",
      "[1300]\tvalid_0's rmse: 1.62799\n",
      "[1400]\tvalid_0's rmse: 1.62453\n",
      "Train WI_1\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_WI_1_validation  1814    1.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_WI_1_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_WI_1_validation  1814    0.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_WI_1_validation  1814    0.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_WI_1_validation  1814    3.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      224    8.257812   9.578125   8.257812  ...        1.142578   \n",
      "1  HOBBIES        6    3.970703   3.970703   3.970703  ...        3.714844   \n",
      "2  HOBBIES      300    2.970703   2.970703   2.970703  ...        0.285645   \n",
      "3  HOBBIES        0    4.640625   4.640625   4.339844  ...        0.714355   \n",
      "4  HOBBIES       14    2.880859   3.080078   2.480469  ...        0.571289   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.899902         0.643066        0.841797         0.666504   \n",
      "1       0.951172         2.714844        1.541016         1.799805   \n",
      "2       0.488037         0.285645        0.468750         0.133301   \n",
      "3       0.488037         0.571289        0.645996         0.433350   \n",
      "4       0.786621         1.000000        1.240234         1.033203   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.994141         0.516602        0.812988         0.372314   \n",
      "1        1.517578         1.233398        1.306641         0.722168   \n",
      "2        0.345703         0.083313        0.278809         0.127808   \n",
      "3        0.568359         0.350098        0.546875         0.322266   \n",
      "4        1.216797         0.783203        1.059570         0.822266   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.677246  \n",
      "1        1.025391  \n",
      "2        0.334717  \n",
      "3        0.604004  \n",
      "4        0.998047  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390239  FOODS_3_823_WI_1_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390240  FOODS_3_824_WI_1_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390241  FOODS_3_825_WI_1_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390242  FOODS_3_826_WI_1_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390243  FOODS_3_827_WI_1_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390239       13    2.980469   2.980469   2.480469  ...        0.428467   \n",
      "390240        0    2.480469   2.679688   2.470703  ...        0.428467   \n",
      "390241        0    3.980469   4.378906   3.939453  ...        1.286133   \n",
      "390242      211    1.280273   1.280273   1.280273  ...        1.286133   \n",
      "390243      304    1.000000   1.000000   1.000000  ...        2.142578   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390239       0.786621         0.643066        0.745117         0.300049   \n",
      "390240       0.534668         0.285645        0.468750         0.333252   \n",
      "390241       1.379883         1.286133        1.069336         1.366211   \n",
      "390242       1.379883         1.286133        1.138672         1.500000   \n",
      "390243       2.794922         2.500000        2.564453         2.966797   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390239        0.596191         0.266602        0.634277         0.733398   \n",
      "390240        0.958984         0.166626        0.692871         0.055542   \n",
      "390241        1.216797         1.299805        1.197266         0.960938   \n",
      "390242        1.502930         1.633789        1.301758         1.233398   \n",
      "390243        2.976562         3.666016        4.242188         3.333984   \n",
      "\n",
      "       rolling_std_180  \n",
      "390239        1.141602  \n",
      "390240        0.405518  \n",
      "390241        1.188477  \n",
      "390242        1.684570  \n",
      "390243        3.437500  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390244 entries, 0 to 390243\n",
      "Data columns (total 63 columns):\n",
      "id                  390244 non-null category\n",
      "d                   390244 non-null int16\n",
      "sales               304872 non-null float64\n",
      "item_id             390244 non-null category\n",
      "dept_id             390244 non-null category\n",
      "cat_id              390244 non-null category\n",
      "release             390244 non-null int16\n",
      "sell_price          390244 non-null float16\n",
      "price_max           390244 non-null float16\n",
      "price_min           390244 non-null float16\n",
      "price_std           390244 non-null float16\n",
      "price_mean          390244 non-null float16\n",
      "price_norm          390244 non-null float16\n",
      "price_nunique       390244 non-null float16\n",
      "item_nunique        390244 non-null int16\n",
      "price_momentum      390237 non-null float16\n",
      "price_momentum_m    390244 non-null float16\n",
      "price_momentum_y    390244 non-null float16\n",
      "event_name_1        39634 non-null category\n",
      "event_type_1        39634 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390244 non-null category\n",
      "snap_TX             390244 non-null category\n",
      "snap_WI             390244 non-null category\n",
      "tm_d                390244 non-null int8\n",
      "tm_w                390244 non-null int8\n",
      "tm_m                390244 non-null int8\n",
      "tm_y                390244 non-null int8\n",
      "tm_wm               390244 non-null int8\n",
      "tm_dw               390244 non-null int8\n",
      "tm_w_end            390244 non-null int8\n",
      "enc_cat_id_mean     390244 non-null float16\n",
      "enc_cat_id_std      390244 non-null float16\n",
      "enc_dept_id_mean    390244 non-null float16\n",
      "enc_dept_id_std     390244 non-null float16\n",
      "enc_item_id_mean    390244 non-null float16\n",
      "enc_item_id_std     390244 non-null float16\n",
      "sales_lag_28        390216 non-null float16\n",
      "sales_lag_29        390215 non-null float16\n",
      "sales_lag_30        390214 non-null float16\n",
      "sales_lag_31        390213 non-null float16\n",
      "sales_lag_32        390212 non-null float16\n",
      "sales_lag_33        390211 non-null float16\n",
      "sales_lag_34        390210 non-null float16\n",
      "sales_lag_35        390209 non-null float16\n",
      "sales_lag_36        390208 non-null float16\n",
      "sales_lag_37        390207 non-null float16\n",
      "sales_lag_38        390206 non-null float16\n",
      "sales_lag_39        390205 non-null float16\n",
      "sales_lag_40        390204 non-null float16\n",
      "sales_lag_41        390203 non-null float16\n",
      "sales_lag_42        390202 non-null float16\n",
      "rolling_mean_7      390210 non-null float16\n",
      "rolling_std_7       390210 non-null float16\n",
      "rolling_mean_14     390203 non-null float16\n",
      "rolling_std_14      390203 non-null float16\n",
      "rolling_mean_30     390187 non-null float16\n",
      "rolling_std_30      390187 non-null float16\n",
      "rolling_mean_60     390157 non-null float16\n",
      "rolling_std_60      390157 non-null float16\n",
      "rolling_mean_180    389401 non-null float16\n",
      "rolling_std_180     389401 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 1.59878\n",
      "[200]\tvalid_0's rmse: 1.57937\n",
      "[300]\tvalid_0's rmse: 1.5718\n",
      "[400]\tvalid_0's rmse: 1.5666\n",
      "[500]\tvalid_0's rmse: 1.56201\n",
      "[600]\tvalid_0's rmse: 1.55715\n",
      "[700]\tvalid_0's rmse: 1.55287\n",
      "[800]\tvalid_0's rmse: 1.54936\n",
      "[900]\tvalid_0's rmse: 1.54571\n",
      "[1000]\tvalid_0's rmse: 1.54212\n",
      "[1100]\tvalid_0's rmse: 1.53796\n",
      "[1200]\tvalid_0's rmse: 1.53458\n",
      "[1300]\tvalid_0's rmse: 1.53124\n",
      "[1400]\tvalid_0's rmse: 1.52818\n",
      "Train WI_2\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_WI_2_validation  1814    0.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_WI_2_validation  1814    1.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_WI_2_validation  1814    0.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_WI_2_validation  1814    0.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_WI_2_validation  1814    1.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      226    8.382812   8.617188   8.257812  ...        0.000000   \n",
      "1  HOBBIES        6    3.970703   3.970703   3.970703  ...        0.856934   \n",
      "2  HOBBIES      304    2.970703   5.968750   2.970703  ...        0.142822   \n",
      "3  HOBBIES        9    4.640625   4.640625   4.261719  ...        0.285645   \n",
      "4  HOBBIES       31    2.880859   3.080078   2.480469  ...        0.285645   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.000000         0.000000        0.000000         0.000000   \n",
      "1       0.689941         0.856934        0.949219         0.600098   \n",
      "2       0.377930         0.071411        0.267334         0.066650   \n",
      "3       0.488037         0.357178        0.497314         0.333252   \n",
      "4       0.488037         0.500000        0.650391         0.500000   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.000000         0.000000        0.000000         0.066650   \n",
      "1        0.813477         0.483398        0.724609         0.511230   \n",
      "2        0.253662         0.083313        0.333984         0.088867   \n",
      "3        0.710938         0.316650        0.624023         0.244385   \n",
      "4        0.682129         0.649902        0.755371         0.438965   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.291504  \n",
      "1        0.688965  \n",
      "2        0.304443  \n",
      "3        0.545410  \n",
      "4        0.644531  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390218  FOODS_3_823_WI_2_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390219  FOODS_3_824_WI_2_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390220  FOODS_3_825_WI_2_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390221  FOODS_3_826_WI_2_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390222  FOODS_3_827_WI_2_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390218       13    2.980469   2.980469   2.480469  ...        0.142822   \n",
      "390219        0    2.480469   2.679688   2.470703  ...        0.428467   \n",
      "390220        0    3.980469   4.378906   3.980469  ...        2.000000   \n",
      "390221      212    1.280273   1.280273   1.280273  ...        1.428711   \n",
      "390222      339    1.000000   1.000000   1.000000  ...        1.713867   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390218       0.377930         0.142822        0.363037         0.066650   \n",
      "390219       0.786621         0.714355        0.994629         0.600098   \n",
      "390220       2.000000         2.214844        1.928711         1.866211   \n",
      "390221       1.511719         1.571289        1.284180         1.066406   \n",
      "390222       2.058594         2.072266        1.774414         2.833984   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390218        0.253662         0.166626        0.418457         0.983398   \n",
      "390219        0.894531         0.300049        0.696289         0.099976   \n",
      "390220        1.655273         1.666992        1.492188         1.122070   \n",
      "390221        1.229492         0.750000        1.083008         0.827637   \n",
      "390222        2.199219         2.867188        2.244141         2.644531   \n",
      "\n",
      "       rolling_std_180  \n",
      "390218        1.692383  \n",
      "390219        0.424072  \n",
      "390220        1.301758  \n",
      "390221        1.107422  \n",
      "390222        2.470703  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390223 entries, 0 to 390222\n",
      "Data columns (total 63 columns):\n",
      "id                  390223 non-null category\n",
      "d                   390223 non-null int16\n",
      "sales               304851 non-null float64\n",
      "item_id             390223 non-null category\n",
      "dept_id             390223 non-null category\n",
      "cat_id              390223 non-null category\n",
      "release             390223 non-null int16\n",
      "sell_price          390223 non-null float16\n",
      "price_max           390223 non-null float16\n",
      "price_min           390223 non-null float16\n",
      "price_std           390223 non-null float16\n",
      "price_mean          390223 non-null float16\n",
      "price_norm          390223 non-null float16\n",
      "price_nunique       390223 non-null float16\n",
      "item_nunique        390223 non-null int16\n",
      "price_momentum      390202 non-null float16\n",
      "price_momentum_m    390223 non-null float16\n",
      "price_momentum_y    390223 non-null float16\n",
      "event_name_1        39632 non-null category\n",
      "event_type_1        39632 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390223 non-null category\n",
      "snap_TX             390223 non-null category\n",
      "snap_WI             390223 non-null category\n",
      "tm_d                390223 non-null int8\n",
      "tm_w                390223 non-null int8\n",
      "tm_m                390223 non-null int8\n",
      "tm_y                390223 non-null int8\n",
      "tm_wm               390223 non-null int8\n",
      "tm_dw               390223 non-null int8\n",
      "tm_w_end            390223 non-null int8\n",
      "enc_cat_id_mean     390223 non-null float16\n",
      "enc_cat_id_std      390223 non-null float16\n",
      "enc_dept_id_mean    390223 non-null float16\n",
      "enc_dept_id_std     390223 non-null float16\n",
      "enc_item_id_mean    390223 non-null float16\n",
      "enc_item_id_std     390223 non-null float16\n",
      "sales_lag_28        390139 non-null float16\n",
      "sales_lag_29        390136 non-null float16\n",
      "sales_lag_30        390133 non-null float16\n",
      "sales_lag_31        390130 non-null float16\n",
      "sales_lag_32        390127 non-null float16\n",
      "sales_lag_33        390124 non-null float16\n",
      "sales_lag_34        390121 non-null float16\n",
      "sales_lag_35        390118 non-null float16\n",
      "sales_lag_36        390115 non-null float16\n",
      "sales_lag_37        390112 non-null float16\n",
      "sales_lag_38        390109 non-null float16\n",
      "sales_lag_39        390106 non-null float16\n",
      "sales_lag_40        390103 non-null float16\n",
      "sales_lag_41        390100 non-null float16\n",
      "sales_lag_42        390097 non-null float16\n",
      "rolling_mean_7      390121 non-null float16\n",
      "rolling_std_7       390121 non-null float16\n",
      "rolling_mean_14     390100 non-null float16\n",
      "rolling_std_14      390100 non-null float16\n",
      "rolling_mean_30     390052 non-null float16\n",
      "rolling_std_30      390052 non-null float16\n",
      "rolling_mean_60     389962 non-null float16\n",
      "rolling_std_60      389962 non-null float16\n",
      "rolling_mean_180    389285 non-null float16\n",
      "rolling_std_180     389285 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.69105\n",
      "[200]\tvalid_0's rmse: 2.58171\n",
      "[300]\tvalid_0's rmse: 2.54574\n",
      "[400]\tvalid_0's rmse: 2.52407\n",
      "[500]\tvalid_0's rmse: 2.50655\n",
      "[600]\tvalid_0's rmse: 2.49078\n",
      "[700]\tvalid_0's rmse: 2.47712\n",
      "[800]\tvalid_0's rmse: 2.46442\n",
      "[900]\tvalid_0's rmse: 2.45332\n",
      "[1000]\tvalid_0's rmse: 2.44306\n",
      "[1100]\tvalid_0's rmse: 2.43294\n",
      "[1200]\tvalid_0's rmse: 2.42588\n",
      "[1300]\tvalid_0's rmse: 2.41622\n",
      "[1400]\tvalid_0's rmse: 2.40552\n",
      "Train WI_3\n",
      "                              id     d  sales        item_id    dept_id  \\\n",
      "0  HOBBIES_1_001_WI_3_validation  1814    2.0  HOBBIES_1_001  HOBBIES_1   \n",
      "1  HOBBIES_1_002_WI_3_validation  1814    0.0  HOBBIES_1_002  HOBBIES_1   \n",
      "2  HOBBIES_1_003_WI_3_validation  1814    1.0  HOBBIES_1_003  HOBBIES_1   \n",
      "3  HOBBIES_1_004_WI_3_validation  1814    3.0  HOBBIES_1_004  HOBBIES_1   \n",
      "4  HOBBIES_1_005_WI_3_validation  1814    3.0  HOBBIES_1_005  HOBBIES_1   \n",
      "\n",
      "    cat_id  release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "0  HOBBIES      227    8.257812   8.382812   8.257812  ...        0.000000   \n",
      "1  HOBBIES        5    3.970703   3.970703   3.970703  ...        1.142578   \n",
      "2  HOBBIES      301    2.970703   2.970703   0.939941  ...        0.285645   \n",
      "3  HOBBIES        0    4.640625   4.640625   4.339844  ...        3.000000   \n",
      "4  HOBBIES       14    2.880859   3.080078   2.480469  ...        0.000000   \n",
      "\n",
      "   rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "0       0.000000         0.142822        0.534668         0.166626   \n",
      "1       0.899902         0.571289        0.851562         0.500000   \n",
      "2       0.488037         0.214233        0.425781         0.333252   \n",
      "3       2.000000         2.642578        2.023438         2.066406   \n",
      "4       0.000000         0.285645        0.825195         0.500000   \n",
      "\n",
      "   rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "0        0.461182         0.233276        0.563477         0.288818   \n",
      "1        0.682129         0.449951        0.674805         0.366699   \n",
      "2        0.710938         0.199951        0.546387         0.077759   \n",
      "3        2.050781         1.866211        1.935547         2.021484   \n",
      "4        0.937500         0.583496        0.907227         0.411133   \n",
      "\n",
      "  rolling_std_180  \n",
      "0        0.563965  \n",
      "1        0.578125  \n",
      "2        0.341797  \n",
      "3        1.848633  \n",
      "4        0.760742  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "                                 id     d  sales      item_id  dept_id cat_id  \\\n",
      "390267  FOODS_3_823_WI_3_validation  1941    NaN  FOODS_3_823  FOODS_3  FOODS   \n",
      "390268  FOODS_3_824_WI_3_validation  1941    NaN  FOODS_3_824  FOODS_3  FOODS   \n",
      "390269  FOODS_3_825_WI_3_validation  1941    NaN  FOODS_3_825  FOODS_3  FOODS   \n",
      "390270  FOODS_3_826_WI_3_validation  1941    NaN  FOODS_3_826  FOODS_3  FOODS   \n",
      "390271  FOODS_3_827_WI_3_validation  1941    NaN  FOODS_3_827  FOODS_3  FOODS   \n",
      "\n",
      "        release  sell_price  price_max  price_min  ...  rolling_mean_7  \\\n",
      "390267        0    2.980469   2.980469   2.480469  ...        0.285645   \n",
      "390268        0    2.480469   2.679688   2.000000  ...        0.142822   \n",
      "390269        0    3.980469   4.378906   3.980469  ...        0.571289   \n",
      "390270      230    1.280273   1.280273   1.280273  ...        1.142578   \n",
      "390271      304    1.000000   1.000000   1.000000  ...        0.000000   \n",
      "\n",
      "        rolling_std_7  rolling_mean_14  rolling_std_14  rolling_mean_30  \\\n",
      "390267       0.488037         0.428467    7.558594e-01         0.199951   \n",
      "390268       0.377930         0.214233    4.257812e-01         0.300049   \n",
      "390269       0.786621         0.785645    1.188477e+00         0.866699   \n",
      "390270       1.344727         0.928711    1.207031e+00         1.066406   \n",
      "390271       0.000000         0.000000    1.192093e-07         1.166992   \n",
      "\n",
      "        rolling_std_30  rolling_mean_60  rolling_std_60 rolling_mean_180  \\\n",
      "390267        0.550781         0.250000        0.571289         0.616699   \n",
      "390268        0.535156         0.150024        0.404541         0.049988   \n",
      "390269        1.136719         1.033203        1.056641         0.761230   \n",
      "390270        1.172852         1.016602        1.065430         1.338867   \n",
      "390271        1.821289         1.500000        1.770508         1.510742   \n",
      "\n",
      "       rolling_std_180  \n",
      "390267        0.987305  \n",
      "390268        0.242798  \n",
      "390269        0.941895  \n",
      "390270        1.550781  \n",
      "390271        1.741211  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390272 entries, 0 to 390271\n",
      "Data columns (total 63 columns):\n",
      "id                  390272 non-null category\n",
      "d                   390272 non-null int16\n",
      "sales               304900 non-null float64\n",
      "item_id             390272 non-null category\n",
      "dept_id             390272 non-null category\n",
      "cat_id              390272 non-null category\n",
      "release             390272 non-null int16\n",
      "sell_price          390272 non-null float16\n",
      "price_max           390272 non-null float16\n",
      "price_min           390272 non-null float16\n",
      "price_std           390272 non-null float16\n",
      "price_mean          390272 non-null float16\n",
      "price_norm          390272 non-null float16\n",
      "price_nunique       390272 non-null float16\n",
      "item_nunique        390272 non-null int16\n",
      "price_momentum      390272 non-null float16\n",
      "price_momentum_m    390272 non-null float16\n",
      "price_momentum_y    390272 non-null float16\n",
      "event_name_1        39637 non-null category\n",
      "event_type_1        39637 non-null category\n",
      "event_name_2        0 non-null category\n",
      "event_type_2        0 non-null category\n",
      "snap_CA             390272 non-null category\n",
      "snap_TX             390272 non-null category\n",
      "snap_WI             390272 non-null category\n",
      "tm_d                390272 non-null int8\n",
      "tm_w                390272 non-null int8\n",
      "tm_m                390272 non-null int8\n",
      "tm_y                390272 non-null int8\n",
      "tm_wm               390272 non-null int8\n",
      "tm_dw               390272 non-null int8\n",
      "tm_w_end            390272 non-null int8\n",
      "enc_cat_id_mean     390272 non-null float16\n",
      "enc_cat_id_std      390272 non-null float16\n",
      "enc_dept_id_mean    390272 non-null float16\n",
      "enc_dept_id_std     390272 non-null float16\n",
      "enc_item_id_mean    390272 non-null float16\n",
      "enc_item_id_std     390272 non-null float16\n",
      "sales_lag_28        390272 non-null float16\n",
      "sales_lag_29        390272 non-null float16\n",
      "sales_lag_30        390272 non-null float16\n",
      "sales_lag_31        390272 non-null float16\n",
      "sales_lag_32        390272 non-null float16\n",
      "sales_lag_33        390272 non-null float16\n",
      "sales_lag_34        390272 non-null float16\n",
      "sales_lag_35        390272 non-null float16\n",
      "sales_lag_36        390272 non-null float16\n",
      "sales_lag_37        390272 non-null float16\n",
      "sales_lag_38        390272 non-null float16\n",
      "sales_lag_39        390272 non-null float16\n",
      "sales_lag_40        390272 non-null float16\n",
      "sales_lag_41        390272 non-null float16\n",
      "sales_lag_42        390272 non-null float16\n",
      "rolling_mean_7      390272 non-null float16\n",
      "rolling_std_7       390272 non-null float16\n",
      "rolling_mean_14     390272 non-null float16\n",
      "rolling_std_14      390272 non-null float16\n",
      "rolling_mean_30     390272 non-null float16\n",
      "rolling_std_30      390272 non-null float16\n",
      "rolling_mean_60     390272 non-null float16\n",
      "rolling_std_60      390272 non-null float16\n",
      "rolling_mean_180    389894 non-null float16\n",
      "rolling_std_180     389894 non-null float16\n",
      "dtypes: category(11), float16(41), float64(1), int16(3), int8(7)\n",
      "memory usage: 43.4 MB\n",
      "None\n",
      "[100]\tvalid_0's rmse: 1.92146\n",
      "[200]\tvalid_0's rmse: 1.85492\n",
      "[300]\tvalid_0's rmse: 1.83253\n",
      "[400]\tvalid_0's rmse: 1.82095\n",
      "[500]\tvalid_0's rmse: 1.81358\n",
      "[600]\tvalid_0's rmse: 1.80564\n",
      "[700]\tvalid_0's rmse: 1.79827\n",
      "[800]\tvalid_0's rmse: 1.79192\n",
      "[900]\tvalid_0's rmse: 1.7861\n",
      "[1000]\tvalid_0's rmse: 1.78047\n",
      "[1100]\tvalid_0's rmse: 1.77421\n",
      "[1200]\tvalid_0's rmse: 1.76966\n",
      "[1300]\tvalid_0's rmse: 1.76475\n",
      "[1400]\tvalid_0's rmse: 1.76026\n"
     ]
    }
   ],
   "source": [
    "for store_id in STORES_IDS:\n",
    "    print('Train', store_id)\n",
    "    \n",
    "    # Get grid for current store\n",
    "    grid_df, features_columns = get_data_by_store(store_id)\n",
    "    \n",
    "    # Masks for \n",
    "    # Train (All data less than 1913)\n",
    "    # \"Validation\" (Last 28 days - not real validation set)\n",
    "    # Test (All data greater than 1913 day, \n",
    "    #       with some gap for recursive features)\n",
    "    train_mask = grid_df['d']<=END_TRAIN\n",
    "    valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "    preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                       label=grid_df[train_mask][TARGET])\n",
    "    train_data.save_binary('train_data.bin')\n",
    "    train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                       label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "    grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "    grid_df = grid_df[keep_cols]\n",
    "    print(grid_df.head())\n",
    "    print(grid_df.tail())\n",
    "    print(grid_df.info())\n",
    "    grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "    del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "    seed_everything(SEED)\n",
    "    estimator = lgb.train(lgb_params,\n",
    "                          train_data,\n",
    "                          valid_sets = [valid_data],\n",
    "                          verbose_eval = 100,\n",
    "                          )\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "    model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "    pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "    !rm train_data.bin\n",
    "    del train_data, valid_data, estimator\n",
    "    gc.collect()\n",
    "    \n",
    "    # \"Keep\" models features for predictions\n",
    "    MODEL_FEATURES = features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  0.77 min round |  0.77 min total |  37308.80 day sales |\n",
      "Predict | Day: 2\n",
      "##########  0.76 min round |  1.53 min total |  35335.42 day sales |\n",
      "Predict | Day: 3\n",
      "##########  0.74 min round |  2.27 min total |  34783.90 day sales |\n",
      "Predict | Day: 4\n",
      "##########  0.74 min round |  3.01 min total |  35285.85 day sales |\n",
      "Predict | Day: 5\n",
      "##########  0.75 min round |  3.76 min total |  41724.47 day sales |\n",
      "Predict | Day: 6\n",
      "##########  0.74 min round |  4.50 min total |  50966.54 day sales |\n",
      "Predict | Day: 7\n",
      "##########  0.74 min round |  5.24 min total |  53580.33 day sales |\n",
      "Predict | Day: 8\n",
      "##########  0.76 min round |  6.00 min total |  44119.60 day sales |\n",
      "Predict | Day: 9\n",
      "##########  0.74 min round |  6.74 min total |  44431.43 day sales |\n",
      "Predict | Day: 10\n",
      "##########  0.75 min round |  7.49 min total |  38864.02 day sales |\n",
      "Predict | Day: 11\n",
      "##########  0.75 min round |  8.24 min total |  40720.81 day sales |\n",
      "Predict | Day: 12\n",
      "##########  0.75 min round |  8.99 min total |  45850.12 day sales |\n",
      "Predict | Day: 13\n",
      "##########  0.77 min round |  9.76 min total |  53919.12 day sales |\n",
      "Predict | Day: 14\n",
      "##########  0.70 min round |  10.46 min total |  46531.75 day sales |\n",
      "Predict | Day: 15\n",
      "##########  0.73 min round |  11.19 min total |  44801.33 day sales |\n",
      "Predict | Day: 16\n",
      "##########  0.75 min round |  11.94 min total |  39406.45 day sales |\n",
      "Predict | Day: 17\n",
      "##########  0.71 min round |  12.65 min total |  40373.79 day sales |\n",
      "Predict | Day: 18\n",
      "##########  0.72 min round |  13.38 min total |  40937.14 day sales |\n",
      "Predict | Day: 19\n",
      "##########  0.72 min round |  14.10 min total |  43909.91 day sales |\n",
      "Predict | Day: 20\n",
      "##########  0.73 min round |  14.83 min total |  53529.62 day sales |\n",
      "Predict | Day: 21\n",
      "##########  0.74 min round |  15.56 min total |  56021.50 day sales |\n",
      "Predict | Day: 22\n",
      "##########  0.73 min round |  16.29 min total |  41809.28 day sales |\n",
      "Predict | Day: 23\n",
      "##########  0.72 min round |  17.01 min total |  37911.11 day sales |\n",
      "Predict | Day: 24\n",
      "##########  0.73 min round |  17.74 min total |  37075.94 day sales |\n",
      "Predict | Day: 25\n",
      "##########  0.73 min round |  18.46 min total |  36977.05 day sales |\n",
      "Predict | Day: 26\n",
      "##########  0.75 min round |  19.21 min total |  41812.40 day sales |\n",
      "Predict | Day: 27\n",
      "##########  0.72 min round |  19.93 min total |  50762.76 day sales |\n",
      "Predict | Day: 28\n",
      "##########  0.72 min round |  20.66 min total |  51417.53 day sales |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.373569</td>\n",
       "      <td>0.341489</td>\n",
       "      <td>0.343651</td>\n",
       "      <td>0.330851</td>\n",
       "      <td>0.378356</td>\n",
       "      <td>0.431511</td>\n",
       "      <td>0.423120</td>\n",
       "      <td>0.463942</td>\n",
       "      <td>0.487156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406368</td>\n",
       "      <td>0.521859</td>\n",
       "      <td>0.573814</td>\n",
       "      <td>0.373389</td>\n",
       "      <td>0.333836</td>\n",
       "      <td>0.301846</td>\n",
       "      <td>0.283167</td>\n",
       "      <td>0.321126</td>\n",
       "      <td>0.396755</td>\n",
       "      <td>0.410307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.304983</td>\n",
       "      <td>0.266182</td>\n",
       "      <td>0.243182</td>\n",
       "      <td>0.240461</td>\n",
       "      <td>0.294768</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.331245</td>\n",
       "      <td>0.434473</td>\n",
       "      <td>0.442417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339828</td>\n",
       "      <td>0.490687</td>\n",
       "      <td>0.559283</td>\n",
       "      <td>0.363130</td>\n",
       "      <td>0.275342</td>\n",
       "      <td>0.245768</td>\n",
       "      <td>0.248248</td>\n",
       "      <td>0.271593</td>\n",
       "      <td>0.345999</td>\n",
       "      <td>0.361340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.674252</td>\n",
       "      <td>0.539741</td>\n",
       "      <td>0.483850</td>\n",
       "      <td>0.463280</td>\n",
       "      <td>0.636023</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.909188</td>\n",
       "      <td>1.166860</td>\n",
       "      <td>1.090199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004481</td>\n",
       "      <td>1.541840</td>\n",
       "      <td>1.688544</td>\n",
       "      <td>1.077601</td>\n",
       "      <td>0.795546</td>\n",
       "      <td>0.742795</td>\n",
       "      <td>0.649474</td>\n",
       "      <td>0.735476</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.916464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.944403</td>\n",
       "      <td>0.935210</td>\n",
       "      <td>0.808110</td>\n",
       "      <td>0.792187</td>\n",
       "      <td>0.949410</td>\n",
       "      <td>1.160681</td>\n",
       "      <td>1.166340</td>\n",
       "      <td>1.236102</td>\n",
       "      <td>1.229442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986986</td>\n",
       "      <td>1.370988</td>\n",
       "      <td>1.437660</td>\n",
       "      <td>1.000928</td>\n",
       "      <td>0.884545</td>\n",
       "      <td>0.845057</td>\n",
       "      <td>0.827194</td>\n",
       "      <td>0.980560</td>\n",
       "      <td>1.152899</td>\n",
       "      <td>1.231655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.239573</td>\n",
       "      <td>1.224351</td>\n",
       "      <td>1.224150</td>\n",
       "      <td>2.056664</td>\n",
       "      <td>2.718922</td>\n",
       "      <td>2.748200</td>\n",
       "      <td>2.405680</td>\n",
       "      <td>2.231635</td>\n",
       "      <td>2.395505</td>\n",
       "      <td>...</td>\n",
       "      <td>1.971739</td>\n",
       "      <td>2.425102</td>\n",
       "      <td>2.260457</td>\n",
       "      <td>1.649259</td>\n",
       "      <td>1.674562</td>\n",
       "      <td>1.553669</td>\n",
       "      <td>1.488599</td>\n",
       "      <td>1.722757</td>\n",
       "      <td>2.069605</td>\n",
       "      <td>1.927087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id        F1        F2        F3        F4  \\\n",
       "30485  FOODS_3_823_WI_3_validation  0.373569  0.341489  0.343651  0.330851   \n",
       "30486  FOODS_3_824_WI_3_validation  0.304983  0.266182  0.243182  0.240461   \n",
       "30487  FOODS_3_825_WI_3_validation  0.674252  0.539741  0.483850  0.463280   \n",
       "30488  FOODS_3_826_WI_3_validation  0.944403  0.935210  0.808110  0.792187   \n",
       "30489  FOODS_3_827_WI_3_validation  0.239573  1.224351  1.224150  2.056664   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "30485  0.378356  0.431511  0.423120  0.463942  0.487156  ...  0.406368   \n",
       "30486  0.294768  0.369417  0.331245  0.434473  0.442417  ...  0.339828   \n",
       "30487  0.636023  0.735115  0.909188  1.166860  1.090199  ...  1.004481   \n",
       "30488  0.949410  1.160681  1.166340  1.236102  1.229442  ...  0.986986   \n",
       "30489  2.718922  2.748200  2.405680  2.231635  2.395505  ...  1.971739   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "30485  0.521859  0.573814  0.373389  0.333836  0.301846  0.283167  0.321126   \n",
       "30486  0.490687  0.559283  0.363130  0.275342  0.245768  0.248248  0.271593   \n",
       "30487  1.541840  1.688544  1.077601  0.795546  0.742795  0.649474  0.735476   \n",
       "30488  1.370988  1.437660  1.000928  0.884545  0.845057  0.827194  0.980560   \n",
       "30489  2.425102  2.260457  1.649259  1.674562  1.553669  1.488599  1.722757   \n",
       "\n",
       "            F27       F28  \n",
       "30485  0.396755  0.410307  \n",
       "30486  0.345999  0.361340  \n",
       "30487  0.864346  0.916464  \n",
       "30488  1.152899  1.231655  \n",
       "30489  2.069605  1.927087  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dummy DataFrame to store predictions\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# Join back the Test dataset with \n",
    "# a small part of the training data \n",
    "# to make recursive features\n",
    "base_test = get_base_test()\n",
    "\n",
    "# Timer to measure predictions time \n",
    "main_time = time.time()\n",
    "\n",
    "# Loop over each prediction day\n",
    "# As rolling lags are the most timeconsuming\n",
    "# we will calculate it for whole day\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make temporary grid to calculate rolling lags\n",
    "    grid_df = base_test.copy()\n",
    "    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "        \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # Read all our models and make predictions\n",
    "        # for each day/store pairs\n",
    "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
    "        \n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask)&(store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # Make good column naming and add \n",
    "    # to all_preds DataFrame\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "all_preds.head()\n",
    "all_preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading competition sample submission and\n",
    "# merging our predictions\n",
    "# As we have predictions only for \"_validation\" data\n",
    "# we need to do fillna() for \"_evaluation\" items\n",
    "submission = pd.read_csv('sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv('submission_v'+str(VER)+'.csv', index=False) #0.47388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step:\n",
    "\n",
    "# Improvement should come from:\n",
    "# bayesian optimization: store_id\n",
    "# Loss function: rmse-wrmse\n",
    "# Stable CV: by week-year\n",
    "# Good features reduction strategy\n",
    "# Predictions stabilization with NN\n",
    "# Trend prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayesian optimization\n",
    "# CA_1\n",
    "grid_df, features_columns = get_data_by_store('CA_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4788267 entries, 0 to 4788266\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 639.6 MB\n"
     ]
    }
   ],
   "source": [
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>release</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_tmp_1_30</th>\n",
       "      <th>rolling_mean_tmp_1_60</th>\n",
       "      <th>rolling_mean_tmp_7_7</th>\n",
       "      <th>rolling_mean_tmp_7_14</th>\n",
       "      <th>rolling_mean_tmp_7_30</th>\n",
       "      <th>rolling_mean_tmp_7_60</th>\n",
       "      <th>rolling_mean_tmp_14_7</th>\n",
       "      <th>rolling_mean_tmp_14_14</th>\n",
       "      <th>rolling_mean_tmp_14_30</th>\n",
       "      <th>rolling_mean_tmp_14_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>1.769531</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_012_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>6.519531</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_015_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HOBBIES_1_015</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  d  sales        item_id    dept_id   cat_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  1   12.0  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "1  HOBBIES_1_009_CA_1_validation  1    2.0  HOBBIES_1_009  HOBBIES_1  HOBBIES   \n",
       "2  HOBBIES_1_010_CA_1_validation  1    0.0  HOBBIES_1_010  HOBBIES_1  HOBBIES   \n",
       "3  HOBBIES_1_012_CA_1_validation  1    0.0  HOBBIES_1_012  HOBBIES_1  HOBBIES   \n",
       "4  HOBBIES_1_015_CA_1_validation  1    4.0  HOBBIES_1_015  HOBBIES_1  HOBBIES   \n",
       "\n",
       "   release  sell_price  price_max  price_min  ...  rolling_mean_tmp_1_30  \\\n",
       "0        0    0.459961   0.500000   0.419922  ...                    NaN   \n",
       "1        0    1.559570   1.769531   1.559570  ...                    NaN   \n",
       "2        0    3.169922   3.169922   2.970703  ...                    NaN   \n",
       "3        0    5.980469   6.519531   5.980469  ...                    NaN   \n",
       "4        0    0.700195   0.720215   0.680176  ...                    NaN   \n",
       "\n",
       "   rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  rolling_mean_tmp_7_14  \\\n",
       "0                    NaN                   NaN                    NaN   \n",
       "1                    NaN                   NaN                    NaN   \n",
       "2                    NaN                   NaN                    NaN   \n",
       "3                    NaN                   NaN                    NaN   \n",
       "4                    NaN                   NaN                    NaN   \n",
       "\n",
       "   rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  rolling_mean_tmp_14_7  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   rolling_mean_tmp_14_14 rolling_mean_tmp_14_30 rolling_mean_tmp_14_60  \n",
       "0                     NaN                    NaN                    NaN  \n",
       "1                     NaN                    NaN                    NaN  \n",
       "2                     NaN                    NaN                    NaN  \n",
       "3                     NaN                    NaN                    NaN  \n",
       "4                     NaN                    NaN                    NaN  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>release</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_tmp_1_30</th>\n",
       "      <th>rolling_mean_tmp_1_60</th>\n",
       "      <th>rolling_mean_tmp_7_7</th>\n",
       "      <th>rolling_mean_tmp_7_14</th>\n",
       "      <th>rolling_mean_tmp_7_30</th>\n",
       "      <th>rolling_mean_tmp_7_60</th>\n",
       "      <th>rolling_mean_tmp_14_7</th>\n",
       "      <th>rolling_mean_tmp_14_14</th>\n",
       "      <th>rolling_mean_tmp_14_30</th>\n",
       "      <th>rolling_mean_tmp_14_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788262</th>\n",
       "      <td>FOODS_3_823_CA_1_validation</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>127</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788263</th>\n",
       "      <td>FOODS_3_824_CA_1_validation</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>2.470703</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788264</th>\n",
       "      <td>FOODS_3_825_CA_1_validation</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>1</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>4.378906</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788265</th>\n",
       "      <td>FOODS_3_826_CA_1_validation</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>211</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788266</th>\n",
       "      <td>FOODS_3_827_CA_1_validation</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id     d  sales      item_id  dept_id  \\\n",
       "4788262  FOODS_3_823_CA_1_validation  1941    NaN  FOODS_3_823  FOODS_3   \n",
       "4788263  FOODS_3_824_CA_1_validation  1941    NaN  FOODS_3_824  FOODS_3   \n",
       "4788264  FOODS_3_825_CA_1_validation  1941    NaN  FOODS_3_825  FOODS_3   \n",
       "4788265  FOODS_3_826_CA_1_validation  1941    NaN  FOODS_3_826  FOODS_3   \n",
       "4788266  FOODS_3_827_CA_1_validation  1941    NaN  FOODS_3_827  FOODS_3   \n",
       "\n",
       "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
       "4788262  FOODS      127    2.980469   2.980469   2.480469  ...   \n",
       "4788263  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
       "4788264  FOODS        1    3.980469   4.378906   3.980469  ...   \n",
       "4788265  FOODS      211    1.280273   1.280273   1.280273  ...   \n",
       "4788266  FOODS      403    1.000000   1.000000   1.000000  ...   \n",
       "\n",
       "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
       "4788262                    NaN                    NaN                   NaN   \n",
       "4788263                    NaN                    NaN                   NaN   \n",
       "4788264                    NaN                    NaN                   NaN   \n",
       "4788265                    NaN                    NaN                   NaN   \n",
       "4788266                    NaN                    NaN                   NaN   \n",
       "\n",
       "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
       "4788262                    NaN                    NaN                    NaN   \n",
       "4788263                    NaN                    NaN                    NaN   \n",
       "4788264                    NaN                    NaN                    NaN   \n",
       "4788265                    NaN                    NaN                    NaN   \n",
       "4788266                    NaN                    NaN                    NaN   \n",
       "\n",
       "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
       "4788262                    NaN                     NaN                    NaN   \n",
       "4788263                    NaN                     NaN                    NaN   \n",
       "4788264                    NaN                     NaN                    NaN   \n",
       "4788265                    NaN                     NaN                    NaN   \n",
       "4788266                    NaN                     NaN                    NaN   \n",
       "\n",
       "        rolling_mean_tmp_14_60  \n",
       "4788262                    NaN  \n",
       "4788263                    NaN  \n",
       "4788264                    NaN  \n",
       "4788265                    NaN  \n",
       "4788266                    NaN  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id',\n",
       " 'dept_id',\n",
       " 'cat_id',\n",
       " 'release',\n",
       " 'sell_price',\n",
       " 'price_max',\n",
       " 'price_min',\n",
       " 'price_std',\n",
       " 'price_mean',\n",
       " 'price_norm',\n",
       " 'price_nunique',\n",
       " 'item_nunique',\n",
       " 'price_momentum',\n",
       " 'price_momentum_m',\n",
       " 'price_momentum_y',\n",
       " 'event_name_1',\n",
       " 'event_type_1',\n",
       " 'event_name_2',\n",
       " 'event_type_2',\n",
       " 'snap_CA',\n",
       " 'snap_TX',\n",
       " 'snap_WI',\n",
       " 'tm_d',\n",
       " 'tm_w',\n",
       " 'tm_m',\n",
       " 'tm_y',\n",
       " 'tm_wm',\n",
       " 'tm_dw',\n",
       " 'tm_w_end',\n",
       " 'enc_cat_id_mean',\n",
       " 'enc_cat_id_std',\n",
       " 'enc_dept_id_mean',\n",
       " 'enc_dept_id_std',\n",
       " 'enc_item_id_mean',\n",
       " 'enc_item_id_std',\n",
       " 'sales_lag_28',\n",
       " 'sales_lag_29',\n",
       " 'sales_lag_30',\n",
       " 'sales_lag_31',\n",
       " 'sales_lag_32',\n",
       " 'sales_lag_33',\n",
       " 'sales_lag_34',\n",
       " 'sales_lag_35',\n",
       " 'sales_lag_36',\n",
       " 'sales_lag_37',\n",
       " 'sales_lag_38',\n",
       " 'sales_lag_39',\n",
       " 'sales_lag_40',\n",
       " 'sales_lag_41',\n",
       " 'sales_lag_42',\n",
       " 'rolling_mean_7',\n",
       " 'rolling_std_7',\n",
       " 'rolling_mean_14',\n",
       " 'rolling_std_14',\n",
       " 'rolling_mean_30',\n",
       " 'rolling_std_30',\n",
       " 'rolling_mean_60',\n",
       " 'rolling_std_60',\n",
       " 'rolling_mean_180',\n",
       " 'rolling_std_180',\n",
       " 'rolling_mean_tmp_1_7',\n",
       " 'rolling_mean_tmp_1_14',\n",
       " 'rolling_mean_tmp_1_30',\n",
       " 'rolling_mean_tmp_1_60',\n",
       " 'rolling_mean_tmp_7_7',\n",
       " 'rolling_mean_tmp_7_14',\n",
       " 'rolling_mean_tmp_7_30',\n",
       " 'rolling_mean_tmp_7_60',\n",
       " 'rolling_mean_tmp_14_7',\n",
       " 'rolling_mean_tmp_14_14',\n",
       " 'rolling_mean_tmp_14_30',\n",
       " 'rolling_mean_tmp_14_60']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1885"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "END_TRAIN-P_HORIZON #1913-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "END_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4617523, 72)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df[train_mask][features_columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4617523,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df[train_mask][TARGET].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85372, 72)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df[valid_mask][features_columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85372,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df[valid_mask][TARGET].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    tweedie_variance_power,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': tweedie_variance_power,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9),\n",
    "    'tweedie_variance_power': (1, 2),   \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_fraction', 'bagging_freq', 'colsample_bytree', 'max_bin', 'max_depth', 'min_data_in_leaf', 'min_split_gain', 'num_leaves', 'reg_alpha', 'reg_lambda', 'tweedie_variance_power']\n"
     ]
    }
   ],
   "source": [
    "print(LGB_BO.space.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_points = 3\n",
    "n_iter = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... | tweedi... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.96584\tvalid_1's rmse: 2.17239\n",
      "[200]\ttraining's rmse: 2.69563\tvalid_1's rmse: 2.05824\n",
      "[300]\ttraining's rmse: 2.60735\tvalid_1's rmse: 2.04816\n",
      "[400]\ttraining's rmse: 2.5637\tvalid_1's rmse: 2.04004\n",
      "[500]\ttraining's rmse: 2.53777\tvalid_1's rmse: 2.03699\n",
      "Early stopping, best iteration is:\n",
      "[457]\ttraining's rmse: 2.54956\tvalid_1's rmse: 2.03638\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.036   \u001b[0m | \u001b[0m 0.3492  \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 0.1043  \u001b[0m | \u001b[0m 183.1   \u001b[0m | \u001b[0m-0.05503 \u001b[0m | \u001b[0m 3.725e+0\u001b[0m | \u001b[0m 0.2304  \u001b[0m | \u001b[0m 1.266e+0\u001b[0m | \u001b[0m 0.3575  \u001b[0m | \u001b[0m 0.6701  \u001b[0m | \u001b[0m 1.436   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.84279\tvalid_1's rmse: 2.11638\n",
      "[200]\ttraining's rmse: 2.57737\tvalid_1's rmse: 2.03615\n",
      "[300]\ttraining's rmse: 2.51892\tvalid_1's rmse: 2.03451\n",
      "[400]\ttraining's rmse: 2.49296\tvalid_1's rmse: 2.0326\n",
      "[500]\ttraining's rmse: 2.47428\tvalid_1's rmse: 2.0298\n",
      "[600]\ttraining's rmse: 2.46253\tvalid_1's rmse: 2.02776\n",
      "[700]\ttraining's rmse: 2.45408\tvalid_1's rmse: 2.02796\n",
      "Early stopping, best iteration is:\n",
      "[646]\ttraining's rmse: 2.45856\tvalid_1's rmse: 2.02664\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.027   \u001b[0m | \u001b[95m 0.8073  \u001b[0m | \u001b[95m 10.12   \u001b[0m | \u001b[95m 0.2149  \u001b[0m | \u001b[95m 126.4   \u001b[0m | \u001b[95m 11.24   \u001b[0m | \u001b[95m 5.371e+0\u001b[0m | \u001b[95m 0.6843  \u001b[0m | \u001b[95m 2.372e+0\u001b[0m | \u001b[95m 0.2908  \u001b[0m | \u001b[95m 0.6511  \u001b[0m | \u001b[95m 1.454   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.82312\tvalid_1's rmse: 2.1085\n",
      "[200]\ttraining's rmse: 2.57234\tvalid_1's rmse: 2.04497\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's rmse: 2.61061\tvalid_1's rmse: 2.04207\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.042   \u001b[0m | \u001b[0m 0.5063  \u001b[0m | \u001b[0m 8.407   \u001b[0m | \u001b[0m 0.3578  \u001b[0m | \u001b[0m 243.4   \u001b[0m | \u001b[0m 8.876   \u001b[0m | \u001b[0m 4.53e+03\u001b[0m | \u001b[0m 0.4649  \u001b[0m | \u001b[0m 2.159e+0\u001b[0m | \u001b[0m 0.1347  \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 1.458   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.38269\tvalid_1's rmse: 2.47321\n",
      "[200]\ttraining's rmse: 2.94504\tvalid_1's rmse: 2.17218\n",
      "[300]\ttraining's rmse: 2.79557\tvalid_1's rmse: 2.09977\n",
      "[400]\ttraining's rmse: 2.71909\tvalid_1's rmse: 2.07641\n",
      "[500]\ttraining's rmse: 2.68043\tvalid_1's rmse: 2.07932\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttraining's rmse: 2.70608\tvalid_1's rmse: 2.07481\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.075   \u001b[0m | \u001b[0m 0.4812  \u001b[0m | \u001b[0m 17.12   \u001b[0m | \u001b[0m 0.7907  \u001b[0m | \u001b[0m 260.1   \u001b[0m | \u001b[0m 2.903   \u001b[0m | \u001b[0m 5.98e+03\u001b[0m | \u001b[0m 0.7716  \u001b[0m | \u001b[0m 1.016e+0\u001b[0m | \u001b[0m 0.1908  \u001b[0m | \u001b[0m 0.9285  \u001b[0m | \u001b[0m 1.716   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.07521\tvalid_1's rmse: 2.27192\n",
      "[200]\ttraining's rmse: 2.69093\tvalid_1's rmse: 2.05586\n",
      "[300]\ttraining's rmse: 2.60684\tvalid_1's rmse: 2.04988\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttraining's rmse: 2.63378\tvalid_1's rmse: 2.04665\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.047   \u001b[0m | \u001b[0m 0.7764  \u001b[0m | \u001b[0m 17.13   \u001b[0m | \u001b[0m 0.3246  \u001b[0m | \u001b[0m 102.3   \u001b[0m | \u001b[0m 3.337   \u001b[0m | \u001b[0m 3.02e+03\u001b[0m | \u001b[0m 0.1325  \u001b[0m | \u001b[0m 2.958e+0\u001b[0m | \u001b[0m 0.9877  \u001b[0m | \u001b[0m 0.925   \u001b[0m | \u001b[0m 1.618   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.87516\tvalid_1's rmse: 2.85783\n",
      "[200]\ttraining's rmse: 3.39025\tvalid_1's rmse: 2.46195\n",
      "[300]\ttraining's rmse: 3.15085\tvalid_1's rmse: 2.29816\n",
      "[400]\ttraining's rmse: 3.01719\tvalid_1's rmse: 2.21715\n",
      "[500]\ttraining's rmse: 2.91921\tvalid_1's rmse: 2.16691\n",
      "[600]\ttraining's rmse: 2.8582\tvalid_1's rmse: 2.13983\n",
      "[700]\ttraining's rmse: 2.80881\tvalid_1's rmse: 2.12347\n",
      "[800]\ttraining's rmse: 2.781\tvalid_1's rmse: 2.11845\n",
      "Early stopping, best iteration is:\n",
      "[793]\ttraining's rmse: 2.78134\tvalid_1's rmse: 2.11833\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.118   \u001b[0m | \u001b[0m 0.5918  \u001b[0m | \u001b[0m 13.01   \u001b[0m | \u001b[0m 0.4537  \u001b[0m | \u001b[0m 275.8   \u001b[0m | \u001b[0m 1.422   \u001b[0m | \u001b[0m 5.994e+0\u001b[0m | \u001b[0m 0.7013  \u001b[0m | \u001b[0m 2.992e+0\u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 0.8114  \u001b[0m | \u001b[0m 1.799   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.41379\tvalid_1's rmse: 2.49118\n",
      "[200]\ttraining's rmse: 2.69063\tvalid_1's rmse: 2.05187\n",
      "[300]\ttraining's rmse: 2.56429\tvalid_1's rmse: 2.04059\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttraining's rmse: 2.60402\tvalid_1's rmse: 2.03859\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.039   \u001b[0m | \u001b[0m 0.7102  \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 0.2944  \u001b[0m | \u001b[0m 101.2   \u001b[0m | \u001b[0m 0.1693  \u001b[0m | \u001b[0m 4.831e+0\u001b[0m | \u001b[0m 0.6229  \u001b[0m | \u001b[0m 1.013e+0\u001b[0m | \u001b[0m 0.7093  \u001b[0m | \u001b[0m 0.725   \u001b[0m | \u001b[0m 1.97    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.63647\tvalid_1's rmse: 2.05741\n",
      "[200]\ttraining's rmse: 2.48516\tvalid_1's rmse: 2.03147\n",
      "[300]\ttraining's rmse: 2.47254\tvalid_1's rmse: 2.02968\n",
      "[400]\ttraining's rmse: 2.46572\tvalid_1's rmse: 2.02904\n",
      "[500]\ttraining's rmse: 2.46076\tvalid_1's rmse: 2.02853\n",
      "[600]\ttraining's rmse: 2.4578\tvalid_1's rmse: 2.0282\n",
      "[700]\ttraining's rmse: 2.45372\tvalid_1's rmse: 2.02717\n",
      "[800]\ttraining's rmse: 2.44973\tvalid_1's rmse: 2.02654\n",
      "[900]\ttraining's rmse: 2.4462\tvalid_1's rmse: 2.02562\n",
      "[1000]\ttraining's rmse: 2.44363\tvalid_1's rmse: 2.02526\n",
      "[1100]\ttraining's rmse: 2.44119\tvalid_1's rmse: 2.02471\n",
      "[1200]\ttraining's rmse: 2.43843\tvalid_1's rmse: 2.0244\n",
      "[1300]\ttraining's rmse: 2.43579\tvalid_1's rmse: 2.02403\n",
      "Early stopping, best iteration is:\n",
      "[1214]\ttraining's rmse: 2.43742\tvalid_1's rmse: 2.024\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-2.024   \u001b[0m | \u001b[95m 0.8807  \u001b[0m | \u001b[95m 3.052   \u001b[0m | \u001b[95m 0.8889  \u001b[0m | \u001b[95m 115.7   \u001b[0m | \u001b[95m 7.263   \u001b[0m | \u001b[95m 3.016e+0\u001b[0m | \u001b[95m 0.7596  \u001b[0m | \u001b[95m 1.018e+0\u001b[0m | \u001b[95m 0.7816  \u001b[0m | \u001b[95m 0.5243  \u001b[0m | \u001b[95m 1.345   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.03553\tvalid_1's rmse: 2.23753\n",
      "[200]\ttraining's rmse: 2.59622\tvalid_1's rmse: 2.036\n",
      "[300]\ttraining's rmse: 2.53194\tvalid_1's rmse: 2.03204\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's rmse: 2.53322\tvalid_1's rmse: 2.03151\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.032   \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 1.854   \u001b[0m | \u001b[0m 0.1907  \u001b[0m | \u001b[0m 101.1   \u001b[0m | \u001b[0m 11.02   \u001b[0m | \u001b[0m 3.05e+03\u001b[0m | \u001b[0m 0.1744  \u001b[0m | \u001b[0m 1.958e+0\u001b[0m | \u001b[0m 0.2179  \u001b[0m | \u001b[0m 0.2125  \u001b[0m | \u001b[0m 1.649   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.13239\tvalid_1's rmse: 2.30413\n",
      "[200]\ttraining's rmse: 2.6289\tvalid_1's rmse: 2.04417\n",
      "[300]\ttraining's rmse: 2.56827\tvalid_1's rmse: 2.0564\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's rmse: 2.6174\tvalid_1's rmse: 2.04343\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.043   \u001b[0m | \u001b[0m 0.7885  \u001b[0m | \u001b[0m 7.375   \u001b[0m | \u001b[0m 0.485   \u001b[0m | \u001b[0m 100.4   \u001b[0m | \u001b[0m 5.954   \u001b[0m | \u001b[0m 4.409e+0\u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 2.977e+0\u001b[0m | \u001b[0m 0.2976  \u001b[0m | \u001b[0m 0.6733  \u001b[0m | \u001b[0m 1.752   \u001b[0m |\n",
      "=============================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... | tweedi... |\n",
    "|  8        | -2.024    |  0.8807   |  3.052    |  0.8889   |  115.7    |  7.263    |  3.016e+0 |  0.7596   |  1.018e+0 |  0.7816   |  0.5243   |  1.345    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, valid_data, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.345,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.8807,\n",
    "                    'subsample_freq': 3,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1018, \n",
    "                    'min_data_in_leaf': 3016, \n",
    "                    'feature_fraction': 0.8889,\n",
    "                    'max_bin': 115,\n",
    "                    'n_estimators': 1300,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':7,\n",
    "                    'min_split_gain':0.7596,\n",
    "                    'reg_alpha':0.7816,\n",
    "                    'reg_lambda':0.5243,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.05702\n",
      "[200]\tvalid_0's rmse: 2.02822\n",
      "[300]\tvalid_0's rmse: 2.02647\n",
      "[400]\tvalid_0's rmse: 2.02562\n",
      "[500]\tvalid_0's rmse: 2.02493\n",
      "[600]\tvalid_0's rmse: 2.02443\n",
      "[700]\tvalid_0's rmse: 2.02385\n",
      "[800]\tvalid_0's rmse: 2.02292\n",
      "[900]\tvalid_0's rmse: 2.02236\n",
      "[1000]\tvalid_0's rmse: 2.02229\n",
      "[1100]\tvalid_0's rmse: 2.02208\n",
      "[1200]\tvalid_0's rmse: 2.02166\n",
      "[1300]\tvalid_0's rmse: 2.02141\n"
     ]
    }
   ],
   "source": [
    "store_id = 'CA_1'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.93576\n",
    "#100: 2.02701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4361148 entries, 0 to 4361147\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 582.5 MB\n",
      "None\n",
      "(4190404, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# CA_2\n",
    "grid_df, features_columns = get_data_by_store('CA_2')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_fraction', 'bagging_freq', 'colsample_bytree', 'max_bin', 'max_depth', 'min_data_in_leaf', 'min_split_gain', 'num_leaves', 'reg_alpha', 'reg_lambda']\n"
     ]
    }
   ],
   "source": [
    "print(LGB_BO.space.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.16031\tvalid_1's rmse: 2.00461\n",
      "[200]\ttraining's rmse: 2.09438\tvalid_1's rmse: 1.92762\n",
      "[300]\ttraining's rmse: 2.06843\tvalid_1's rmse: 1.90423\n",
      "[400]\ttraining's rmse: 2.05283\tvalid_1's rmse: 1.89178\n",
      "[500]\ttraining's rmse: 2.04255\tvalid_1's rmse: 1.88507\n",
      "[600]\ttraining's rmse: 2.03561\tvalid_1's rmse: 1.88174\n",
      "[700]\ttraining's rmse: 2.02934\tvalid_1's rmse: 1.87792\n",
      "[800]\ttraining's rmse: 2.02377\tvalid_1's rmse: 1.87501\n",
      "[900]\ttraining's rmse: 2.01995\tvalid_1's rmse: 1.87264\n",
      "[1000]\ttraining's rmse: 2.0158\tvalid_1's rmse: 1.87026\n",
      "[1100]\ttraining's rmse: 2.01257\tvalid_1's rmse: 1.86884\n",
      "[1200]\ttraining's rmse: 2.00973\tvalid_1's rmse: 1.86751\n",
      "[1300]\ttraining's rmse: 2.00722\tvalid_1's rmse: 1.8661\n",
      "[1400]\ttraining's rmse: 2.00476\tvalid_1's rmse: 1.86474\n",
      "[1500]\ttraining's rmse: 2.00285\tvalid_1's rmse: 1.86379\n",
      "[1600]\ttraining's rmse: 2.00026\tvalid_1's rmse: 1.8629\n",
      "[1700]\ttraining's rmse: 1.99821\tvalid_1's rmse: 1.86197\n",
      "[1800]\ttraining's rmse: 1.99621\tvalid_1's rmse: 1.86116\n",
      "[1900]\ttraining's rmse: 1.99452\tvalid_1's rmse: 1.8607\n",
      "[2000]\ttraining's rmse: 1.99291\tvalid_1's rmse: 1.86017\n",
      "[2100]\ttraining's rmse: 1.99125\tvalid_1's rmse: 1.85946\n",
      "[2200]\ttraining's rmse: 1.98965\tvalid_1's rmse: 1.85901\n",
      "[2300]\ttraining's rmse: 1.98824\tvalid_1's rmse: 1.85848\n",
      "[2400]\ttraining's rmse: 1.98675\tvalid_1's rmse: 1.85787\n",
      "[2500]\ttraining's rmse: 1.98525\tvalid_1's rmse: 1.85751\n",
      "Early stopping, best iteration is:\n",
      "[2495]\ttraining's rmse: 1.98531\tvalid_1's rmse: 1.85744\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.857   \u001b[0m | \u001b[0m 0.2964  \u001b[0m | \u001b[0m 6.889   \u001b[0m | \u001b[0m 0.1193  \u001b[0m | \u001b[0m 174.8   \u001b[0m | \u001b[0m 10.82   \u001b[0m | \u001b[0m 4.116e+0\u001b[0m | \u001b[0m 0.8545  \u001b[0m | \u001b[0m 1.045e+0\u001b[0m | \u001b[0m 0.242   \u001b[0m | \u001b[0m 0.2271  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.18442\tvalid_1's rmse: 2.05301\n",
      "[200]\ttraining's rmse: 2.09397\tvalid_1's rmse: 1.93458\n",
      "[300]\ttraining's rmse: 2.07282\tvalid_1's rmse: 1.90597\n",
      "[400]\ttraining's rmse: 2.06528\tvalid_1's rmse: 1.89961\n",
      "[500]\ttraining's rmse: 2.06138\tvalid_1's rmse: 1.89624\n",
      "[600]\ttraining's rmse: 2.05754\tvalid_1's rmse: 1.89169\n",
      "[700]\ttraining's rmse: 2.05611\tvalid_1's rmse: 1.89068\n",
      "[800]\ttraining's rmse: 2.05473\tvalid_1's rmse: 1.88956\n",
      "[900]\ttraining's rmse: 2.05355\tvalid_1's rmse: 1.88894\n",
      "[1000]\ttraining's rmse: 2.05258\tvalid_1's rmse: 1.88784\n",
      "[1100]\ttraining's rmse: 2.05117\tvalid_1's rmse: 1.88622\n",
      "[1200]\ttraining's rmse: 2.05003\tvalid_1's rmse: 1.8855\n",
      "[1300]\ttraining's rmse: 2.04911\tvalid_1's rmse: 1.88474\n",
      "[1400]\ttraining's rmse: 2.04807\tvalid_1's rmse: 1.88434\n",
      "[1500]\ttraining's rmse: 2.0473\tvalid_1's rmse: 1.88404\n",
      "[1600]\ttraining's rmse: 2.04667\tvalid_1's rmse: 1.88348\n",
      "[1700]\ttraining's rmse: 2.04587\tvalid_1's rmse: 1.88305\n",
      "[1800]\ttraining's rmse: 2.04488\tvalid_1's rmse: 1.8823\n",
      "[1900]\ttraining's rmse: 2.04418\tvalid_1's rmse: 1.88146\n",
      "[2000]\ttraining's rmse: 2.04334\tvalid_1's rmse: 1.88118\n",
      "[2100]\ttraining's rmse: 2.04252\tvalid_1's rmse: 1.8809\n",
      "[2200]\ttraining's rmse: 2.04212\tvalid_1's rmse: 1.8802\n",
      "[2300]\ttraining's rmse: 2.0414\tvalid_1's rmse: 1.87968\n",
      "[2400]\ttraining's rmse: 2.04071\tvalid_1's rmse: 1.87938\n",
      "[2500]\ttraining's rmse: 2.04043\tvalid_1's rmse: 1.87887\n",
      "[2600]\ttraining's rmse: 2.03971\tvalid_1's rmse: 1.87867\n",
      "Early stopping, best iteration is:\n",
      "[2594]\ttraining's rmse: 2.03974\tvalid_1's rmse: 1.87858\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.879   \u001b[0m | \u001b[0m 0.2657  \u001b[0m | \u001b[0m 4.334   \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 121.0   \u001b[0m | \u001b[0m 2.798   \u001b[0m | \u001b[0m 5.172e+0\u001b[0m | \u001b[0m 0.1129  \u001b[0m | \u001b[0m 2.723e+0\u001b[0m | \u001b[0m 0.1856  \u001b[0m | \u001b[0m 0.7739  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.13673\tvalid_1's rmse: 1.99739\n",
      "[200]\ttraining's rmse: 2.08009\tvalid_1's rmse: 1.92503\n",
      "[300]\ttraining's rmse: 2.06085\tvalid_1's rmse: 1.90545\n",
      "[400]\ttraining's rmse: 2.05056\tvalid_1's rmse: 1.89317\n",
      "[500]\ttraining's rmse: 2.04359\tvalid_1's rmse: 1.88593\n",
      "[600]\ttraining's rmse: 2.03884\tvalid_1's rmse: 1.88068\n",
      "[700]\ttraining's rmse: 2.03497\tvalid_1's rmse: 1.87644\n",
      "[800]\ttraining's rmse: 2.03233\tvalid_1's rmse: 1.87378\n",
      "[900]\ttraining's rmse: 2.02962\tvalid_1's rmse: 1.87216\n",
      "[1000]\ttraining's rmse: 2.0275\tvalid_1's rmse: 1.87052\n",
      "[1100]\ttraining's rmse: 2.02531\tvalid_1's rmse: 1.86993\n",
      "[1200]\ttraining's rmse: 2.02367\tvalid_1's rmse: 1.8684\n",
      "[1300]\ttraining's rmse: 2.02169\tvalid_1's rmse: 1.86681\n",
      "[1400]\ttraining's rmse: 2.02053\tvalid_1's rmse: 1.86655\n",
      "[1500]\ttraining's rmse: 2.01944\tvalid_1's rmse: 1.86617\n",
      "Early stopping, best iteration is:\n",
      "[1478]\ttraining's rmse: 2.01968\tvalid_1's rmse: 1.86588\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.866   \u001b[0m | \u001b[0m 0.1179  \u001b[0m | \u001b[0m 7.575   \u001b[0m | \u001b[0m 0.7764  \u001b[0m | \u001b[0m 135.9   \u001b[0m | \u001b[0m 9.544   \u001b[0m | \u001b[0m 5.679e+0\u001b[0m | \u001b[0m 0.8521  \u001b[0m | \u001b[0m 1.606e+0\u001b[0m | \u001b[0m 0.7689  \u001b[0m | \u001b[0m 0.34    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.39198\tvalid_1's rmse: 2.29615\n",
      "[200]\ttraining's rmse: 2.20326\tvalid_1's rmse: 2.06745\n",
      "[300]\ttraining's rmse: 2.13103\tvalid_1's rmse: 1.96985\n",
      "[400]\ttraining's rmse: 2.10405\tvalid_1's rmse: 1.93464\n",
      "[500]\ttraining's rmse: 2.09453\tvalid_1's rmse: 1.92353\n",
      "[600]\ttraining's rmse: 2.08631\tvalid_1's rmse: 1.91277\n",
      "[700]\ttraining's rmse: 2.08051\tvalid_1's rmse: 1.90411\n",
      "[800]\ttraining's rmse: 2.07724\tvalid_1's rmse: 1.901\n",
      "[900]\ttraining's rmse: 2.07336\tvalid_1's rmse: 1.8972\n",
      "[1000]\ttraining's rmse: 2.07148\tvalid_1's rmse: 1.8957\n",
      "[1100]\ttraining's rmse: 2.06994\tvalid_1's rmse: 1.89448\n",
      "[1200]\ttraining's rmse: 2.06867\tvalid_1's rmse: 1.89317\n",
      "[1300]\ttraining's rmse: 2.06715\tvalid_1's rmse: 1.89119\n",
      "[1400]\ttraining's rmse: 2.06615\tvalid_1's rmse: 1.89064\n",
      "[1500]\ttraining's rmse: 2.06574\tvalid_1's rmse: 1.89049\n",
      "[1600]\ttraining's rmse: 2.06469\tvalid_1's rmse: 1.88938\n",
      "[1700]\ttraining's rmse: 2.06384\tvalid_1's rmse: 1.88879\n",
      "[1800]\ttraining's rmse: 2.06343\tvalid_1's rmse: 1.88875\n",
      "[1900]\ttraining's rmse: 2.06226\tvalid_1's rmse: 1.88725\n",
      "[2000]\ttraining's rmse: 2.06161\tvalid_1's rmse: 1.88687\n",
      "Early stopping, best iteration is:\n",
      "[1918]\ttraining's rmse: 2.06199\tvalid_1's rmse: 1.88683\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.887   \u001b[0m | \u001b[0m 0.3658  \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 0.2599  \u001b[0m | \u001b[0m 282.9   \u001b[0m | \u001b[0m 1.442   \u001b[0m | \u001b[0m 3.01e+03\u001b[0m | \u001b[0m 0.6518  \u001b[0m | \u001b[0m 1.003e+0\u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 0.4162  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.04211\tvalid_1's rmse: 1.89413\n",
      "[200]\ttraining's rmse: 2.02107\tvalid_1's rmse: 1.87209\n",
      "[300]\ttraining's rmse: 2.01535\tvalid_1's rmse: 1.87002\n",
      "[400]\ttraining's rmse: 2.01177\tvalid_1's rmse: 1.8698\n",
      "[500]\ttraining's rmse: 2.00844\tvalid_1's rmse: 1.87058\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's rmse: 2.01165\tvalid_1's rmse: 1.86979\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.87    \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 0.8812  \u001b[0m | \u001b[0m 108.0   \u001b[0m | \u001b[0m 6.006   \u001b[0m | \u001b[0m 3.015e+0\u001b[0m | \u001b[0m 0.6036  \u001b[0m | \u001b[0m 2.985e+0\u001b[0m | \u001b[0m 0.273   \u001b[0m | \u001b[0m 0.9301  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.11646\tvalid_1's rmse: 1.95831\n",
      "[200]\ttraining's rmse: 2.05574\tvalid_1's rmse: 1.89544\n",
      "[300]\ttraining's rmse: 2.03242\tvalid_1's rmse: 1.88097\n",
      "[400]\ttraining's rmse: 2.01836\tvalid_1's rmse: 1.87536\n",
      "[500]\ttraining's rmse: 2.00749\tvalid_1's rmse: 1.87056\n",
      "[600]\ttraining's rmse: 1.99959\tvalid_1's rmse: 1.86714\n",
      "[700]\ttraining's rmse: 1.99251\tvalid_1's rmse: 1.86388\n",
      "[800]\ttraining's rmse: 1.98616\tvalid_1's rmse: 1.86271\n",
      "[900]\ttraining's rmse: 1.98107\tvalid_1's rmse: 1.86148\n",
      "[1000]\ttraining's rmse: 1.97602\tvalid_1's rmse: 1.86024\n",
      "[1100]\ttraining's rmse: 1.97146\tvalid_1's rmse: 1.85974\n",
      "[1200]\ttraining's rmse: 1.9671\tvalid_1's rmse: 1.85865\n",
      "[1300]\ttraining's rmse: 1.96306\tvalid_1's rmse: 1.85759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 1.95906\tvalid_1's rmse: 1.85692\n",
      "[1500]\ttraining's rmse: 1.95566\tvalid_1's rmse: 1.85686\n",
      "[1600]\ttraining's rmse: 1.95211\tvalid_1's rmse: 1.85628\n",
      "[1700]\ttraining's rmse: 1.94847\tvalid_1's rmse: 1.85649\n",
      "Early stopping, best iteration is:\n",
      "[1643]\ttraining's rmse: 1.95055\tvalid_1's rmse: 1.85621\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-1.856   \u001b[0m | \u001b[95m 0.5212  \u001b[0m | \u001b[95m 5.112   \u001b[0m | \u001b[95m 0.1614  \u001b[0m | \u001b[95m 298.3   \u001b[0m | \u001b[95m 0.3673  \u001b[0m | \u001b[95m 5.096e+0\u001b[0m | \u001b[95m 0.7937  \u001b[0m | \u001b[95m 1.014e+0\u001b[0m | \u001b[95m 0.2466  \u001b[0m | \u001b[95m 0.8621  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.10025\tvalid_1's rmse: 1.95437\n",
      "[200]\ttraining's rmse: 2.05984\tvalid_1's rmse: 1.89991\n",
      "[300]\ttraining's rmse: 2.05205\tvalid_1's rmse: 1.89198\n",
      "[400]\ttraining's rmse: 2.04626\tvalid_1's rmse: 1.88706\n",
      "[500]\ttraining's rmse: 2.04215\tvalid_1's rmse: 1.8846\n",
      "[600]\ttraining's rmse: 2.03963\tvalid_1's rmse: 1.88193\n",
      "[700]\ttraining's rmse: 2.03716\tvalid_1's rmse: 1.87959\n",
      "[800]\ttraining's rmse: 2.03408\tvalid_1's rmse: 1.87762\n",
      "[900]\ttraining's rmse: 2.03287\tvalid_1's rmse: 1.87618\n",
      "[1000]\ttraining's rmse: 2.0314\tvalid_1's rmse: 1.87475\n",
      "[1100]\ttraining's rmse: 2.03015\tvalid_1's rmse: 1.87482\n",
      "[1200]\ttraining's rmse: 2.02858\tvalid_1's rmse: 1.87379\n",
      "[1300]\ttraining's rmse: 2.02713\tvalid_1's rmse: 1.87363\n",
      "[1400]\ttraining's rmse: 2.02635\tvalid_1's rmse: 1.87138\n",
      "[1500]\ttraining's rmse: 2.02548\tvalid_1's rmse: 1.87148\n",
      "[1600]\ttraining's rmse: 2.02424\tvalid_1's rmse: 1.87047\n",
      "[1700]\ttraining's rmse: 2.02326\tvalid_1's rmse: 1.86989\n",
      "[1800]\ttraining's rmse: 2.02233\tvalid_1's rmse: 1.86884\n",
      "[1900]\ttraining's rmse: 2.02125\tvalid_1's rmse: 1.86844\n",
      "[2000]\ttraining's rmse: 2.02074\tvalid_1's rmse: 1.86831\n",
      "[2100]\ttraining's rmse: 2.02004\tvalid_1's rmse: 1.86815\n",
      "[2200]\ttraining's rmse: 2.01896\tvalid_1's rmse: 1.86748\n",
      "[2300]\ttraining's rmse: 2.01841\tvalid_1's rmse: 1.86713\n",
      "[2400]\ttraining's rmse: 2.01754\tvalid_1's rmse: 1.86743\n",
      "Early stopping, best iteration is:\n",
      "[2305]\ttraining's rmse: 2.01837\tvalid_1's rmse: 1.86711\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.867   \u001b[0m | \u001b[0m 0.2234  \u001b[0m | \u001b[0m 5.834   \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 104.9   \u001b[0m | \u001b[0m 7.806   \u001b[0m | \u001b[0m 5.973e+0\u001b[0m | \u001b[0m 0.1987  \u001b[0m | \u001b[0m 1.006e+0\u001b[0m | \u001b[0m 0.4401  \u001b[0m | \u001b[0m 0.906   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.08734\tvalid_1's rmse: 1.9415\n",
      "[200]\ttraining's rmse: 2.05187\tvalid_1's rmse: 1.89942\n",
      "[300]\ttraining's rmse: 2.04654\tvalid_1's rmse: 1.89357\n",
      "[400]\ttraining's rmse: 2.0422\tvalid_1's rmse: 1.88995\n",
      "[500]\ttraining's rmse: 2.03942\tvalid_1's rmse: 1.88931\n",
      "[600]\ttraining's rmse: 2.03757\tvalid_1's rmse: 1.88658\n",
      "[700]\ttraining's rmse: 2.03619\tvalid_1's rmse: 1.8864\n",
      "[800]\ttraining's rmse: 2.03395\tvalid_1's rmse: 1.88539\n",
      "[900]\ttraining's rmse: 2.03321\tvalid_1's rmse: 1.88513\n",
      "[1000]\ttraining's rmse: 2.0321\tvalid_1's rmse: 1.88367\n",
      "[1100]\ttraining's rmse: 2.03093\tvalid_1's rmse: 1.88244\n",
      "[1200]\ttraining's rmse: 2.02973\tvalid_1's rmse: 1.88157\n",
      "[1300]\ttraining's rmse: 2.02853\tvalid_1's rmse: 1.88098\n",
      "[1400]\ttraining's rmse: 2.02738\tvalid_1's rmse: 1.87909\n",
      "[1500]\ttraining's rmse: 2.02674\tvalid_1's rmse: 1.87892\n",
      "[1600]\ttraining's rmse: 2.02541\tvalid_1's rmse: 1.87899\n",
      "Early stopping, best iteration is:\n",
      "[1590]\ttraining's rmse: 2.02556\tvalid_1's rmse: 1.87837\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.878   \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 6.28    \u001b[0m | \u001b[0m 0.894   \u001b[0m | \u001b[0m 299.1   \u001b[0m | \u001b[0m 10.58   \u001b[0m | \u001b[0m 4.086e+0\u001b[0m | \u001b[0m 0.7386  \u001b[0m | \u001b[0m 1.963e+0\u001b[0m | \u001b[0m 0.3078  \u001b[0m | \u001b[0m 0.8197  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.12149\tvalid_1's rmse: 1.97643\n",
      "[200]\ttraining's rmse: 2.07651\tvalid_1's rmse: 1.91649\n",
      "[300]\ttraining's rmse: 2.0635\tvalid_1's rmse: 1.90234\n",
      "[400]\ttraining's rmse: 2.05276\tvalid_1's rmse: 1.89142\n",
      "[500]\ttraining's rmse: 2.0472\tvalid_1's rmse: 1.88633\n",
      "[600]\ttraining's rmse: 2.04152\tvalid_1's rmse: 1.88183\n",
      "[700]\ttraining's rmse: 2.03883\tvalid_1's rmse: 1.88087\n",
      "Early stopping, best iteration is:\n",
      "[626]\ttraining's rmse: 2.04018\tvalid_1's rmse: 1.88008\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.88    \u001b[0m | \u001b[0m 0.1393  \u001b[0m | \u001b[0m 18.83   \u001b[0m | \u001b[0m 0.6853  \u001b[0m | \u001b[0m 100.1   \u001b[0m | \u001b[0m 5.106   \u001b[0m | \u001b[0m 4.941e+0\u001b[0m | \u001b[0m 0.6823  \u001b[0m | \u001b[0m 1.034e+0\u001b[0m | \u001b[0m 0.6781  \u001b[0m | \u001b[0m 0.8299  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.13121\tvalid_1's rmse: 1.97396\n",
      "[200]\ttraining's rmse: 2.08158\tvalid_1's rmse: 1.91624\n",
      "[300]\ttraining's rmse: 2.06226\tvalid_1's rmse: 1.90075\n",
      "[400]\ttraining's rmse: 2.05113\tvalid_1's rmse: 1.89299\n",
      "[500]\ttraining's rmse: 2.04217\tvalid_1's rmse: 1.88382\n",
      "[600]\ttraining's rmse: 2.03645\tvalid_1's rmse: 1.87905\n",
      "[700]\ttraining's rmse: 2.03168\tvalid_1's rmse: 1.87521\n",
      "[800]\ttraining's rmse: 2.02772\tvalid_1's rmse: 1.87283\n",
      "[900]\ttraining's rmse: 2.02436\tvalid_1's rmse: 1.87083\n",
      "[1000]\ttraining's rmse: 2.02145\tvalid_1's rmse: 1.86886\n",
      "[1100]\ttraining's rmse: 2.01822\tvalid_1's rmse: 1.86664\n",
      "[1200]\ttraining's rmse: 2.01633\tvalid_1's rmse: 1.86603\n",
      "[1300]\ttraining's rmse: 2.01444\tvalid_1's rmse: 1.86498\n",
      "[1400]\ttraining's rmse: 2.01263\tvalid_1's rmse: 1.86389\n",
      "[1500]\ttraining's rmse: 2.01107\tvalid_1's rmse: 1.86247\n",
      "[1600]\ttraining's rmse: 2.00952\tvalid_1's rmse: 1.86183\n",
      "[1700]\ttraining's rmse: 2.00791\tvalid_1's rmse: 1.86111\n",
      "[1800]\ttraining's rmse: 2.00649\tvalid_1's rmse: 1.86042\n",
      "[1900]\ttraining's rmse: 2.0053\tvalid_1's rmse: 1.85985\n",
      "[2000]\ttraining's rmse: 2.00404\tvalid_1's rmse: 1.8597\n",
      "[2100]\ttraining's rmse: 2.00278\tvalid_1's rmse: 1.8596\n",
      "[2200]\ttraining's rmse: 2.0016\tvalid_1's rmse: 1.85917\n",
      "[2300]\ttraining's rmse: 2.00068\tvalid_1's rmse: 1.85924\n",
      "[2400]\ttraining's rmse: 1.99972\tvalid_1's rmse: 1.85888\n",
      "[2500]\ttraining's rmse: 1.99881\tvalid_1's rmse: 1.85853\n",
      "[2600]\ttraining's rmse: 1.998\tvalid_1's rmse: 1.85851\n",
      "Early stopping, best iteration is:\n",
      "[2550]\ttraining's rmse: 1.99842\tvalid_1's rmse: 1.85846\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.858   \u001b[0m | \u001b[0m 0.5852  \u001b[0m | \u001b[0m 6.783   \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 287.2   \u001b[0m | \u001b[0m 5.267   \u001b[0m | \u001b[0m 5.983e+0\u001b[0m | \u001b[0m 0.8036  \u001b[0m | \u001b[0m 2.982e+0\u001b[0m | \u001b[0m 0.1177  \u001b[0m | \u001b[0m 0.1344  \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
    "------------------------------\n",
    "|  6        | -1.856    |  0.5212   |  5.112    |  0.1614   |  298.3    |  0.3673   |  5.096e+0 |  0.7937   |  1.014e+0 |  0.2466   |  0.8621   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample':  0.5212,\n",
    "                    'subsample_freq': 5,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1014, \n",
    "                    'min_data_in_leaf': 5096, \n",
    "                    'feature_fraction': 0.1614,\n",
    "                    'max_bin': 298,\n",
    "                    'n_estimators': 1700,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':0,\n",
    "                    'min_split_gain':0.7937,\n",
    "                    'reg_alpha':0.2466,\n",
    "                    'reg_lambda':0.8621,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.95079\n",
      "[200]\tvalid_0's rmse: 1.88472\n",
      "[300]\tvalid_0's rmse: 1.86512\n",
      "[400]\tvalid_0's rmse: 1.85509\n",
      "[500]\tvalid_0's rmse: 1.84702\n",
      "[600]\tvalid_0's rmse: 1.8418\n",
      "[700]\tvalid_0's rmse: 1.83643\n",
      "[800]\tvalid_0's rmse: 1.83189\n",
      "[900]\tvalid_0's rmse: 1.82839\n",
      "[1000]\tvalid_0's rmse: 1.82515\n",
      "[1100]\tvalid_0's rmse: 1.82187\n",
      "[1200]\tvalid_0's rmse: 1.81818\n",
      "[1300]\tvalid_0's rmse: 1.81514\n",
      "[1400]\tvalid_0's rmse: 1.81263\n",
      "[1500]\tvalid_0's rmse: 1.81043\n",
      "[1600]\tvalid_0's rmse: 1.80831\n",
      "[1700]\tvalid_0's rmse: 1.80575\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('CA_2')\n",
    "store_id = 'CA_2'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.78449\n",
    "#100:1.89284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4757313 entries, 0 to 4757312\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 635.4 MB\n",
      "None\n",
      "(4586569, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('CA_3')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_fraction', 'bagging_freq', 'colsample_bytree', 'max_bin', 'max_depth', 'min_data_in_leaf', 'min_split_gain', 'num_leaves', 'reg_alpha', 'reg_lambda']\n"
     ]
    }
   ],
   "source": [
    "print(LGB_BO.space.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.70364\tvalid_1's rmse: 2.55534\n",
      "[200]\ttraining's rmse: 3.51676\tvalid_1's rmse: 2.55846\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's rmse: 3.68429\tvalid_1's rmse: 2.5538\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.554   \u001b[0m | \u001b[0m 0.3714  \u001b[0m | \u001b[0m 10.4    \u001b[0m | \u001b[0m 0.7481  \u001b[0m | \u001b[0m 163.8   \u001b[0m | \u001b[0m 6.045   \u001b[0m | \u001b[0m 3.586e+0\u001b[0m | \u001b[0m 0.1033  \u001b[0m | \u001b[0m 2.709e+0\u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.1662  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.89823\tvalid_1's rmse: 2.57029\n",
      "[200]\ttraining's rmse: 3.63966\tvalid_1's rmse: 2.53175\n",
      "[300]\ttraining's rmse: 3.54274\tvalid_1's rmse: 2.50824\n",
      "[400]\ttraining's rmse: 3.4896\tvalid_1's rmse: 2.49453\n",
      "[500]\ttraining's rmse: 3.44886\tvalid_1's rmse: 2.48743\n",
      "[600]\ttraining's rmse: 3.42527\tvalid_1's rmse: 2.48251\n",
      "[700]\ttraining's rmse: 3.40107\tvalid_1's rmse: 2.4809\n",
      "[800]\ttraining's rmse: 3.38257\tvalid_1's rmse: 2.47667\n",
      "[900]\ttraining's rmse: 3.36178\tvalid_1's rmse: 2.47533\n",
      "[1000]\ttraining's rmse: 3.34365\tvalid_1's rmse: 2.4743\n",
      "[1100]\ttraining's rmse: 3.32646\tvalid_1's rmse: 2.47355\n",
      "Early stopping, best iteration is:\n",
      "[1040]\ttraining's rmse: 3.33597\tvalid_1's rmse: 2.47312\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.473   \u001b[0m | \u001b[95m 0.5576  \u001b[0m | \u001b[95m 12.98   \u001b[0m | \u001b[95m 0.1701  \u001b[0m | \u001b[95m 265.9   \u001b[0m | \u001b[95m 0.4201  \u001b[0m | \u001b[95m 5.695e+0\u001b[0m | \u001b[95m 0.8848  \u001b[0m | \u001b[95m 2.42e+03\u001b[0m | \u001b[95m 0.189   \u001b[0m | \u001b[95m 0.2926  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.66463\tvalid_1's rmse: 2.53263\n",
      "[200]\ttraining's rmse: 3.46528\tvalid_1's rmse: 2.51039\n",
      "[300]\ttraining's rmse: 3.42792\tvalid_1's rmse: 2.4984\n",
      "[400]\ttraining's rmse: 3.4069\tvalid_1's rmse: 2.4853\n",
      "[500]\ttraining's rmse: 3.39104\tvalid_1's rmse: 2.48298\n",
      "[600]\ttraining's rmse: 3.38174\tvalid_1's rmse: 2.48052\n",
      "[700]\ttraining's rmse: 3.37307\tvalid_1's rmse: 2.47665\n",
      "[800]\ttraining's rmse: 3.36677\tvalid_1's rmse: 2.47446\n",
      "[900]\ttraining's rmse: 3.35714\tvalid_1's rmse: 2.47407\n",
      "[1000]\ttraining's rmse: 3.35175\tvalid_1's rmse: 2.47202\n",
      "[1100]\ttraining's rmse: 3.3457\tvalid_1's rmse: 2.47123\n",
      "[1200]\ttraining's rmse: 3.3423\tvalid_1's rmse: 2.46979\n",
      "[1300]\ttraining's rmse: 3.33581\tvalid_1's rmse: 2.46935\n",
      "[1400]\ttraining's rmse: 3.33157\tvalid_1's rmse: 2.46819\n",
      "[1500]\ttraining's rmse: 3.32729\tvalid_1's rmse: 2.46661\n",
      "Early stopping, best iteration is:\n",
      "[1476]\ttraining's rmse: 3.32819\tvalid_1's rmse: 2.4662\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-2.466   \u001b[0m | \u001b[95m 0.485   \u001b[0m | \u001b[95m 12.14   \u001b[0m | \u001b[95m 0.7249  \u001b[0m | \u001b[95m 149.2   \u001b[0m | \u001b[95m 11.45   \u001b[0m | \u001b[95m 4.558e+0\u001b[0m | \u001b[95m 0.4759  \u001b[0m | \u001b[95m 2.136e+0\u001b[0m | \u001b[95m 0.3833  \u001b[0m | \u001b[95m 0.4072  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.94258\tvalid_1's rmse: 2.60102\n",
      "[200]\ttraining's rmse: 3.71634\tvalid_1's rmse: 2.54927\n",
      "[300]\ttraining's rmse: 3.62675\tvalid_1's rmse: 2.52734\n",
      "[400]\ttraining's rmse: 3.57316\tvalid_1's rmse: 2.50942\n",
      "[500]\ttraining's rmse: 3.53406\tvalid_1's rmse: 2.50071\n",
      "[600]\ttraining's rmse: 3.5032\tvalid_1's rmse: 2.49031\n",
      "[700]\ttraining's rmse: 3.48052\tvalid_1's rmse: 2.48648\n",
      "[800]\ttraining's rmse: 3.46172\tvalid_1's rmse: 2.48171\n",
      "[900]\ttraining's rmse: 3.44607\tvalid_1's rmse: 2.47799\n",
      "[1000]\ttraining's rmse: 3.4314\tvalid_1's rmse: 2.47557\n",
      "[1100]\ttraining's rmse: 3.42017\tvalid_1's rmse: 2.47383\n",
      "[1200]\ttraining's rmse: 3.40765\tvalid_1's rmse: 2.47294\n",
      "[1300]\ttraining's rmse: 3.39762\tvalid_1's rmse: 2.47228\n",
      "Early stopping, best iteration is:\n",
      "[1227]\ttraining's rmse: 3.40473\tvalid_1's rmse: 2.47195\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.472   \u001b[0m | \u001b[0m 0.7337  \u001b[0m | \u001b[0m 2.181   \u001b[0m | \u001b[0m 0.1556  \u001b[0m | \u001b[0m 292.8   \u001b[0m | \u001b[0m 6.159   \u001b[0m | \u001b[0m 5.948e+0\u001b[0m | \u001b[0m 0.1495  \u001b[0m | \u001b[0m 1.007e+0\u001b[0m | \u001b[0m 0.231   \u001b[0m | \u001b[0m 0.3357  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.85233\tvalid_1's rmse: 2.55496\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's rmse: 3.86702\tvalid_1's rmse: 2.55448\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.554   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.76256\tvalid_1's rmse: 2.54026\n",
      "[200]\ttraining's rmse: 3.54893\tvalid_1's rmse: 2.50333\n",
      "[300]\ttraining's rmse: 3.47228\tvalid_1's rmse: 2.49179\n",
      "[400]\ttraining's rmse: 3.42818\tvalid_1's rmse: 2.48279\n",
      "[500]\ttraining's rmse: 3.39501\tvalid_1's rmse: 2.47619\n",
      "[600]\ttraining's rmse: 3.37188\tvalid_1's rmse: 2.47261\n",
      "[700]\ttraining's rmse: 3.35107\tvalid_1's rmse: 2.46959\n",
      "[800]\ttraining's rmse: 3.3302\tvalid_1's rmse: 2.46818\n",
      "[900]\ttraining's rmse: 3.31274\tvalid_1's rmse: 2.46889\n",
      "Early stopping, best iteration is:\n",
      "[815]\ttraining's rmse: 3.32729\tvalid_1's rmse: 2.46806\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.468   \u001b[0m | \u001b[0m 0.8885  \u001b[0m | \u001b[0m 16.47   \u001b[0m | \u001b[0m 0.2252  \u001b[0m | \u001b[0m 102.4   \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 4.908e+0\u001b[0m | \u001b[0m 0.7143  \u001b[0m | \u001b[0m 1.001e+0\u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 0.4387  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.85755\tvalid_1's rmse: 2.56306\n",
      "[200]\ttraining's rmse: 3.63906\tvalid_1's rmse: 2.5911\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's rmse: 3.83415\tvalid_1's rmse: 2.55811\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.558   \u001b[0m | \u001b[0m 0.4387  \u001b[0m | \u001b[0m 2.506   \u001b[0m | \u001b[0m 0.7138  \u001b[0m | \u001b[0m 102.5   \u001b[0m | \u001b[0m 3.675   \u001b[0m | \u001b[0m 5.976e+0\u001b[0m | \u001b[0m 0.2596  \u001b[0m | \u001b[0m 1.775e+0\u001b[0m | \u001b[0m 0.5209  \u001b[0m | \u001b[0m 0.1103  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.7055\tvalid_1's rmse: 2.52755\n",
      "[200]\ttraining's rmse: 3.51012\tvalid_1's rmse: 2.51299\n",
      "[300]\ttraining's rmse: 3.45339\tvalid_1's rmse: 2.50323\n",
      "[400]\ttraining's rmse: 3.41751\tvalid_1's rmse: 2.49081\n",
      "[500]\ttraining's rmse: 3.39488\tvalid_1's rmse: 2.48511\n",
      "[600]\ttraining's rmse: 3.37648\tvalid_1's rmse: 2.48136\n",
      "[700]\ttraining's rmse: 3.36071\tvalid_1's rmse: 2.47899\n",
      "[800]\ttraining's rmse: 3.34931\tvalid_1's rmse: 2.47497\n",
      "[900]\ttraining's rmse: 3.33802\tvalid_1's rmse: 2.47455\n",
      "[1000]\ttraining's rmse: 3.33122\tvalid_1's rmse: 2.47299\n",
      "[1100]\ttraining's rmse: 3.32254\tvalid_1's rmse: 2.47164\n",
      "[1200]\ttraining's rmse: 3.31419\tvalid_1's rmse: 2.47176\n",
      "[1300]\ttraining's rmse: 3.30644\tvalid_1's rmse: 2.4722\n",
      "Early stopping, best iteration is:\n",
      "[1210]\ttraining's rmse: 3.31324\tvalid_1's rmse: 2.47135\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.471   \u001b[0m | \u001b[0m 0.7452  \u001b[0m | \u001b[0m 14.14   \u001b[0m | \u001b[0m 0.295   \u001b[0m | \u001b[0m 297.4   \u001b[0m | \u001b[0m 8.445   \u001b[0m | \u001b[0m 4.974e+0\u001b[0m | \u001b[0m 0.7542  \u001b[0m | \u001b[0m 2.994e+0\u001b[0m | \u001b[0m 0.8136  \u001b[0m | \u001b[0m 0.7336  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.6372\tvalid_1's rmse: 2.53614\n",
      "[200]\ttraining's rmse: 3.46137\tvalid_1's rmse: 2.51986\n",
      "[300]\ttraining's rmse: 3.41635\tvalid_1's rmse: 2.49575\n",
      "[400]\ttraining's rmse: 3.39351\tvalid_1's rmse: 2.4828\n",
      "[500]\ttraining's rmse: 3.37611\tvalid_1's rmse: 2.47679\n",
      "[600]\ttraining's rmse: 3.3636\tvalid_1's rmse: 2.47259\n",
      "[700]\ttraining's rmse: 3.35446\tvalid_1's rmse: 2.4699\n",
      "[800]\ttraining's rmse: 3.34502\tvalid_1's rmse: 2.46751\n",
      "[900]\ttraining's rmse: 3.34004\tvalid_1's rmse: 2.46593\n",
      "[1000]\ttraining's rmse: 3.33247\tvalid_1's rmse: 2.46494\n",
      "[1100]\ttraining's rmse: 3.32741\tvalid_1's rmse: 2.46469\n",
      "[1200]\ttraining's rmse: 3.32028\tvalid_1's rmse: 2.4636\n",
      "[1300]\ttraining's rmse: 3.31376\tvalid_1's rmse: 2.46323\n",
      "[1400]\ttraining's rmse: 3.31045\tvalid_1's rmse: 2.46268\n",
      "Early stopping, best iteration is:\n",
      "[1386]\ttraining's rmse: 3.31048\tvalid_1's rmse: 2.46264\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-2.463   \u001b[0m | \u001b[95m 0.7422  \u001b[0m | \u001b[95m 2.388   \u001b[0m | \u001b[95m 0.7504  \u001b[0m | \u001b[95m 299.2   \u001b[0m | \u001b[95m 8.297   \u001b[0m | \u001b[95m 4.621e+0\u001b[0m | \u001b[95m 0.3224  \u001b[0m | \u001b[95m 1.342e+0\u001b[0m | \u001b[95m 0.1614  \u001b[0m | \u001b[95m 0.6339  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.97497\tvalid_1's rmse: 2.59331\n",
      "[200]\ttraining's rmse: 3.69989\tvalid_1's rmse: 2.65561\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's rmse: 3.89801\tvalid_1's rmse: 2.57805\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.578   \u001b[0m | \u001b[0m 0.1976  \u001b[0m | \u001b[0m 18.8    \u001b[0m | \u001b[0m 0.5336  \u001b[0m | \u001b[0m 297.7   \u001b[0m | \u001b[0m 4.085   \u001b[0m | \u001b[0m 5.987e+0\u001b[0m | \u001b[0m 0.1706  \u001b[0m | \u001b[0m 2.991e+0\u001b[0m | \u001b[0m 0.3584  \u001b[0m | \u001b[0m 0.105   \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
    "\n",
    "|  9        | -2.463    |  0.7422   |  2.388    |  0.7504   |  299.2    |  8.297    |  4.621e+0 |  0.3224   |  1.342e+0 |  0.1614   |  0.6339   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample':  0.7422,\n",
    "                    'subsample_freq': 2,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1342, \n",
    "                    'min_data_in_leaf': 4621, \n",
    "                    'feature_fraction': 0.7504,\n",
    "                    'max_bin': 299,\n",
    "                    'n_estimators': 1400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':8,\n",
    "                    'min_split_gain':0.3224,\n",
    "                    'reg_alpha':0.1614,\n",
    "                    'reg_lambda':0.6339,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.52203\n",
      "[200]\tvalid_0's rmse: 2.49136\n",
      "[300]\tvalid_0's rmse: 2.46984\n",
      "[400]\tvalid_0's rmse: 2.46083\n",
      "[500]\tvalid_0's rmse: 2.45542\n",
      "[600]\tvalid_0's rmse: 2.45215\n",
      "[700]\tvalid_0's rmse: 2.44896\n",
      "[800]\tvalid_0's rmse: 2.44647\n",
      "[900]\tvalid_0's rmse: 2.44459\n",
      "[1000]\tvalid_0's rmse: 2.44284\n",
      "[1100]\tvalid_0's rmse: 2.44105\n",
      "[1200]\tvalid_0's rmse: 2.44029\n",
      "[1300]\tvalid_0's rmse: 2.43914\n",
      "[1400]\tvalid_0's rmse: 2.4384\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('CA_3')\n",
    "store_id = 'CA_3'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#2.36679\n",
    "#100:2.5055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4652558 entries, 0 to 4652557\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 621.4 MB\n",
      "None\n",
      "(4481814, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# CA_4\n",
    "grid_df, features_columns = get_data_by_store('CA_4')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.54042\tvalid_1's rmse: 1.34456\n",
      "[200]\ttraining's rmse: 1.51072\tvalid_1's rmse: 1.3379\n",
      "[300]\ttraining's rmse: 1.5005\tvalid_1's rmse: 1.33624\n",
      "[400]\ttraining's rmse: 1.49378\tvalid_1's rmse: 1.33476\n",
      "[500]\ttraining's rmse: 1.48939\tvalid_1's rmse: 1.33395\n",
      "[600]\ttraining's rmse: 1.48607\tvalid_1's rmse: 1.33319\n",
      "[700]\ttraining's rmse: 1.48317\tvalid_1's rmse: 1.33278\n",
      "[800]\ttraining's rmse: 1.48107\tvalid_1's rmse: 1.33248\n",
      "[900]\ttraining's rmse: 1.47857\tvalid_1's rmse: 1.33234\n",
      "[1000]\ttraining's rmse: 1.47671\tvalid_1's rmse: 1.33227\n",
      "[1100]\ttraining's rmse: 1.47504\tvalid_1's rmse: 1.3323\n",
      "Early stopping, best iteration is:\n",
      "[1028]\ttraining's rmse: 1.47635\tvalid_1's rmse: 1.33218\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.332   \u001b[0m | \u001b[0m 0.7419  \u001b[0m | \u001b[0m 1.917   \u001b[0m | \u001b[0m 0.1992  \u001b[0m | \u001b[0m 197.9   \u001b[0m | \u001b[0m 8.224   \u001b[0m | \u001b[0m 4.053e+0\u001b[0m | \u001b[0m 0.704   \u001b[0m | \u001b[0m 2.959e+0\u001b[0m | \u001b[0m 0.2832  \u001b[0m | \u001b[0m 0.8882  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.52511\tvalid_1's rmse: 1.3385\n",
      "[200]\ttraining's rmse: 1.50384\tvalid_1's rmse: 1.33833\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's rmse: 1.51836\tvalid_1's rmse: 1.33799\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.338   \u001b[0m | \u001b[0m 0.563   \u001b[0m | \u001b[0m 11.6    \u001b[0m | \u001b[0m 0.769   \u001b[0m | \u001b[0m 218.9   \u001b[0m | \u001b[0m 7.412   \u001b[0m | \u001b[0m 5.47e+03\u001b[0m | \u001b[0m 0.3521  \u001b[0m | \u001b[0m 2.305e+0\u001b[0m | \u001b[0m 0.7228  \u001b[0m | \u001b[0m 0.3887  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.52679\tvalid_1's rmse: 1.33763\n",
      "[200]\ttraining's rmse: 1.50488\tvalid_1's rmse: 1.33801\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 1.51901\tvalid_1's rmse: 1.33694\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.337   \u001b[0m | \u001b[0m 0.4674  \u001b[0m | \u001b[0m 8.603   \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 163.1   \u001b[0m | \u001b[0m 9.873   \u001b[0m | \u001b[0m 5.276e+0\u001b[0m | \u001b[0m 0.5359  \u001b[0m | \u001b[0m 2.45e+03\u001b[0m | \u001b[0m 0.7217  \u001b[0m | \u001b[0m 0.8131  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.51948\tvalid_1's rmse: 1.33996\n",
      "[200]\ttraining's rmse: 1.49991\tvalid_1's rmse: 1.33652\n",
      "[300]\ttraining's rmse: 1.49423\tvalid_1's rmse: 1.33568\n",
      "[400]\ttraining's rmse: 1.4903\tvalid_1's rmse: 1.33458\n",
      "[500]\ttraining's rmse: 1.48699\tvalid_1's rmse: 1.33388\n",
      "[600]\ttraining's rmse: 1.48411\tvalid_1's rmse: 1.33356\n",
      "[700]\ttraining's rmse: 1.48232\tvalid_1's rmse: 1.3333\n",
      "[800]\ttraining's rmse: 1.48037\tvalid_1's rmse: 1.33285\n",
      "[900]\ttraining's rmse: 1.47847\tvalid_1's rmse: 1.3325\n",
      "[1000]\ttraining's rmse: 1.47699\tvalid_1's rmse: 1.33237\n",
      "[1100]\ttraining's rmse: 1.47548\tvalid_1's rmse: 1.33229\n",
      "[1200]\ttraining's rmse: 1.47418\tvalid_1's rmse: 1.33218\n",
      "[1300]\ttraining's rmse: 1.47296\tvalid_1's rmse: 1.33208\n",
      "[1400]\ttraining's rmse: 1.47173\tvalid_1's rmse: 1.33209\n",
      "[1500]\ttraining's rmse: 1.47032\tvalid_1's rmse: 1.33177\n",
      "[1600]\ttraining's rmse: 1.46907\tvalid_1's rmse: 1.33159\n",
      "[1700]\ttraining's rmse: 1.46806\tvalid_1's rmse: 1.33158\n",
      "Early stopping, best iteration is:\n",
      "[1671]\ttraining's rmse: 1.46836\tvalid_1's rmse: 1.33151\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-1.332   \u001b[0m | \u001b[95m 0.599   \u001b[0m | \u001b[95m 16.03   \u001b[0m | \u001b[95m 0.3151  \u001b[0m | \u001b[95m 140.4   \u001b[0m | \u001b[95m 7.443   \u001b[0m | \u001b[95m 3.009e+0\u001b[0m | \u001b[95m 0.7421  \u001b[0m | \u001b[95m 1.001e+0\u001b[0m | \u001b[95m 0.987   \u001b[0m | \u001b[95m 0.7153  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.54219\tvalid_1's rmse: 1.34628\n",
      "[200]\ttraining's rmse: 1.51971\tvalid_1's rmse: 1.34419\n",
      "[300]\ttraining's rmse: 1.51536\tvalid_1's rmse: 1.3444\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's rmse: 1.51923\tvalid_1's rmse: 1.344\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.344   \u001b[0m | \u001b[0m 0.2143  \u001b[0m | \u001b[0m 19.2    \u001b[0m | \u001b[0m 0.8671  \u001b[0m | \u001b[0m 285.5   \u001b[0m | \u001b[0m 4.09    \u001b[0m | \u001b[0m 3.018e+0\u001b[0m | \u001b[0m 0.5598  \u001b[0m | \u001b[0m 2.992e+0\u001b[0m | \u001b[0m 0.1286  \u001b[0m | \u001b[0m 0.2298  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.51636\tvalid_1's rmse: 1.33804\n",
      "[200]\ttraining's rmse: 1.49522\tvalid_1's rmse: 1.3362\n",
      "[300]\ttraining's rmse: 1.49077\tvalid_1's rmse: 1.33537\n",
      "[400]\ttraining's rmse: 1.48798\tvalid_1's rmse: 1.33475\n",
      "[500]\ttraining's rmse: 1.48513\tvalid_1's rmse: 1.33421\n",
      "[600]\ttraining's rmse: 1.48301\tvalid_1's rmse: 1.33376\n",
      "[700]\ttraining's rmse: 1.48108\tvalid_1's rmse: 1.33335\n",
      "[800]\ttraining's rmse: 1.47941\tvalid_1's rmse: 1.33303\n",
      "[900]\ttraining's rmse: 1.47763\tvalid_1's rmse: 1.33283\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's rmse: 1.47791\tvalid_1's rmse: 1.33276\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.333   \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 8.375   \u001b[0m | \u001b[0m 0.5999  \u001b[0m | \u001b[0m 107.8   \u001b[0m | \u001b[0m 8.035   \u001b[0m | \u001b[0m 5.01e+03\u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 1.005e+0\u001b[0m | \u001b[0m 0.7394  \u001b[0m | \u001b[0m 0.2526  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.54823\tvalid_1's rmse: 1.34126\n",
      "[200]\ttraining's rmse: 1.51506\tvalid_1's rmse: 1.33648\n",
      "[300]\ttraining's rmse: 1.50463\tvalid_1's rmse: 1.33496\n",
      "[400]\ttraining's rmse: 1.49799\tvalid_1's rmse: 1.3338\n",
      "[500]\ttraining's rmse: 1.49391\tvalid_1's rmse: 1.33369\n",
      "[600]\ttraining's rmse: 1.49083\tvalid_1's rmse: 1.33307\n",
      "[700]\ttraining's rmse: 1.48842\tvalid_1's rmse: 1.33301\n",
      "[800]\ttraining's rmse: 1.48576\tvalid_1's rmse: 1.33252\n",
      "[900]\ttraining's rmse: 1.48374\tvalid_1's rmse: 1.33222\n",
      "[1000]\ttraining's rmse: 1.4817\tvalid_1's rmse: 1.33185\n",
      "[1100]\ttraining's rmse: 1.48004\tvalid_1's rmse: 1.33184\n",
      "[1200]\ttraining's rmse: 1.47828\tvalid_1's rmse: 1.33172\n",
      "[1300]\ttraining's rmse: 1.4767\tvalid_1's rmse: 1.33149\n",
      "[1400]\ttraining's rmse: 1.47508\tvalid_1's rmse: 1.33141\n",
      "[1500]\ttraining's rmse: 1.47349\tvalid_1's rmse: 1.33144\n",
      "[1600]\ttraining's rmse: 1.47233\tvalid_1's rmse: 1.33148\n",
      "Early stopping, best iteration is:\n",
      "[1556]\ttraining's rmse: 1.4729\tvalid_1's rmse: 1.33134\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-1.331   \u001b[0m | \u001b[95m 0.3801  \u001b[0m | \u001b[95m 4.931   \u001b[0m | \u001b[95m 0.2262  \u001b[0m | \u001b[95m 299.5   \u001b[0m | \u001b[95m 10.99   \u001b[0m | \u001b[95m 4.055e+0\u001b[0m | \u001b[95m 0.8417  \u001b[0m | \u001b[95m 1.011e+0\u001b[0m | \u001b[95m 0.1893  \u001b[0m | \u001b[95m 0.3858  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.53729\tvalid_1's rmse: 1.3475\n",
      "[200]\ttraining's rmse: 1.51313\tvalid_1's rmse: 1.34339\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's rmse: 1.51402\tvalid_1's rmse: 1.34332\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.343   \u001b[0m | \u001b[0m 0.7205  \u001b[0m | \u001b[0m 6.191   \u001b[0m | \u001b[0m 0.3513  \u001b[0m | \u001b[0m 100.5   \u001b[0m | \u001b[0m 4.669   \u001b[0m | \u001b[0m 3.931e+0\u001b[0m | \u001b[0m 0.6457  \u001b[0m | \u001b[0m 1.86e+03\u001b[0m | \u001b[0m 0.8491  \u001b[0m | \u001b[0m 0.8013  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.54986\tvalid_1's rmse: 1.34468\n",
      "[200]\ttraining's rmse: 1.5135\tvalid_1's rmse: 1.34105\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's rmse: 1.52776\tvalid_1's rmse: 1.33874\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.339   \u001b[0m | \u001b[0m 0.2397  \u001b[0m | \u001b[0m 6.917   \u001b[0m | \u001b[0m 0.5581  \u001b[0m | \u001b[0m 102.9   \u001b[0m | \u001b[0m 0.03234 \u001b[0m | \u001b[0m 5.988e+0\u001b[0m | \u001b[0m 0.1109  \u001b[0m | \u001b[0m 2.995e+0\u001b[0m | \u001b[0m 0.9856  \u001b[0m | \u001b[0m 0.9265  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.58552\tvalid_1's rmse: 1.36137\n",
      "[200]\ttraining's rmse: 1.54687\tvalid_1's rmse: 1.34743\n",
      "[300]\ttraining's rmse: 1.53348\tvalid_1's rmse: 1.34675\n",
      "[400]\ttraining's rmse: 1.52707\tvalid_1's rmse: 1.34536\n",
      "[500]\ttraining's rmse: 1.52052\tvalid_1's rmse: 1.3436\n",
      "[600]\ttraining's rmse: 1.51659\tvalid_1's rmse: 1.34271\n",
      "[700]\ttraining's rmse: 1.51397\tvalid_1's rmse: 1.34205\n",
      "[800]\ttraining's rmse: 1.51103\tvalid_1's rmse: 1.34095\n",
      "[900]\ttraining's rmse: 1.50915\tvalid_1's rmse: 1.33998\n",
      "[1000]\ttraining's rmse: 1.50725\tvalid_1's rmse: 1.33956\n",
      "[1100]\ttraining's rmse: 1.50563\tvalid_1's rmse: 1.33912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 1.50419\tvalid_1's rmse: 1.33885\n",
      "[1300]\ttraining's rmse: 1.5032\tvalid_1's rmse: 1.33852\n",
      "[1400]\ttraining's rmse: 1.50195\tvalid_1's rmse: 1.33815\n",
      "[1500]\ttraining's rmse: 1.501\tvalid_1's rmse: 1.33801\n",
      "[1600]\ttraining's rmse: 1.50014\tvalid_1's rmse: 1.33779\n",
      "[1700]\ttraining's rmse: 1.49925\tvalid_1's rmse: 1.33764\n",
      "[1800]\ttraining's rmse: 1.4984\tvalid_1's rmse: 1.33733\n",
      "[1900]\ttraining's rmse: 1.49774\tvalid_1's rmse: 1.33727\n",
      "[2000]\ttraining's rmse: 1.49693\tvalid_1's rmse: 1.33703\n",
      "[2100]\ttraining's rmse: 1.49609\tvalid_1's rmse: 1.33689\n",
      "Early stopping, best iteration is:\n",
      "[2077]\ttraining's rmse: 1.4963\tvalid_1's rmse: 1.33685\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.337   \u001b[0m | \u001b[0m 0.8469  \u001b[0m | \u001b[0m 16.59   \u001b[0m | \u001b[0m 0.1789  \u001b[0m | \u001b[0m 281.3   \u001b[0m | \u001b[0m 3.993   \u001b[0m | \u001b[0m 5.976e+0\u001b[0m | \u001b[0m 0.7909  \u001b[0m | \u001b[0m 1.002e+0\u001b[0m | \u001b[0m 0.2905  \u001b[0m | \u001b[0m 0.4242  \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
    "|  7        | -1.331    |  0.3801   |  4.931    |  0.2262   |  299.5    |  10.99    |  4.055e+0 |  0.8417   |  1.011e+0 |  0.1893   |  0.3858   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.3801,\n",
    "                    'subsample_freq': 4,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1011, \n",
    "                    'min_data_in_leaf': 4055, \n",
    "                    'feature_fraction': 0.2262,\n",
    "                    'max_bin': 299,\n",
    "                    'n_estimators': 1600,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':10,\n",
    "                    'min_split_gain':0.8417,\n",
    "                    'reg_alpha': 0.1893,\n",
    "                    'reg_lambda':0.3858,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.33982\n",
      "[200]\tvalid_0's rmse: 1.33359\n",
      "[300]\tvalid_0's rmse: 1.33138\n",
      "[400]\tvalid_0's rmse: 1.32898\n",
      "[500]\tvalid_0's rmse: 1.32795\n",
      "[600]\tvalid_0's rmse: 1.32686\n",
      "[700]\tvalid_0's rmse: 1.3261\n",
      "[800]\tvalid_0's rmse: 1.32499\n",
      "[900]\tvalid_0's rmse: 1.32439\n",
      "[1000]\tvalid_0's rmse: 1.32361\n",
      "[1100]\tvalid_0's rmse: 1.323\n",
      "[1200]\tvalid_0's rmse: 1.3222\n",
      "[1300]\tvalid_0's rmse: 1.32154\n",
      "[1400]\tvalid_0's rmse: 1.32092\n",
      "[1500]\tvalid_0's rmse: 1.32019\n",
      "[1600]\tvalid_0's rmse: 1.31947\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('CA_4')\n",
    "store_id = 'CA_4'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.28865\n",
    "#100:1.3326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4797955 entries, 0 to 4797954\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 640.9 MB\n",
      "None\n",
      "(4627211, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# TX_1\n",
    "grid_df, features_columns = get_data_by_store('TX_1')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.23722\tvalid_1's rmse: 1.66354\n",
      "[200]\ttraining's rmse: 2.16178\tvalid_1's rmse: 1.63279\n",
      "[300]\ttraining's rmse: 2.12833\tvalid_1's rmse: 1.62103\n",
      "[400]\ttraining's rmse: 2.10818\tvalid_1's rmse: 1.61476\n",
      "[500]\ttraining's rmse: 2.09568\tvalid_1's rmse: 1.6104\n",
      "[600]\ttraining's rmse: 2.08511\tvalid_1's rmse: 1.60665\n",
      "[700]\ttraining's rmse: 2.07579\tvalid_1's rmse: 1.60363\n",
      "[800]\ttraining's rmse: 2.06958\tvalid_1's rmse: 1.60171\n",
      "[900]\ttraining's rmse: 2.06331\tvalid_1's rmse: 1.60045\n",
      "[1000]\ttraining's rmse: 2.05834\tvalid_1's rmse: 1.59911\n",
      "[1100]\ttraining's rmse: 2.05342\tvalid_1's rmse: 1.59842\n",
      "[1200]\ttraining's rmse: 2.04811\tvalid_1's rmse: 1.59778\n",
      "[1300]\ttraining's rmse: 2.04446\tvalid_1's rmse: 1.59707\n",
      "[1400]\ttraining's rmse: 2.04125\tvalid_1's rmse: 1.59664\n",
      "[1500]\ttraining's rmse: 2.03802\tvalid_1's rmse: 1.59669\n",
      "Early stopping, best iteration is:\n",
      "[1447]\ttraining's rmse: 2.03987\tvalid_1's rmse: 1.59648\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.596   \u001b[0m | \u001b[0m 0.8553  \u001b[0m | \u001b[0m 10.26   \u001b[0m | \u001b[0m 0.1551  \u001b[0m | \u001b[0m 112.2   \u001b[0m | \u001b[0m 6.62    \u001b[0m | \u001b[0m 4.174e+0\u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 2.512e+0\u001b[0m | \u001b[0m 0.5937  \u001b[0m | \u001b[0m 0.6784  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.35824\tvalid_1's rmse: 1.7463\n",
      "[200]\ttraining's rmse: 2.22003\tvalid_1's rmse: 1.65151\n",
      "[300]\ttraining's rmse: 2.18474\tvalid_1's rmse: 1.64724\n",
      "[400]\ttraining's rmse: 2.16556\tvalid_1's rmse: 1.64603\n",
      "[500]\ttraining's rmse: 2.15485\tvalid_1's rmse: 1.64385\n",
      "[600]\ttraining's rmse: 2.14677\tvalid_1's rmse: 1.6402\n",
      "[700]\ttraining's rmse: 2.13865\tvalid_1's rmse: 1.63785\n",
      "[800]\ttraining's rmse: 2.13215\tvalid_1's rmse: 1.63542\n",
      "[900]\ttraining's rmse: 2.12758\tvalid_1's rmse: 1.63403\n",
      "[1000]\ttraining's rmse: 2.12436\tvalid_1's rmse: 1.63293\n",
      "[1100]\ttraining's rmse: 2.12026\tvalid_1's rmse: 1.6313\n",
      "[1200]\ttraining's rmse: 2.11889\tvalid_1's rmse: 1.63022\n",
      "[1300]\ttraining's rmse: 2.11662\tvalid_1's rmse: 1.62975\n",
      "[1400]\ttraining's rmse: 2.11508\tvalid_1's rmse: 1.62842\n",
      "[1500]\ttraining's rmse: 2.11408\tvalid_1's rmse: 1.62769\n",
      "[1600]\ttraining's rmse: 2.11237\tvalid_1's rmse: 1.62635\n",
      "[1700]\ttraining's rmse: 2.11117\tvalid_1's rmse: 1.62487\n",
      "[1800]\ttraining's rmse: 2.10996\tvalid_1's rmse: 1.62389\n",
      "[1900]\ttraining's rmse: 2.10894\tvalid_1's rmse: 1.62261\n",
      "[2000]\ttraining's rmse: 2.10732\tvalid_1's rmse: 1.62152\n",
      "[2100]\ttraining's rmse: 2.1055\tvalid_1's rmse: 1.62134\n",
      "[2200]\ttraining's rmse: 2.10423\tvalid_1's rmse: 1.62014\n",
      "[2300]\ttraining's rmse: 2.10324\tvalid_1's rmse: 1.61969\n",
      "[2400]\ttraining's rmse: 2.102\tvalid_1's rmse: 1.61898\n",
      "[2500]\ttraining's rmse: 2.10163\tvalid_1's rmse: 1.61896\n",
      "Early stopping, best iteration is:\n",
      "[2443]\ttraining's rmse: 2.1018\tvalid_1's rmse: 1.61872\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.619   \u001b[0m | \u001b[0m 0.1931  \u001b[0m | \u001b[0m 8.428   \u001b[0m | \u001b[0m 0.2586  \u001b[0m | \u001b[0m 281.1   \u001b[0m | \u001b[0m 2.835   \u001b[0m | \u001b[0m 3.914e+0\u001b[0m | \u001b[0m 0.7214  \u001b[0m | \u001b[0m 2.954e+0\u001b[0m | \u001b[0m 0.7525  \u001b[0m | \u001b[0m 0.4168  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.37001\tvalid_1's rmse: 1.74223\n",
      "[200]\ttraining's rmse: 2.26889\tvalid_1's rmse: 1.69325\n",
      "[300]\ttraining's rmse: 2.22836\tvalid_1's rmse: 1.68137\n",
      "[400]\ttraining's rmse: 2.20338\tvalid_1's rmse: 1.67391\n",
      "[500]\ttraining's rmse: 2.18528\tvalid_1's rmse: 1.66654\n",
      "[600]\ttraining's rmse: 2.16968\tvalid_1's rmse: 1.65882\n",
      "[700]\ttraining's rmse: 2.1596\tvalid_1's rmse: 1.65391\n",
      "[800]\ttraining's rmse: 2.14981\tvalid_1's rmse: 1.6485\n",
      "[900]\ttraining's rmse: 2.143\tvalid_1's rmse: 1.64428\n",
      "[1000]\ttraining's rmse: 2.13615\tvalid_1's rmse: 1.63943\n",
      "[1100]\ttraining's rmse: 2.13118\tvalid_1's rmse: 1.63605\n",
      "[1200]\ttraining's rmse: 2.12685\tvalid_1's rmse: 1.6333\n",
      "[1300]\ttraining's rmse: 2.12311\tvalid_1's rmse: 1.63146\n",
      "[1400]\ttraining's rmse: 2.12011\tvalid_1's rmse: 1.63028\n",
      "[1500]\ttraining's rmse: 2.11744\tvalid_1's rmse: 1.62838\n",
      "[1600]\ttraining's rmse: 2.1145\tvalid_1's rmse: 1.6265\n",
      "[1700]\ttraining's rmse: 2.11132\tvalid_1's rmse: 1.62475\n",
      "[1800]\ttraining's rmse: 2.10829\tvalid_1's rmse: 1.62307\n",
      "[1900]\ttraining's rmse: 2.106\tvalid_1's rmse: 1.62186\n",
      "[2000]\ttraining's rmse: 2.10346\tvalid_1's rmse: 1.62067\n",
      "[2100]\ttraining's rmse: 2.10138\tvalid_1's rmse: 1.61998\n",
      "[2200]\ttraining's rmse: 2.09895\tvalid_1's rmse: 1.61891\n",
      "[2300]\ttraining's rmse: 2.09707\tvalid_1's rmse: 1.61739\n",
      "[2400]\ttraining's rmse: 2.09535\tvalid_1's rmse: 1.61651\n",
      "[2500]\ttraining's rmse: 2.09304\tvalid_1's rmse: 1.61557\n",
      "[2600]\ttraining's rmse: 2.09124\tvalid_1's rmse: 1.61413\n",
      "[2700]\ttraining's rmse: 2.08951\tvalid_1's rmse: 1.61331\n",
      "[2800]\ttraining's rmse: 2.088\tvalid_1's rmse: 1.61278\n",
      "[2900]\ttraining's rmse: 2.08639\tvalid_1's rmse: 1.61257\n",
      "[3000]\ttraining's rmse: 2.085\tvalid_1's rmse: 1.61186\n",
      "[3100]\ttraining's rmse: 2.08363\tvalid_1's rmse: 1.61161\n",
      "[3200]\ttraining's rmse: 2.082\tvalid_1's rmse: 1.61116\n",
      "[3300]\ttraining's rmse: 2.08053\tvalid_1's rmse: 1.61085\n",
      "[3400]\ttraining's rmse: 2.07918\tvalid_1's rmse: 1.60995\n",
      "[3500]\ttraining's rmse: 2.07763\tvalid_1's rmse: 1.60939\n",
      "[3600]\ttraining's rmse: 2.07656\tvalid_1's rmse: 1.60923\n",
      "[3700]\ttraining's rmse: 2.07542\tvalid_1's rmse: 1.60906\n",
      "[3800]\ttraining's rmse: 2.07388\tvalid_1's rmse: 1.60886\n",
      "[3900]\ttraining's rmse: 2.0731\tvalid_1's rmse: 1.60841\n",
      "[4000]\ttraining's rmse: 2.07215\tvalid_1's rmse: 1.60831\n",
      "[4100]\ttraining's rmse: 2.07088\tvalid_1's rmse: 1.60777\n",
      "[4200]\ttraining's rmse: 2.06988\tvalid_1's rmse: 1.60701\n",
      "[4300]\ttraining's rmse: 2.0689\tvalid_1's rmse: 1.60642\n",
      "[4400]\ttraining's rmse: 2.06763\tvalid_1's rmse: 1.60643\n",
      "[4500]\ttraining's rmse: 2.06696\tvalid_1's rmse: 1.60633\n",
      "[4600]\ttraining's rmse: 2.06602\tvalid_1's rmse: 1.60604\n",
      "[4700]\ttraining's rmse: 2.06476\tvalid_1's rmse: 1.6056\n",
      "[4800]\ttraining's rmse: 2.06414\tvalid_1's rmse: 1.60559\n",
      "[4900]\ttraining's rmse: 2.06311\tvalid_1's rmse: 1.60512\n",
      "[5000]\ttraining's rmse: 2.06236\tvalid_1's rmse: 1.60482\n",
      "[5100]\ttraining's rmse: 2.06159\tvalid_1's rmse: 1.6045\n",
      "[5200]\ttraining's rmse: 2.06098\tvalid_1's rmse: 1.6043\n",
      "[5300]\ttraining's rmse: 2.06024\tvalid_1's rmse: 1.60418\n",
      "[5400]\ttraining's rmse: 2.05932\tvalid_1's rmse: 1.60417\n",
      "Early stopping, best iteration is:\n",
      "[5367]\ttraining's rmse: 2.05965\tvalid_1's rmse: 1.60396\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.604   \u001b[0m | \u001b[0m 0.4615  \u001b[0m | \u001b[0m 5.433   \u001b[0m | \u001b[0m 0.1243  \u001b[0m | \u001b[0m 101.1   \u001b[0m | \u001b[0m 3.852   \u001b[0m | \u001b[0m 5.642e+0\u001b[0m | \u001b[0m 0.6388  \u001b[0m | \u001b[0m 2.788e+0\u001b[0m | \u001b[0m 0.8481  \u001b[0m | \u001b[0m 0.5716  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.24138\tvalid_1's rmse: 1.67165\n",
      "[200]\ttraining's rmse: 2.16198\tvalid_1's rmse: 1.64347\n",
      "[300]\ttraining's rmse: 2.13041\tvalid_1's rmse: 1.63018\n",
      "[400]\ttraining's rmse: 2.11444\tvalid_1's rmse: 1.62289\n",
      "[500]\ttraining's rmse: 2.10066\tvalid_1's rmse: 1.61665\n",
      "[600]\ttraining's rmse: 2.09233\tvalid_1's rmse: 1.61426\n",
      "[700]\ttraining's rmse: 2.08444\tvalid_1's rmse: 1.61061\n",
      "[800]\ttraining's rmse: 2.07891\tvalid_1's rmse: 1.60797\n",
      "[900]\ttraining's rmse: 2.07326\tvalid_1's rmse: 1.60632\n",
      "[1000]\ttraining's rmse: 2.0685\tvalid_1's rmse: 1.60493\n",
      "[1100]\ttraining's rmse: 2.06413\tvalid_1's rmse: 1.60329\n",
      "[1200]\ttraining's rmse: 2.06017\tvalid_1's rmse: 1.6024\n",
      "[1300]\ttraining's rmse: 2.05667\tvalid_1's rmse: 1.60169\n",
      "[1400]\ttraining's rmse: 2.05346\tvalid_1's rmse: 1.60116\n",
      "[1500]\ttraining's rmse: 2.05044\tvalid_1's rmse: 1.6007\n",
      "[1600]\ttraining's rmse: 2.04762\tvalid_1's rmse: 1.59969\n",
      "[1700]\ttraining's rmse: 2.04415\tvalid_1's rmse: 1.59931\n",
      "[1800]\ttraining's rmse: 2.04082\tvalid_1's rmse: 1.59905\n",
      "[1900]\ttraining's rmse: 2.03891\tvalid_1's rmse: 1.59863\n",
      "[2000]\ttraining's rmse: 2.03626\tvalid_1's rmse: 1.59847\n",
      "[2100]\ttraining's rmse: 2.03367\tvalid_1's rmse: 1.59855\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's rmse: 2.03587\tvalid_1's rmse: 1.59833\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.598   \u001b[0m | \u001b[0m 0.7277  \u001b[0m | \u001b[0m 19.06   \u001b[0m | \u001b[0m 0.1696  \u001b[0m | \u001b[0m 279.3   \u001b[0m | \u001b[0m 6.193   \u001b[0m | \u001b[0m 5.975e+0\u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.396   \u001b[0m | \u001b[0m 0.7448  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.13491\tvalid_1's rmse: 1.60854\n",
      "[200]\ttraining's rmse: 2.09375\tvalid_1's rmse: 1.59751\n",
      "[300]\ttraining's rmse: 2.08115\tvalid_1's rmse: 1.5956\n",
      "[400]\ttraining's rmse: 2.07342\tvalid_1's rmse: 1.59437\n",
      "[500]\ttraining's rmse: 2.06666\tvalid_1's rmse: 1.5934\n",
      "[600]\ttraining's rmse: 2.06007\tvalid_1's rmse: 1.59344\n",
      "Early stopping, best iteration is:\n",
      "[534]\ttraining's rmse: 2.06458\tvalid_1's rmse: 1.59313\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-1.593   \u001b[0m | \u001b[95m 0.7015  \u001b[0m | \u001b[95m 12.96   \u001b[0m | \u001b[95m 0.4496  \u001b[0m | \u001b[95m 112.5   \u001b[0m | \u001b[95m 6.688   \u001b[0m | \u001b[95m 3.016e+0\u001b[0m | \u001b[95m 0.1475  \u001b[0m | \u001b[95m 1.009e+0\u001b[0m | \u001b[95m 0.8076  \u001b[0m | \u001b[95m 0.88    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.14747\tvalid_1's rmse: 1.61588\n",
      "[200]\ttraining's rmse: 2.08973\tvalid_1's rmse: 1.60501\n",
      "[300]\ttraining's rmse: 2.07572\tvalid_1's rmse: 1.60248\n",
      "[400]\ttraining's rmse: 2.06582\tvalid_1's rmse: 1.60007\n",
      "[500]\ttraining's rmse: 2.05718\tvalid_1's rmse: 1.59926\n",
      "[600]\ttraining's rmse: 2.05184\tvalid_1's rmse: 1.59839\n",
      "[700]\ttraining's rmse: 2.04684\tvalid_1's rmse: 1.59808\n",
      "[800]\ttraining's rmse: 2.04148\tvalid_1's rmse: 1.59741\n",
      "[900]\ttraining's rmse: 2.03708\tvalid_1's rmse: 1.59695\n",
      "[1000]\ttraining's rmse: 2.03357\tvalid_1's rmse: 1.59689\n",
      "[1100]\ttraining's rmse: 2.02991\tvalid_1's rmse: 1.5972\n",
      "Early stopping, best iteration is:\n",
      "[1053]\ttraining's rmse: 2.03165\tvalid_1's rmse: 1.59677\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.597   \u001b[0m | \u001b[0m 0.5613  \u001b[0m | \u001b[0m 13.95   \u001b[0m | \u001b[0m 0.4885  \u001b[0m | \u001b[0m 101.9   \u001b[0m | \u001b[0m 10.5    \u001b[0m | \u001b[0m 4.473e+0\u001b[0m | \u001b[0m 0.7024  \u001b[0m | \u001b[0m 1.011e+0\u001b[0m | \u001b[0m 0.59    \u001b[0m | \u001b[0m 0.6684  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.20869\tvalid_1's rmse: 1.64514\n",
      "[200]\ttraining's rmse: 2.13557\tvalid_1's rmse: 1.62063\n",
      "[300]\ttraining's rmse: 2.10692\tvalid_1's rmse: 1.61157\n",
      "[400]\ttraining's rmse: 2.08807\tvalid_1's rmse: 1.60597\n",
      "[500]\ttraining's rmse: 2.07696\tvalid_1's rmse: 1.60271\n",
      "[600]\ttraining's rmse: 2.06916\tvalid_1's rmse: 1.60001\n",
      "[700]\ttraining's rmse: 2.06184\tvalid_1's rmse: 1.59834\n",
      "[800]\ttraining's rmse: 2.05613\tvalid_1's rmse: 1.59733\n",
      "[900]\ttraining's rmse: 2.04994\tvalid_1's rmse: 1.59579\n",
      "[1000]\ttraining's rmse: 2.04545\tvalid_1's rmse: 1.59581\n",
      "[1100]\ttraining's rmse: 2.04058\tvalid_1's rmse: 1.59541\n",
      "Early stopping, best iteration is:\n",
      "[1068]\ttraining's rmse: 2.04189\tvalid_1's rmse: 1.59508\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.595   \u001b[0m | \u001b[0m 0.4768  \u001b[0m | \u001b[0m 5.58    \u001b[0m | \u001b[0m 0.2115  \u001b[0m | \u001b[0m 104.0   \u001b[0m | \u001b[0m 7.652   \u001b[0m | \u001b[0m 3.018e+0\u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 2.946e+0\u001b[0m | \u001b[0m 0.8725  \u001b[0m | \u001b[0m 0.7209  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.25305\tvalid_1's rmse: 1.67215\n",
      "[200]\ttraining's rmse: 2.15674\tvalid_1's rmse: 1.63417\n",
      "[300]\ttraining's rmse: 2.1149\tvalid_1's rmse: 1.62097\n",
      "[400]\ttraining's rmse: 2.08932\tvalid_1's rmse: 1.61572\n",
      "[500]\ttraining's rmse: 2.07345\tvalid_1's rmse: 1.61234\n",
      "[600]\ttraining's rmse: 2.05986\tvalid_1's rmse: 1.61035\n",
      "[700]\ttraining's rmse: 2.04827\tvalid_1's rmse: 1.60773\n",
      "[800]\ttraining's rmse: 2.03962\tvalid_1's rmse: 1.60568\n",
      "[900]\ttraining's rmse: 2.03004\tvalid_1's rmse: 1.60412\n",
      "[1000]\ttraining's rmse: 2.02138\tvalid_1's rmse: 1.60312\n",
      "[1100]\ttraining's rmse: 2.01442\tvalid_1's rmse: 1.60225\n",
      "[1200]\ttraining's rmse: 2.00672\tvalid_1's rmse: 1.60139\n",
      "[1300]\ttraining's rmse: 1.99935\tvalid_1's rmse: 1.60112\n",
      "[1400]\ttraining's rmse: 1.99199\tvalid_1's rmse: 1.60086\n",
      "[1500]\ttraining's rmse: 1.98568\tvalid_1's rmse: 1.60013\n",
      "[1600]\ttraining's rmse: 1.97899\tvalid_1's rmse: 1.60073\n",
      "Early stopping, best iteration is:\n",
      "[1502]\ttraining's rmse: 1.98556\tvalid_1's rmse: 1.60012\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.6     \u001b[0m | \u001b[0m 0.789   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 0.1319  \u001b[0m | \u001b[0m 102.2   \u001b[0m | \u001b[0m-0.1091  \u001b[0m | \u001b[0m 5.966e+0\u001b[0m | \u001b[0m 0.4551  \u001b[0m | \u001b[0m 1.029e+0\u001b[0m | \u001b[0m 0.1858  \u001b[0m | \u001b[0m 0.8796  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.15869\tvalid_1's rmse: 1.62133\n",
      "[200]\ttraining's rmse: 2.1005\tvalid_1's rmse: 1.60709\n",
      "[300]\ttraining's rmse: 2.08839\tvalid_1's rmse: 1.60351\n",
      "[400]\ttraining's rmse: 2.0795\tvalid_1's rmse: 1.60104\n",
      "[500]\ttraining's rmse: 2.0725\tvalid_1's rmse: 1.59962\n",
      "[600]\ttraining's rmse: 2.06684\tvalid_1's rmse: 1.59817\n",
      "[700]\ttraining's rmse: 2.06321\tvalid_1's rmse: 1.59696\n",
      "[800]\ttraining's rmse: 2.0582\tvalid_1's rmse: 1.59636\n",
      "[900]\ttraining's rmse: 2.05437\tvalid_1's rmse: 1.59558\n",
      "[1000]\ttraining's rmse: 2.05167\tvalid_1's rmse: 1.59505\n",
      "[1100]\ttraining's rmse: 2.04771\tvalid_1's rmse: 1.59441\n",
      "Early stopping, best iteration is:\n",
      "[1073]\ttraining's rmse: 2.04858\tvalid_1's rmse: 1.59416\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.594   \u001b[0m | \u001b[0m 0.3021  \u001b[0m | \u001b[0m 1.442   \u001b[0m | \u001b[0m 0.5317  \u001b[0m | \u001b[0m 294.7   \u001b[0m | \u001b[0m 9.441   \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.787   \u001b[0m | \u001b[0m 1.863e+0\u001b[0m | \u001b[0m 0.1441  \u001b[0m | \u001b[0m 0.6432  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.32336\tvalid_1's rmse: 1.70768\n",
      "[200]\ttraining's rmse: 2.18824\tvalid_1's rmse: 1.62745\n",
      "[300]\ttraining's rmse: 2.15455\tvalid_1's rmse: 1.62639\n",
      "[400]\ttraining's rmse: 2.13956\tvalid_1's rmse: 1.62424\n",
      "[500]\ttraining's rmse: 2.12978\tvalid_1's rmse: 1.62114\n",
      "[600]\ttraining's rmse: 2.12427\tvalid_1's rmse: 1.62021\n",
      "Early stopping, best iteration is:\n",
      "[599]\ttraining's rmse: 2.1243\tvalid_1's rmse: 1.62018\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.62    \u001b[0m | \u001b[0m 0.322   \u001b[0m | \u001b[0m 17.16   \u001b[0m | \u001b[0m 0.3991  \u001b[0m | \u001b[0m 103.9   \u001b[0m | \u001b[0m 2.997   \u001b[0m | \u001b[0m 3.025e+0\u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 1.919e+0\u001b[0m | \u001b[0m 0.1476  \u001b[0m | \u001b[0m 0.4328  \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
    "|  5        | -1.593    |  0.7015   |  12.96    |  0.4496   |  112.5    |  6.688    |  3.016e+0 |  0.1475   |  1.009e+0 |  0.8076   |  0.88     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample':  0.7015 ,\n",
    "                    'subsample_freq': 12,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1099, \n",
    "                    'min_data_in_leaf': 3016, \n",
    "                    'feature_fraction':  0.4496,\n",
    "                    'max_bin': 112,\n",
    "                    'n_estimators': 600,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':6,\n",
    "                    'min_split_gain':0.1475,\n",
    "                    'reg_alpha': 0.8076,\n",
    "                    'reg_lambda': 0.88,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.59904\n",
      "[200]\tvalid_0's rmse: 1.58891\n",
      "[300]\tvalid_0's rmse: 1.58737\n",
      "[400]\tvalid_0's rmse: 1.58611\n",
      "[500]\tvalid_0's rmse: 1.58533\n",
      "[600]\tvalid_0's rmse: 1.58475\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('TX_1')\n",
    "store_id = 'TX_1'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.5354\n",
    "#100:1.60744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4807881 entries, 0 to 4807880\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 642.2 MB\n",
      "None\n",
      "(4637137, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# TX_2\n",
    "grid_df, features_columns = get_data_by_store('TX_2')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.53618\tvalid_1's rmse: 1.7273\n",
      "[200]\ttraining's rmse: 2.46001\tvalid_1's rmse: 1.72316\n",
      "[300]\ttraining's rmse: 2.44144\tvalid_1's rmse: 1.71919\n",
      "[400]\ttraining's rmse: 2.4307\tvalid_1's rmse: 1.71792\n",
      "[500]\ttraining's rmse: 2.41913\tvalid_1's rmse: 1.71542\n",
      "[600]\ttraining's rmse: 2.41131\tvalid_1's rmse: 1.71448\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's rmse: 2.41473\tvalid_1's rmse: 1.71396\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.714   \u001b[0m | \u001b[0m 0.7902  \u001b[0m | \u001b[0m 16.11   \u001b[0m | \u001b[0m 0.6931  \u001b[0m | \u001b[0m 192.8   \u001b[0m | \u001b[0m 9.956   \u001b[0m | \u001b[0m 4.678e+0\u001b[0m | \u001b[0m 0.8959  \u001b[0m | \u001b[0m 2.662e+0\u001b[0m | \u001b[0m 0.9913  \u001b[0m | \u001b[0m 0.5926  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.70092\tvalid_1's rmse: 1.74698\n",
      "[200]\ttraining's rmse: 2.57083\tvalid_1's rmse: 1.75841\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's rmse: 2.64177\tvalid_1's rmse: 1.74146\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.741   \u001b[0m | \u001b[0m 0.6292  \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 0.2786  \u001b[0m | \u001b[0m 137.5   \u001b[0m | \u001b[0m 3.352   \u001b[0m | \u001b[0m 5.24e+03\u001b[0m | \u001b[0m 0.4704  \u001b[0m | \u001b[0m 1.359e+0\u001b[0m | \u001b[0m 0.5207  \u001b[0m | \u001b[0m 0.3652  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.5684\tvalid_1's rmse: 1.74\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's rmse: 2.58762\tvalid_1's rmse: 1.73878\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.739   \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 8.436   \u001b[0m | \u001b[0m 0.8688  \u001b[0m | \u001b[0m 279.8   \u001b[0m | \u001b[0m 5.942   \u001b[0m | \u001b[0m 5.723e+0\u001b[0m | \u001b[0m 0.7386  \u001b[0m | \u001b[0m 2.901e+0\u001b[0m | \u001b[0m 0.2125  \u001b[0m | \u001b[0m 0.6699  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.49089\tvalid_1's rmse: 1.71276\n",
      "[200]\ttraining's rmse: 2.3914\tvalid_1's rmse: 1.71586\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's rmse: 2.48189\tvalid_1's rmse: 1.71209\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-1.712   \u001b[0m | \u001b[95m 0.8611  \u001b[0m | \u001b[95m 13.63   \u001b[0m | \u001b[95m 0.8275  \u001b[0m | \u001b[95m 298.4   \u001b[0m | \u001b[95m 0.7706  \u001b[0m | \u001b[95m 3.021e+0\u001b[0m | \u001b[95m 0.6468  \u001b[0m | \u001b[95m 2.962e+0\u001b[0m | \u001b[95m 0.2014  \u001b[0m | \u001b[95m 0.8631  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.65794\tvalid_1's rmse: 1.73612\n",
      "[200]\ttraining's rmse: 2.53219\tvalid_1's rmse: 1.73795\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's rmse: 2.60061\tvalid_1's rmse: 1.72505\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.725   \u001b[0m | \u001b[0m 0.527   \u001b[0m | \u001b[0m 10.46   \u001b[0m | \u001b[0m 0.3908  \u001b[0m | \u001b[0m 101.2   \u001b[0m | \u001b[0m 3.302   \u001b[0m | \u001b[0m 3.013e+0\u001b[0m | \u001b[0m 0.1178  \u001b[0m | \u001b[0m 1.02e+03\u001b[0m | \u001b[0m 0.1324  \u001b[0m | \u001b[0m 0.7655  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.94242\tvalid_1's rmse: 1.83577\n",
      "[200]\ttraining's rmse: 2.73842\tvalid_1's rmse: 1.79014\n",
      "[300]\ttraining's rmse: 2.68102\tvalid_1's rmse: 1.79632\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's rmse: 2.73842\tvalid_1's rmse: 1.79014\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.79    \u001b[0m | \u001b[0m 0.3007  \u001b[0m | \u001b[0m 19.53   \u001b[0m | \u001b[0m 0.1737  \u001b[0m | \u001b[0m 101.8   \u001b[0m | \u001b[0m 2.499   \u001b[0m | \u001b[0m 3.01e+03\u001b[0m | \u001b[0m 0.8068  \u001b[0m | \u001b[0m 2.979e+0\u001b[0m | \u001b[0m 0.727   \u001b[0m | \u001b[0m 0.9175  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.62923\tvalid_1's rmse: 1.76915\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's rmse: 2.65815\tvalid_1's rmse: 1.76532\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.765   \u001b[0m | \u001b[0m 0.2949  \u001b[0m | \u001b[0m 1.906   \u001b[0m | \u001b[0m 0.4909  \u001b[0m | \u001b[0m 299.9   \u001b[0m | \u001b[0m 5.015   \u001b[0m | \u001b[0m 4.217e+0\u001b[0m | \u001b[0m 0.4911  \u001b[0m | \u001b[0m 1.011e+0\u001b[0m | \u001b[0m 0.6125  \u001b[0m | \u001b[0m 0.2306  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.91022\tvalid_1's rmse: 1.86266\n",
      "[200]\ttraining's rmse: 2.67703\tvalid_1's rmse: 1.7833\n",
      "[300]\ttraining's rmse: 2.60594\tvalid_1's rmse: 1.77\n",
      "[400]\ttraining's rmse: 2.56913\tvalid_1's rmse: 1.75531\n",
      "[500]\ttraining's rmse: 2.54801\tvalid_1's rmse: 1.74839\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttraining's rmse: 2.55052\tvalid_1's rmse: 1.74836\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.748   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.8725  \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 6e+03   \u001b[0m | \u001b[0m 0.6745  \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.64873\tvalid_1's rmse: 1.77927\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's rmse: 2.68663\tvalid_1's rmse: 1.77333\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.773   \u001b[0m | \u001b[0m 0.145   \u001b[0m | \u001b[0m 2.096   \u001b[0m | \u001b[0m 0.5478  \u001b[0m | \u001b[0m 293.4   \u001b[0m | \u001b[0m 7.229   \u001b[0m | \u001b[0m 3.006e+0\u001b[0m | \u001b[0m 0.4264  \u001b[0m | \u001b[0m 1.869e+0\u001b[0m | \u001b[0m 0.3071  \u001b[0m | \u001b[0m 0.2201  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.85174\tvalid_1's rmse: 1.80504\n",
      "[200]\ttraining's rmse: 2.64681\tvalid_1's rmse: 1.77539\n",
      "[300]\ttraining's rmse: 2.59306\tvalid_1's rmse: 1.75976\n",
      "[400]\ttraining's rmse: 2.56442\tvalid_1's rmse: 1.7476\n",
      "[500]\ttraining's rmse: 2.54264\tvalid_1's rmse: 1.737\n",
      "[600]\ttraining's rmse: 2.53001\tvalid_1's rmse: 1.73435\n",
      "[700]\ttraining's rmse: 2.51771\tvalid_1's rmse: 1.72971\n",
      "[800]\ttraining's rmse: 2.50935\tvalid_1's rmse: 1.73048\n",
      "Early stopping, best iteration is:\n",
      "[762]\ttraining's rmse: 2.51254\tvalid_1's rmse: 1.72777\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.728   \u001b[0m | \u001b[0m 0.1086  \u001b[0m | \u001b[0m 3.081   \u001b[0m | \u001b[0m 0.1714  \u001b[0m | \u001b[0m 291.8   \u001b[0m | \u001b[0m 8.866   \u001b[0m | \u001b[0m 4.003e+0\u001b[0m | \u001b[0m 0.8831  \u001b[0m | \u001b[0m 2.998e+0\u001b[0m | \u001b[0m 0.6347  \u001b[0m | \u001b[0m 0.7991  \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
    "|  4        | -1.712    |  0.8611   |  13.63    |  0.8275   |  298.4    |  0.7706   |  3.021e+0 |  0.6468   |  2.962e+0 |  0.2014   |  0.8631   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample':  0.8611 ,\n",
    "                    'subsample_freq': 13,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2962, \n",
    "                    'min_data_in_leaf': 3021, \n",
    "                    'feature_fraction': 0.8275,\n",
    "                    'max_bin': 298,\n",
    "                    'n_estimators': 150,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':0,\n",
    "                    'min_split_gain':0.6468,\n",
    "                    'reg_alpha': 0.2014,\n",
    "                    'reg_lambda':  0.8631,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.69645\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('TX_2')\n",
    "store_id = 'TX_2'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#.163887\n",
    "#1.71833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4737167 entries, 0 to 4737166\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 632.7 MB\n",
      "None\n",
      "(4566423, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# TX_3\n",
    "grid_df, features_columns = get_data_by_store('TX_3')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.35054\tvalid_1's rmse: 1.73475\n",
      "[200]\ttraining's rmse: 2.22485\tvalid_1's rmse: 1.73453\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's rmse: 2.32758\tvalid_1's rmse: 1.73315\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.733   \u001b[0m | \u001b[0m 0.1514  \u001b[0m | \u001b[0m 11.54   \u001b[0m | \u001b[0m 0.5272  \u001b[0m | \u001b[0m 278.7   \u001b[0m | \u001b[0m 7.944   \u001b[0m | \u001b[0m 5.486e+0\u001b[0m | \u001b[0m 0.5564  \u001b[0m | \u001b[0m 1.601e+0\u001b[0m | \u001b[0m 0.5006  \u001b[0m | \u001b[0m 0.1111  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.37092\tvalid_1's rmse: 1.74483\n",
      "[200]\ttraining's rmse: 2.2531\tvalid_1's rmse: 1.72912\n",
      "[300]\ttraining's rmse: 2.21546\tvalid_1's rmse: 1.71935\n",
      "[400]\ttraining's rmse: 2.19182\tvalid_1's rmse: 1.71175\n",
      "[500]\ttraining's rmse: 2.17566\tvalid_1's rmse: 1.70771\n",
      "[600]\ttraining's rmse: 2.16484\tvalid_1's rmse: 1.70496\n",
      "[700]\ttraining's rmse: 2.15669\tvalid_1's rmse: 1.70385\n",
      "[800]\ttraining's rmse: 2.14926\tvalid_1's rmse: 1.70151\n",
      "Early stopping, best iteration is:\n",
      "[790]\ttraining's rmse: 2.1498\tvalid_1's rmse: 1.70121\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-1.701   \u001b[0m | \u001b[95m 0.249   \u001b[0m | \u001b[95m 10.62   \u001b[0m | \u001b[95m 0.2478  \u001b[0m | \u001b[95m 228.1   \u001b[0m | \u001b[95m 5.703   \u001b[0m | \u001b[95m 4.432e+0\u001b[0m | \u001b[95m 0.7119  \u001b[0m | \u001b[95m 2.726e+0\u001b[0m | \u001b[95m 0.5791  \u001b[0m | \u001b[95m 0.167   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.9234\tvalid_1's rmse: 2.03519\n",
      "[200]\ttraining's rmse: 2.54862\tvalid_1's rmse: 1.80139\n",
      "[300]\ttraining's rmse: 2.44556\tvalid_1's rmse: 1.7861\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttraining's rmse: 2.46288\tvalid_1's rmse: 1.78294\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.783   \u001b[0m | \u001b[0m 0.4691  \u001b[0m | \u001b[0m 6.493   \u001b[0m | \u001b[0m 0.1644  \u001b[0m | \u001b[0m 181.5   \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m 4.036e+0\u001b[0m | \u001b[0m 0.1958  \u001b[0m | \u001b[0m 1.414e+0\u001b[0m | \u001b[0m 0.8192  \u001b[0m | \u001b[0m 0.5031  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.21901\tvalid_1's rmse: 1.69477\n",
      "[200]\ttraining's rmse: 2.12521\tvalid_1's rmse: 1.68783\n",
      "[300]\ttraining's rmse: 2.08894\tvalid_1's rmse: 1.68575\n",
      "[400]\ttraining's rmse: 2.07021\tvalid_1's rmse: 1.6851\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's rmse: 2.07098\tvalid_1's rmse: 1.68504\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-1.685   \u001b[0m | \u001b[95m 0.8975  \u001b[0m | \u001b[95m 1.521   \u001b[0m | \u001b[95m 0.2709  \u001b[0m | \u001b[95m 127.3   \u001b[0m | \u001b[95m-0.5098  \u001b[0m | \u001b[95m 5.995e+0\u001b[0m | \u001b[95m 0.7792  \u001b[0m | \u001b[95m 2.992e+0\u001b[0m | \u001b[95m 0.14    \u001b[0m | \u001b[95m 0.3187  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.22523\tvalid_1's rmse: 1.71326\n",
      "[200]\ttraining's rmse: 2.16045\tvalid_1's rmse: 1.71763\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's rmse: 2.22523\tvalid_1's rmse: 1.71326\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.713   \u001b[0m | \u001b[0m 0.3866  \u001b[0m | \u001b[0m 9.133   \u001b[0m | \u001b[0m 0.762   \u001b[0m | \u001b[0m 298.5   \u001b[0m | \u001b[0m 5.677   \u001b[0m | \u001b[0m 3.009e+0\u001b[0m | \u001b[0m 0.679   \u001b[0m | \u001b[0m 2.999e+0\u001b[0m | \u001b[0m 0.6589  \u001b[0m | \u001b[0m 0.2798  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.21464\tvalid_1's rmse: 1.70991\n",
      "[200]\ttraining's rmse: 2.15275\tvalid_1's rmse: 1.71222\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's rmse: 2.20343\tvalid_1's rmse: 1.70859\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.709   \u001b[0m | \u001b[0m 0.8737  \u001b[0m | \u001b[0m 7.187   \u001b[0m | \u001b[0m 0.8899  \u001b[0m | \u001b[0m 292.2   \u001b[0m | \u001b[0m 5.445   \u001b[0m | \u001b[0m 5.956e+0\u001b[0m | \u001b[0m 0.1742  \u001b[0m | \u001b[0m 2.989e+0\u001b[0m | \u001b[0m 0.4972  \u001b[0m | \u001b[0m 0.423   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.19161\tvalid_1's rmse: 1.69149\n",
      "[200]\ttraining's rmse: 2.11942\tvalid_1's rmse: 1.6895\n",
      "[300]\ttraining's rmse: 2.1006\tvalid_1's rmse: 1.68815\n",
      "[400]\ttraining's rmse: 2.08913\tvalid_1's rmse: 1.68602\n",
      "[500]\ttraining's rmse: 2.07819\tvalid_1's rmse: 1.68642\n",
      "Early stopping, best iteration is:\n",
      "[429]\ttraining's rmse: 2.08608\tvalid_1's rmse: 1.6856\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.686   \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 0.4262  \u001b[0m | \u001b[0m 100.7   \u001b[0m | \u001b[0m 10.87   \u001b[0m | \u001b[0m 4.651e+0\u001b[0m | \u001b[0m 0.6253  \u001b[0m | \u001b[0m 2.994e+0\u001b[0m | \u001b[0m 0.819   \u001b[0m | \u001b[0m 0.3437  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.3138\tvalid_1's rmse: 1.72171\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's rmse: 2.33318\tvalid_1's rmse: 1.72096\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.721   \u001b[0m | \u001b[0m 0.3078  \u001b[0m | \u001b[0m 17.21   \u001b[0m | \u001b[0m 0.3549  \u001b[0m | \u001b[0m 100.5   \u001b[0m | \u001b[0m 5.533   \u001b[0m | \u001b[0m 5.99e+03\u001b[0m | \u001b[0m 0.5516  \u001b[0m | \u001b[0m 2.236e+0\u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.9007  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.41277\tvalid_1's rmse: 1.74279\n",
      "[200]\ttraining's rmse: 2.25153\tvalid_1's rmse: 1.73166\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's rmse: 2.32256\tvalid_1's rmse: 1.72311\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.723   \u001b[0m | \u001b[0m 0.1296  \u001b[0m | \u001b[0m 1.165   \u001b[0m | \u001b[0m 0.6348  \u001b[0m | \u001b[0m 107.0   \u001b[0m | \u001b[0m 9.96    \u001b[0m | \u001b[0m 5.999e+0\u001b[0m | \u001b[0m 0.26    \u001b[0m | \u001b[0m 1.011e+0\u001b[0m | \u001b[0m 0.3702  \u001b[0m | \u001b[0m 0.2091  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.16884\tvalid_1's rmse: 1.69147\n",
      "[200]\ttraining's rmse: 2.10885\tvalid_1's rmse: 1.68963\n",
      "[300]\ttraining's rmse: 2.09354\tvalid_1's rmse: 1.68908\n",
      "[400]\ttraining's rmse: 2.0812\tvalid_1's rmse: 1.68672\n",
      "[500]\ttraining's rmse: 2.07072\tvalid_1's rmse: 1.68615\n",
      "[600]\ttraining's rmse: 2.06471\tvalid_1's rmse: 1.68587\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's rmse: 2.06619\tvalid_1's rmse: 1.68576\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.686   \u001b[0m | \u001b[0m 0.8103  \u001b[0m | \u001b[0m 1.056   \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 103.7   \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 3.738e+0\u001b[0m | \u001b[0m 0.3261  \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.8616  \u001b[0m | \u001b[0m 0.8966  \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|  4        | -1.685    |  0.8975   |  1.521    |  0.2709   |  127.3    | -0.5098   |  5.995e+0 |  0.7792   |  2.992e+0 |  0.14     |  0.3187   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample':  0.8975  ,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2992, \n",
    "                    'min_data_in_leaf': 5995, \n",
    "                    'feature_fraction': 0.2709,\n",
    "                    'max_bin': 127,\n",
    "                    'n_estimators': 400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':0,\n",
    "                    'min_split_gain':0.7792,\n",
    "                    'reg_alpha': 0.14 ,\n",
    "                    'reg_lambda':  0.3187,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.68803\n",
      "[200]\tvalid_0's rmse: 1.67352\n",
      "[300]\tvalid_0's rmse: 1.6638\n",
      "[400]\tvalid_0's rmse: 1.65826\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('TX_3')\n",
    "store_id = 'TX_3'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.62453\n",
    "#1.6915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4560767 entries, 0 to 4560766\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 609.2 MB\n",
      "None\n",
      "(4390023, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# WI_1\n",
    "grid_df, features_columns = get_data_by_store('WI_1')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.70708\tvalid_1's rmse: 1.60331\n",
      "[200]\ttraining's rmse: 1.66748\tvalid_1's rmse: 1.59281\n",
      "[300]\ttraining's rmse: 1.64965\tvalid_1's rmse: 1.59201\n",
      "[400]\ttraining's rmse: 1.63769\tvalid_1's rmse: 1.59142\n",
      "[500]\ttraining's rmse: 1.62792\tvalid_1's rmse: 1.59082\n",
      "Early stopping, best iteration is:\n",
      "[474]\ttraining's rmse: 1.63037\tvalid_1's rmse: 1.59053\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.591   \u001b[0m | \u001b[0m 0.7091  \u001b[0m | \u001b[0m 11.13   \u001b[0m | \u001b[0m 0.6197  \u001b[0m | \u001b[0m 175.1   \u001b[0m | \u001b[0m 0.8421  \u001b[0m | \u001b[0m 4.872e+0\u001b[0m | \u001b[0m 0.5806  \u001b[0m | \u001b[0m 2.884e+0\u001b[0m | \u001b[0m 0.8454  \u001b[0m | \u001b[0m 0.696   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.73709\tvalid_1's rmse: 1.61129\n",
      "[200]\ttraining's rmse: 1.69271\tvalid_1's rmse: 1.59976\n",
      "[300]\ttraining's rmse: 1.67913\tvalid_1's rmse: 1.59604\n",
      "[400]\ttraining's rmse: 1.67029\tvalid_1's rmse: 1.59487\n",
      "[500]\ttraining's rmse: 1.66326\tvalid_1's rmse: 1.5943\n",
      "[600]\ttraining's rmse: 1.65731\tvalid_1's rmse: 1.59273\n",
      "[700]\ttraining's rmse: 1.65183\tvalid_1's rmse: 1.59257\n",
      "[800]\ttraining's rmse: 1.64744\tvalid_1's rmse: 1.59241\n",
      "Early stopping, best iteration is:\n",
      "[773]\ttraining's rmse: 1.64872\tvalid_1's rmse: 1.59198\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.592   \u001b[0m | \u001b[0m 0.3561  \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 0.5089  \u001b[0m | \u001b[0m 137.8   \u001b[0m | \u001b[0m-0.86    \u001b[0m | \u001b[0m 5.397e+0\u001b[0m | \u001b[0m 0.2693  \u001b[0m | \u001b[0m 1.285e+0\u001b[0m | \u001b[0m 0.4007  \u001b[0m | \u001b[0m 0.6608  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.8237\tvalid_1's rmse: 1.65779\n",
      "[200]\ttraining's rmse: 1.75834\tvalid_1's rmse: 1.61889\n",
      "[300]\ttraining's rmse: 1.73352\tvalid_1's rmse: 1.60654\n",
      "[400]\ttraining's rmse: 1.72036\tvalid_1's rmse: 1.6032\n",
      "[500]\ttraining's rmse: 1.71313\tvalid_1's rmse: 1.60128\n",
      "[600]\ttraining's rmse: 1.70763\tvalid_1's rmse: 1.59887\n",
      "[700]\ttraining's rmse: 1.70387\tvalid_1's rmse: 1.5975\n",
      "[800]\ttraining's rmse: 1.70055\tvalid_1's rmse: 1.59658\n",
      "[900]\ttraining's rmse: 1.69803\tvalid_1's rmse: 1.59607\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 1.69923\tvalid_1's rmse: 1.59604\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.596   \u001b[0m | \u001b[0m 0.1041  \u001b[0m | \u001b[0m 9.148   \u001b[0m | \u001b[0m 0.6142  \u001b[0m | \u001b[0m 277.2   \u001b[0m | \u001b[0m 9.583   \u001b[0m | \u001b[0m 5.745e+0\u001b[0m | \u001b[0m 0.2813  \u001b[0m | \u001b[0m 2.691e+0\u001b[0m | \u001b[0m 0.5391  \u001b[0m | \u001b[0m 0.4106  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.78519\tvalid_1's rmse: 1.64555\n",
      "[200]\ttraining's rmse: 1.73264\tvalid_1's rmse: 1.61626\n",
      "[300]\ttraining's rmse: 1.70788\tvalid_1's rmse: 1.60504\n",
      "[400]\ttraining's rmse: 1.69528\tvalid_1's rmse: 1.60143\n",
      "[500]\ttraining's rmse: 1.68643\tvalid_1's rmse: 1.59959\n",
      "[600]\ttraining's rmse: 1.67951\tvalid_1's rmse: 1.59818\n",
      "[700]\ttraining's rmse: 1.67314\tvalid_1's rmse: 1.5975\n",
      "[800]\ttraining's rmse: 1.66915\tvalid_1's rmse: 1.59678\n",
      "[900]\ttraining's rmse: 1.66496\tvalid_1's rmse: 1.59628\n",
      "[1000]\ttraining's rmse: 1.66177\tvalid_1's rmse: 1.59635\n",
      "Early stopping, best iteration is:\n",
      "[904]\ttraining's rmse: 1.66478\tvalid_1's rmse: 1.59624\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.596   \u001b[0m | \u001b[0m 0.516   \u001b[0m | \u001b[0m 7.533   \u001b[0m | \u001b[0m 0.1365  \u001b[0m | \u001b[0m 292.3   \u001b[0m | \u001b[0m 8.771   \u001b[0m | \u001b[0m 3.01e+03\u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m 1.001e+0\u001b[0m | \u001b[0m 0.6915  \u001b[0m | \u001b[0m 0.2412  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.7417\tvalid_1's rmse: 1.62322\n",
      "[200]\ttraining's rmse: 1.69376\tvalid_1's rmse: 1.60057\n",
      "[300]\ttraining's rmse: 1.67482\tvalid_1's rmse: 1.59591\n",
      "[400]\ttraining's rmse: 1.6631\tvalid_1's rmse: 1.59459\n",
      "[500]\ttraining's rmse: 1.6545\tvalid_1's rmse: 1.59388\n",
      "[600]\ttraining's rmse: 1.64837\tvalid_1's rmse: 1.59398\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's rmse: 1.65286\tvalid_1's rmse: 1.59374\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.594   \u001b[0m | \u001b[0m 0.8345  \u001b[0m | \u001b[0m 16.65   \u001b[0m | \u001b[0m 0.191   \u001b[0m | \u001b[0m 104.6   \u001b[0m | \u001b[0m 10.88   \u001b[0m | \u001b[0m 3.055e+0\u001b[0m | \u001b[0m 0.3242  \u001b[0m | \u001b[0m 2.991e+0\u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 0.9765  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.0318\tvalid_1's rmse: 1.84954\n",
      "[200]\ttraining's rmse: 1.86983\tvalid_1's rmse: 1.70909\n",
      "[300]\ttraining's rmse: 1.79967\tvalid_1's rmse: 1.65483\n",
      "[400]\ttraining's rmse: 1.76717\tvalid_1's rmse: 1.6355\n",
      "[500]\ttraining's rmse: 1.75288\tvalid_1's rmse: 1.62847\n",
      "[600]\ttraining's rmse: 1.74635\tvalid_1's rmse: 1.62539\n",
      "[700]\ttraining's rmse: 1.7417\tvalid_1's rmse: 1.62306\n",
      "[800]\ttraining's rmse: 1.73838\tvalid_1's rmse: 1.62161\n",
      "[900]\ttraining's rmse: 1.73503\tvalid_1's rmse: 1.62031\n",
      "[1000]\ttraining's rmse: 1.73297\tvalid_1's rmse: 1.61939\n",
      "[1100]\ttraining's rmse: 1.73093\tvalid_1's rmse: 1.61889\n",
      "[1200]\ttraining's rmse: 1.72962\tvalid_1's rmse: 1.61847\n",
      "[1300]\ttraining's rmse: 1.72845\tvalid_1's rmse: 1.61842\n",
      "[1400]\ttraining's rmse: 1.72731\tvalid_1's rmse: 1.61821\n",
      "[1500]\ttraining's rmse: 1.72659\tvalid_1's rmse: 1.61811\n",
      "[1600]\ttraining's rmse: 1.72598\tvalid_1's rmse: 1.61794\n",
      "Early stopping, best iteration is:\n",
      "[1573]\ttraining's rmse: 1.7261\tvalid_1's rmse: 1.61793\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.618   \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 5.652   \u001b[0m | \u001b[0m 0.66    \u001b[0m | \u001b[0m 100.2   \u001b[0m | \u001b[0m 1.329   \u001b[0m | \u001b[0m 5.964e+0\u001b[0m | \u001b[0m 0.2525  \u001b[0m | \u001b[0m 2.974e+0\u001b[0m | \u001b[0m 0.9519  \u001b[0m | \u001b[0m 0.6938  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.8482\tvalid_1's rmse: 1.69391\n",
      "[200]\ttraining's rmse: 1.756\tvalid_1's rmse: 1.62644\n",
      "[300]\ttraining's rmse: 1.73389\tvalid_1's rmse: 1.61638\n",
      "[400]\ttraining's rmse: 1.72467\tvalid_1's rmse: 1.61238\n",
      "[500]\ttraining's rmse: 1.72001\tvalid_1's rmse: 1.61079\n",
      "[600]\ttraining's rmse: 1.71661\tvalid_1's rmse: 1.60993\n",
      "[700]\ttraining's rmse: 1.71387\tvalid_1's rmse: 1.60983\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's rmse: 1.71611\tvalid_1's rmse: 1.60969\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.61    \u001b[0m | \u001b[0m 0.6383  \u001b[0m | \u001b[0m 2.327   \u001b[0m | \u001b[0m 0.486   \u001b[0m | \u001b[0m 298.8   \u001b[0m | \u001b[0m 2.885   \u001b[0m | \u001b[0m 4.145e+0\u001b[0m | \u001b[0m 0.6321  \u001b[0m | \u001b[0m 2.061e+0\u001b[0m | \u001b[0m 0.1755  \u001b[0m | \u001b[0m 0.3416  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.73311\tvalid_1's rmse: 1.61631\n",
      "[200]\ttraining's rmse: 1.70525\tvalid_1's rmse: 1.60405\n",
      "[300]\ttraining's rmse: 1.69638\tvalid_1's rmse: 1.60219\n",
      "[400]\ttraining's rmse: 1.69246\tvalid_1's rmse: 1.60123\n",
      "[500]\ttraining's rmse: 1.68894\tvalid_1's rmse: 1.60055\n",
      "[600]\ttraining's rmse: 1.68644\tvalid_1's rmse: 1.59983\n",
      "[700]\ttraining's rmse: 1.68391\tvalid_1's rmse: 1.59882\n",
      "[800]\ttraining's rmse: 1.68177\tvalid_1's rmse: 1.59823\n",
      "[900]\ttraining's rmse: 1.67973\tvalid_1's rmse: 1.59794\n",
      "[1000]\ttraining's rmse: 1.678\tvalid_1's rmse: 1.59779\n",
      "[1100]\ttraining's rmse: 1.67546\tvalid_1's rmse: 1.59723\n",
      "[1200]\ttraining's rmse: 1.67336\tvalid_1's rmse: 1.5971\n",
      "[1300]\ttraining's rmse: 1.67131\tvalid_1's rmse: 1.59633\n",
      "Early stopping, best iteration is:\n",
      "[1291]\ttraining's rmse: 1.67145\tvalid_1's rmse: 1.59625\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.596   \u001b[0m | \u001b[0m 0.8716  \u001b[0m | \u001b[0m 14.2    \u001b[0m | \u001b[0m 0.7534  \u001b[0m | \u001b[0m 299.2   \u001b[0m | \u001b[0m 5.537   \u001b[0m | \u001b[0m 6e+03   \u001b[0m | \u001b[0m 0.2324  \u001b[0m | \u001b[0m 1.019e+0\u001b[0m | \u001b[0m 0.1057  \u001b[0m | \u001b[0m 0.3305  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.78224\tvalid_1's rmse: 1.648\n",
      "[200]\ttraining's rmse: 1.72313\tvalid_1's rmse: 1.61276\n",
      "[300]\ttraining's rmse: 1.71213\tvalid_1's rmse: 1.60797\n",
      "[400]\ttraining's rmse: 1.70657\tvalid_1's rmse: 1.6061\n",
      "[500]\ttraining's rmse: 1.70283\tvalid_1's rmse: 1.60621\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's rmse: 1.70426\tvalid_1's rmse: 1.60557\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.606   \u001b[0m | \u001b[0m 0.7247  \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 0.5904  \u001b[0m | \u001b[0m 292.4   \u001b[0m | \u001b[0m 3.588   \u001b[0m | \u001b[0m 4.789e+0\u001b[0m | \u001b[0m 0.7817  \u001b[0m | \u001b[0m 1.005e+0\u001b[0m | \u001b[0m 0.9384  \u001b[0m | \u001b[0m 0.8316  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.71193\tvalid_1's rmse: 1.60351\n",
      "[200]\ttraining's rmse: 1.67154\tvalid_1's rmse: 1.59234\n",
      "[300]\ttraining's rmse: 1.65547\tvalid_1's rmse: 1.59086\n",
      "[400]\ttraining's rmse: 1.64468\tvalid_1's rmse: 1.58931\n",
      "[500]\ttraining's rmse: 1.63574\tvalid_1's rmse: 1.58923\n",
      "Early stopping, best iteration is:\n",
      "[485]\ttraining's rmse: 1.63682\tvalid_1's rmse: 1.58909\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-1.589   \u001b[0m | \u001b[95m 0.3897  \u001b[0m | \u001b[95m 10.74   \u001b[0m | \u001b[95m 0.6065  \u001b[0m | \u001b[95m 101.7   \u001b[0m | \u001b[95m-0.6873  \u001b[0m | \u001b[95m 3.006e+0\u001b[0m | \u001b[95m 0.4203  \u001b[0m | \u001b[95m 1e+03   \u001b[0m | \u001b[95m 0.384   \u001b[0m | \u001b[95m 0.562   \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|  10       | -1.589    |  0.3897   |  10.74    |  0.6065   |  101.7    | -0.6873   |  3.006e+0 |  0.4203   |  1e+03    |  0.384    |  0.562    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.3897 ,\n",
    "                    'subsample_freq': 10,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1000, \n",
    "                    'min_data_in_leaf': 3006, \n",
    "                    'feature_fraction': 0.6065,\n",
    "                    'max_bin': 101,\n",
    "                    'n_estimators': 500,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':0,\n",
    "                    'min_split_gain':0.4203,\n",
    "                    'reg_alpha': 0.384,\n",
    "                    'reg_lambda': 0.562,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.59786\n",
      "[200]\tvalid_0's rmse: 1.57898\n",
      "[300]\tvalid_0's rmse: 1.57013\n",
      "[400]\tvalid_0's rmse: 1.56394\n",
      "[500]\tvalid_0's rmse: 1.55878\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('WI_1')\n",
    "store_id = 'WI_1'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#.152818\n",
    "#100:1.59878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4646580 entries, 0 to 4646579\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 620.6 MB\n",
      "None\n",
      "(4475836, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# WI_2\n",
    "grid_df, features_columns = get_data_by_store('WI_2')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.68086\tvalid_1's rmse: 2.71022\n",
      "[200]\ttraining's rmse: 2.63946\tvalid_1's rmse: 2.63889\n",
      "[300]\ttraining's rmse: 2.6293\tvalid_1's rmse: 2.62378\n",
      "[400]\ttraining's rmse: 2.62124\tvalid_1's rmse: 2.61617\n",
      "[500]\ttraining's rmse: 2.6152\tvalid_1's rmse: 2.61159\n",
      "[600]\ttraining's rmse: 2.61044\tvalid_1's rmse: 2.60814\n",
      "[700]\ttraining's rmse: 2.60625\tvalid_1's rmse: 2.60451\n",
      "[800]\ttraining's rmse: 2.60246\tvalid_1's rmse: 2.60162\n",
      "[900]\ttraining's rmse: 2.59887\tvalid_1's rmse: 2.59938\n",
      "[1000]\ttraining's rmse: 2.59603\tvalid_1's rmse: 2.59889\n",
      "[1100]\ttraining's rmse: 2.59271\tvalid_1's rmse: 2.59761\n",
      "[1200]\ttraining's rmse: 2.58977\tvalid_1's rmse: 2.59584\n",
      "[1300]\ttraining's rmse: 2.58721\tvalid_1's rmse: 2.59488\n",
      "[1400]\ttraining's rmse: 2.58417\tvalid_1's rmse: 2.59328\n",
      "[1500]\ttraining's rmse: 2.58177\tvalid_1's rmse: 2.59279\n",
      "[1600]\ttraining's rmse: 2.57859\tvalid_1's rmse: 2.59109\n",
      "[1700]\ttraining's rmse: 2.57655\tvalid_1's rmse: 2.59071\n",
      "[1800]\ttraining's rmse: 2.57431\tvalid_1's rmse: 2.58974\n",
      "[1900]\ttraining's rmse: 2.57218\tvalid_1's rmse: 2.58899\n",
      "[2000]\ttraining's rmse: 2.57045\tvalid_1's rmse: 2.58851\n",
      "[2100]\ttraining's rmse: 2.56879\tvalid_1's rmse: 2.58977\n",
      "Early stopping, best iteration is:\n",
      "[2001]\ttraining's rmse: 2.57045\tvalid_1's rmse: 2.5885\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.589   \u001b[0m | \u001b[0m 0.7694  \u001b[0m | \u001b[0m 3.62    \u001b[0m | \u001b[0m 0.6542  \u001b[0m | \u001b[0m 111.2   \u001b[0m | \u001b[0m 6.34    \u001b[0m | \u001b[0m 5.27e+03\u001b[0m | \u001b[0m 0.278   \u001b[0m | \u001b[0m 2.168e+0\u001b[0m | \u001b[0m 0.4565  \u001b[0m | \u001b[0m 0.4951  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.78914\tvalid_1's rmse: 2.88869\n",
      "[200]\ttraining's rmse: 2.70631\tvalid_1's rmse: 2.74126\n",
      "[300]\ttraining's rmse: 2.67855\tvalid_1's rmse: 2.69855\n",
      "[400]\ttraining's rmse: 2.66683\tvalid_1's rmse: 2.68052\n",
      "[500]\ttraining's rmse: 2.65724\tvalid_1's rmse: 2.66666\n",
      "[600]\ttraining's rmse: 2.65041\tvalid_1's rmse: 2.66591\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's rmse: 2.65477\tvalid_1's rmse: 2.66245\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.662   \u001b[0m | \u001b[0m 0.116   \u001b[0m | \u001b[0m 13.11   \u001b[0m | \u001b[0m 0.3806  \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m-0.1715  \u001b[0m | \u001b[0m 5.216e+0\u001b[0m | \u001b[0m 0.1885  \u001b[0m | \u001b[0m 2.171e+0\u001b[0m | \u001b[0m 0.6159  \u001b[0m | \u001b[0m 0.7227  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.73162\tvalid_1's rmse: 2.79052\n",
      "[200]\ttraining's rmse: 2.66268\tvalid_1's rmse: 2.67261\n",
      "[300]\ttraining's rmse: 2.64603\tvalid_1's rmse: 2.64994\n",
      "[400]\ttraining's rmse: 2.63695\tvalid_1's rmse: 2.63662\n",
      "[500]\ttraining's rmse: 2.62989\tvalid_1's rmse: 2.63215\n",
      "[600]\ttraining's rmse: 2.62396\tvalid_1's rmse: 2.62903\n",
      "[700]\ttraining's rmse: 2.6194\tvalid_1's rmse: 2.62347\n",
      "[800]\ttraining's rmse: 2.61496\tvalid_1's rmse: 2.62263\n",
      "[900]\ttraining's rmse: 2.61143\tvalid_1's rmse: 2.6202\n",
      "[1000]\ttraining's rmse: 2.60836\tvalid_1's rmse: 2.6168\n",
      "[1100]\ttraining's rmse: 2.60508\tvalid_1's rmse: 2.61751\n",
      "Early stopping, best iteration is:\n",
      "[1072]\ttraining's rmse: 2.60621\tvalid_1's rmse: 2.61615\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.616   \u001b[0m | \u001b[0m 0.2668  \u001b[0m | \u001b[0m 16.86   \u001b[0m | \u001b[0m 0.4647  \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 11.91   \u001b[0m | \u001b[0m 5.871e+0\u001b[0m | \u001b[0m 0.164   \u001b[0m | \u001b[0m 1.409e+0\u001b[0m | \u001b[0m 0.5829  \u001b[0m | \u001b[0m 0.6944  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.63008\tvalid_1's rmse: 2.65958\n",
      "[200]\ttraining's rmse: 2.58758\tvalid_1's rmse: 2.60155\n",
      "[300]\ttraining's rmse: 2.56577\tvalid_1's rmse: 2.59478\n",
      "[400]\ttraining's rmse: 2.55005\tvalid_1's rmse: 2.59286\n",
      "[500]\ttraining's rmse: 2.5387\tvalid_1's rmse: 2.59023\n",
      "[600]\ttraining's rmse: 2.52859\tvalid_1's rmse: 2.589\n",
      "[700]\ttraining's rmse: 2.52001\tvalid_1's rmse: 2.5879\n",
      "[800]\ttraining's rmse: 2.50934\tvalid_1's rmse: 2.58521\n",
      "Early stopping, best iteration is:\n",
      "[798]\ttraining's rmse: 2.50955\tvalid_1's rmse: 2.58497\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-2.585   \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 3e+03   \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 1e+03   \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.63008\tvalid_1's rmse: 2.65958\n",
      "[200]\ttraining's rmse: 2.58758\tvalid_1's rmse: 2.60155\n",
      "[300]\ttraining's rmse: 2.56577\tvalid_1's rmse: 2.59478\n",
      "[400]\ttraining's rmse: 2.55005\tvalid_1's rmse: 2.59286\n",
      "[500]\ttraining's rmse: 2.5387\tvalid_1's rmse: 2.59023\n",
      "[600]\ttraining's rmse: 2.52859\tvalid_1's rmse: 2.589\n",
      "[700]\ttraining's rmse: 2.52001\tvalid_1's rmse: 2.5879\n",
      "[800]\ttraining's rmse: 2.50934\tvalid_1's rmse: 2.58521\n",
      "Early stopping, best iteration is:\n",
      "[798]\ttraining's rmse: 2.50955\tvalid_1's rmse: 2.58497\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.585   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.66222\tvalid_1's rmse: 2.69014\n",
      "[200]\ttraining's rmse: 2.61598\tvalid_1's rmse: 2.61785\n",
      "[300]\ttraining's rmse: 2.5963\tvalid_1's rmse: 2.60291\n",
      "[400]\ttraining's rmse: 2.58263\tvalid_1's rmse: 2.59766\n",
      "[500]\ttraining's rmse: 2.57242\tvalid_1's rmse: 2.59372\n",
      "[600]\ttraining's rmse: 2.56406\tvalid_1's rmse: 2.59097\n",
      "[700]\ttraining's rmse: 2.55604\tvalid_1's rmse: 2.5891\n",
      "[800]\ttraining's rmse: 2.54796\tvalid_1's rmse: 2.58777\n",
      "[900]\ttraining's rmse: 2.54229\tvalid_1's rmse: 2.5863\n",
      "[1000]\ttraining's rmse: 2.53598\tvalid_1's rmse: 2.58454\n",
      "[1100]\ttraining's rmse: 2.53037\tvalid_1's rmse: 2.5827\n",
      "Early stopping, best iteration is:\n",
      "[1097]\ttraining's rmse: 2.53043\tvalid_1's rmse: 2.58258\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-2.583   \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 6e+03   \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 3e+03   \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.64913\tvalid_1's rmse: 2.67239\n",
      "[200]\ttraining's rmse: 2.60355\tvalid_1's rmse: 2.60743\n",
      "[300]\ttraining's rmse: 2.58354\tvalid_1's rmse: 2.59667\n",
      "[400]\ttraining's rmse: 2.56797\tvalid_1's rmse: 2.59062\n",
      "[500]\ttraining's rmse: 2.55718\tvalid_1's rmse: 2.58826\n",
      "[600]\ttraining's rmse: 2.54783\tvalid_1's rmse: 2.5867\n",
      "[700]\ttraining's rmse: 2.53941\tvalid_1's rmse: 2.5846\n",
      "[800]\ttraining's rmse: 2.53132\tvalid_1's rmse: 2.58278\n",
      "[900]\ttraining's rmse: 2.52538\tvalid_1's rmse: 2.58146\n",
      "Early stopping, best iteration is:\n",
      "[869]\ttraining's rmse: 2.52691\tvalid_1's rmse: 2.58124\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-2.581   \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 4.405e+0\u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 1e+03   \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.63032\tvalid_1's rmse: 2.65965\n",
      "[200]\ttraining's rmse: 2.58742\tvalid_1's rmse: 2.60497\n",
      "[300]\ttraining's rmse: 2.56621\tvalid_1's rmse: 2.59726\n",
      "[400]\ttraining's rmse: 2.54985\tvalid_1's rmse: 2.59382\n",
      "[500]\ttraining's rmse: 2.53774\tvalid_1's rmse: 2.5917\n",
      "[600]\ttraining's rmse: 2.5291\tvalid_1's rmse: 2.59058\n",
      "Early stopping, best iteration is:\n",
      "[540]\ttraining's rmse: 2.53418\tvalid_1's rmse: 2.58976\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.59    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.999e+0\u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.64762\tvalid_1's rmse: 2.66988\n",
      "[200]\ttraining's rmse: 2.60152\tvalid_1's rmse: 2.60474\n",
      "[300]\ttraining's rmse: 2.58172\tvalid_1's rmse: 2.59423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 2.56555\tvalid_1's rmse: 2.5894\n",
      "[500]\ttraining's rmse: 2.55552\tvalid_1's rmse: 2.58716\n",
      "[600]\ttraining's rmse: 2.54729\tvalid_1's rmse: 2.58679\n",
      "[700]\ttraining's rmse: 2.53931\tvalid_1's rmse: 2.58425\n",
      "[800]\ttraining's rmse: 2.53158\tvalid_1's rmse: 2.5823\n",
      "Early stopping, best iteration is:\n",
      "[794]\ttraining's rmse: 2.53217\tvalid_1's rmse: 2.58203\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.582   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 4.176e+0\u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.65951\tvalid_1's rmse: 2.68838\n",
      "[200]\ttraining's rmse: 2.6127\tvalid_1's rmse: 2.61598\n",
      "[300]\ttraining's rmse: 2.59311\tvalid_1's rmse: 2.59978\n",
      "[400]\ttraining's rmse: 2.57923\tvalid_1's rmse: 2.59401\n",
      "[500]\ttraining's rmse: 2.56902\tvalid_1's rmse: 2.59208\n",
      "[600]\ttraining's rmse: 2.56137\tvalid_1's rmse: 2.5911\n",
      "[700]\ttraining's rmse: 2.55376\tvalid_1's rmse: 2.58785\n",
      "[800]\ttraining's rmse: 2.54599\tvalid_1's rmse: 2.58654\n",
      "[900]\ttraining's rmse: 2.54017\tvalid_1's rmse: 2.5849\n",
      "[1000]\ttraining's rmse: 2.5342\tvalid_1's rmse: 2.58393\n",
      "[1100]\ttraining's rmse: 2.52866\tvalid_1's rmse: 2.58257\n",
      "[1200]\ttraining's rmse: 2.52427\tvalid_1's rmse: 2.58162\n",
      "[1300]\ttraining's rmse: 2.51952\tvalid_1's rmse: 2.58123\n",
      "Early stopping, best iteration is:\n",
      "[1290]\ttraining's rmse: 2.51983\tvalid_1's rmse: 2.58089\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-2.581   \u001b[0m | \u001b[95m 0.9     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.8677  \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 6e+03   \u001b[0m | \u001b[95m 0.1323  \u001b[0m | \u001b[95m 2.193e+0\u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|  10       | -2.581    |  0.9      |  1.0      |  0.8677   |  100.0    |  12.0     |  6e+03    |  0.1323   |  2.193e+0 |  0.1      |  0.1      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.9 ,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2193, \n",
    "                    'min_data_in_leaf': 6000, \n",
    "                    'feature_fraction': 0.8677,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 1300,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':12,\n",
    "                    'min_split_gain':0.1323,\n",
    "                    'reg_alpha': 0.1,\n",
    "                    'reg_lambda': 0.1,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.66479\n",
      "[200]\tvalid_0's rmse: 2.57496\n",
      "[300]\tvalid_0's rmse: 2.54272\n",
      "[400]\tvalid_0's rmse: 2.52461\n",
      "[500]\tvalid_0's rmse: 2.51358\n",
      "[600]\tvalid_0's rmse: 2.50669\n",
      "[700]\tvalid_0's rmse: 2.49751\n",
      "[800]\tvalid_0's rmse: 2.49216\n",
      "[900]\tvalid_0's rmse: 2.48606\n",
      "[1000]\tvalid_0's rmse: 2.48031\n",
      "[1100]\tvalid_0's rmse: 2.47645\n",
      "[1200]\tvalid_0's rmse: 2.4702\n",
      "[1300]\tvalid_0's rmse: 2.46611\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('WI_2')\n",
    "store_id = 'WI_2'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.76026\n",
    "#100:2.69105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4772041 entries, 0 to 4772040\n",
      "Data columns (total 75 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "item_id                   category\n",
      "dept_id                   category\n",
      "cat_id                    category\n",
      "release                   int16\n",
      "sell_price                float16\n",
      "price_max                 float16\n",
      "price_min                 float16\n",
      "price_std                 float16\n",
      "price_mean                float16\n",
      "price_norm                float16\n",
      "price_nunique             float16\n",
      "item_nunique              int16\n",
      "price_momentum            float16\n",
      "price_momentum_m          float16\n",
      "price_momentum_y          float16\n",
      "event_name_1              category\n",
      "event_type_1              category\n",
      "event_name_2              category\n",
      "event_type_2              category\n",
      "snap_CA                   category\n",
      "snap_TX                   category\n",
      "snap_WI                   category\n",
      "tm_d                      int8\n",
      "tm_w                      int8\n",
      "tm_m                      int8\n",
      "tm_y                      int8\n",
      "tm_wm                     int8\n",
      "tm_dw                     int8\n",
      "tm_w_end                  int8\n",
      "enc_cat_id_mean           float16\n",
      "enc_cat_id_std            float16\n",
      "enc_dept_id_mean          float16\n",
      "enc_dept_id_std           float16\n",
      "enc_item_id_mean          float16\n",
      "enc_item_id_std           float16\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(11), float16(53), float64(1), int16(3), int8(7)\n",
      "memory usage: 637.4 MB\n",
      "None\n",
      "(4601297, 72)\n",
      "(85372, 72)\n"
     ]
    }
   ],
   "source": [
    "# WI_3\n",
    "grid_df, features_columns = get_data_by_store('WI_3')\n",
    "print(grid_df.info())\n",
    "train_mask = grid_df['d']<=(END_TRAIN-P_HORIZON)\n",
    "valid_mask = (grid_df['d']>(END_TRAIN-P_HORIZON)) & (grid_df['d']<=END_TRAIN)\n",
    "print(grid_df[train_mask][features_columns].shape)\n",
    "print(grid_df[valid_mask][features_columns].shape)\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "X_valid=grid_df[valid_mask][features_columns]\n",
    "y_valid=grid_df[valid_mask][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    bagging_freq,\n",
    "    colsample_bytree,\n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "    min_split_gain,\n",
    "    max_bin\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    bagging_freq=int(bagging_freq)\n",
    "    max_bin=int(max_bin)\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(bagging_freq)==int\n",
    "    assert type(max_bin)==int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'tweedie_variance_power': 1.1,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'bagging_freq':bagging_freq,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_bin':max_bin,\n",
    "              'min_split_gain':min_split_gain,\n",
    "              'objective': 'tweedie',\n",
    "              'boosting_type':'gbdt',\n",
    "              'boost_from_average': False,\n",
    "              'learning_rate': 0.03,\n",
    "              'metric':'rmse',\n",
    "              'verbose': -1}    \n",
    "\n",
    "\n",
    "    model= lgb.train(param, train_data, num_boost_round = 10000, early_stopping_rounds = 100, valid_sets = [train_data, valid_data], verbose_eval = 100)\n",
    "    val_pred = model.predict(X_valid, num_iteration=model.best_iteration)  \n",
    "    \n",
    "    rmse =sqrt(mean_squared_error(val_pred, y_valid))\n",
    "\n",
    "    return -rmse\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (1000, 3000), \n",
    "    'min_data_in_leaf': (3000,6000),\n",
    "    'bagging_fraction' : (0.1,0.9),\n",
    "    'bagging_freq':(1,20),\n",
    "    'max_bin':(100,300),\n",
    "    'min_split_gain':(0.1,0.9),\n",
    "    'colsample_bytree' : (0.1,0.9), \n",
    "    'reg_alpha': (0.1, 1), \n",
    "    'reg_lambda': (0.1, 1),\n",
    "    'max_depth':(-1,12),\n",
    "}\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... |  max_bin  | max_depth | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.53321\tvalid_1's rmse: 1.97885\n",
      "[200]\ttraining's rmse: 2.42836\tvalid_1's rmse: 1.90522\n",
      "[300]\ttraining's rmse: 2.38866\tvalid_1's rmse: 1.88852\n",
      "[400]\ttraining's rmse: 2.36621\tvalid_1's rmse: 1.88078\n",
      "[500]\ttraining's rmse: 2.35214\tvalid_1's rmse: 1.87409\n",
      "[600]\ttraining's rmse: 2.34267\tvalid_1's rmse: 1.87066\n",
      "[700]\ttraining's rmse: 2.33468\tvalid_1's rmse: 1.86736\n",
      "[800]\ttraining's rmse: 2.32799\tvalid_1's rmse: 1.86547\n",
      "[900]\ttraining's rmse: 2.32226\tvalid_1's rmse: 1.86358\n",
      "[1000]\ttraining's rmse: 2.31734\tvalid_1's rmse: 1.86241\n",
      "[1100]\ttraining's rmse: 2.31175\tvalid_1's rmse: 1.86126\n",
      "[1200]\ttraining's rmse: 2.30756\tvalid_1's rmse: 1.85934\n",
      "[1300]\ttraining's rmse: 2.30463\tvalid_1's rmse: 1.8579\n",
      "[1400]\ttraining's rmse: 2.30001\tvalid_1's rmse: 1.85487\n",
      "[1500]\ttraining's rmse: 2.29649\tvalid_1's rmse: 1.85329\n",
      "[1600]\ttraining's rmse: 2.29231\tvalid_1's rmse: 1.85269\n",
      "[1700]\ttraining's rmse: 2.28912\tvalid_1's rmse: 1.85207\n",
      "[1800]\ttraining's rmse: 2.28535\tvalid_1's rmse: 1.85112\n",
      "[1900]\ttraining's rmse: 2.28243\tvalid_1's rmse: 1.85015\n",
      "Early stopping, best iteration is:\n",
      "[1892]\ttraining's rmse: 2.28238\tvalid_1's rmse: 1.84983\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.85    \u001b[0m | \u001b[0m 0.4607  \u001b[0m | \u001b[0m 18.18   \u001b[0m | \u001b[0m 0.255   \u001b[0m | \u001b[0m 119.2   \u001b[0m | \u001b[0m 5.296   \u001b[0m | \u001b[0m 5.501e+0\u001b[0m | \u001b[0m 0.8761  \u001b[0m | \u001b[0m 1.77e+03\u001b[0m | \u001b[0m 0.6403  \u001b[0m | \u001b[0m 0.7973  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.41537\tvalid_1's rmse: 1.91754\n",
      "[200]\ttraining's rmse: 2.33359\tvalid_1's rmse: 1.87871\n",
      "[300]\ttraining's rmse: 2.31364\tvalid_1's rmse: 1.8726\n",
      "[400]\ttraining's rmse: 2.29885\tvalid_1's rmse: 1.86695\n",
      "[500]\ttraining's rmse: 2.28958\tvalid_1's rmse: 1.86277\n",
      "[600]\ttraining's rmse: 2.28135\tvalid_1's rmse: 1.86047\n",
      "[700]\ttraining's rmse: 2.27365\tvalid_1's rmse: 1.85701\n",
      "[800]\ttraining's rmse: 2.26516\tvalid_1's rmse: 1.85481\n",
      "[900]\ttraining's rmse: 2.25897\tvalid_1's rmse: 1.85295\n",
      "[1000]\ttraining's rmse: 2.2549\tvalid_1's rmse: 1.85183\n",
      "[1100]\ttraining's rmse: 2.25084\tvalid_1's rmse: 1.85115\n",
      "[1200]\ttraining's rmse: 2.24656\tvalid_1's rmse: 1.8502\n",
      "[1300]\ttraining's rmse: 2.24289\tvalid_1's rmse: 1.8496\n",
      "[1400]\ttraining's rmse: 2.23916\tvalid_1's rmse: 1.84846\n",
      "[1500]\ttraining's rmse: 2.23572\tvalid_1's rmse: 1.84812\n",
      "[1600]\ttraining's rmse: 2.23197\tvalid_1's rmse: 1.84761\n",
      "[1700]\ttraining's rmse: 2.22891\tvalid_1's rmse: 1.84673\n",
      "[1800]\ttraining's rmse: 2.2253\tvalid_1's rmse: 1.84629\n",
      "[1900]\ttraining's rmse: 2.22288\tvalid_1's rmse: 1.84586\n",
      "[2000]\ttraining's rmse: 2.2209\tvalid_1's rmse: 1.84592\n",
      "[2100]\ttraining's rmse: 2.21853\tvalid_1's rmse: 1.84534\n",
      "[2200]\ttraining's rmse: 2.21547\tvalid_1's rmse: 1.84518\n",
      "Early stopping, best iteration is:\n",
      "[2159]\ttraining's rmse: 2.21689\tvalid_1's rmse: 1.845\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-1.845   \u001b[0m | \u001b[95m 0.83    \u001b[0m | \u001b[95m 5.833   \u001b[0m | \u001b[95m 0.6944  \u001b[0m | \u001b[95m 270.7   \u001b[0m | \u001b[95m 7.194   \u001b[0m | \u001b[95m 4.013e+0\u001b[0m | \u001b[95m 0.6251  \u001b[0m | \u001b[95m 1.352e+0\u001b[0m | \u001b[95m 0.6124  \u001b[0m | \u001b[95m 0.83    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.54661\tvalid_1's rmse: 2.00563\n",
      "[200]\ttraining's rmse: 2.4076\tvalid_1's rmse: 1.89443\n",
      "[300]\ttraining's rmse: 2.37242\tvalid_1's rmse: 1.88485\n",
      "[400]\ttraining's rmse: 2.35829\tvalid_1's rmse: 1.88119\n",
      "[500]\ttraining's rmse: 2.35328\tvalid_1's rmse: 1.87984\n",
      "[600]\ttraining's rmse: 2.34923\tvalid_1's rmse: 1.87921\n",
      "[700]\ttraining's rmse: 2.34662\tvalid_1's rmse: 1.87838\n",
      "[800]\ttraining's rmse: 2.3423\tvalid_1's rmse: 1.87654\n",
      "[900]\ttraining's rmse: 2.33878\tvalid_1's rmse: 1.8752\n",
      "[1000]\ttraining's rmse: 2.3371\tvalid_1's rmse: 1.87479\n",
      "[1100]\ttraining's rmse: 2.33368\tvalid_1's rmse: 1.87395\n",
      "[1200]\ttraining's rmse: 2.33204\tvalid_1's rmse: 1.87311\n",
      "[1300]\ttraining's rmse: 2.32957\tvalid_1's rmse: 1.87222\n",
      "[1400]\ttraining's rmse: 2.3274\tvalid_1's rmse: 1.87117\n",
      "[1500]\ttraining's rmse: 2.32505\tvalid_1's rmse: 1.87031\n",
      "[1600]\ttraining's rmse: 2.32262\tvalid_1's rmse: 1.87004\n",
      "[1700]\ttraining's rmse: 2.32173\tvalid_1's rmse: 1.86967\n",
      "[1800]\ttraining's rmse: 2.3208\tvalid_1's rmse: 1.86933\n",
      "[1900]\ttraining's rmse: 2.31901\tvalid_1's rmse: 1.86922\n",
      "[2000]\ttraining's rmse: 2.31806\tvalid_1's rmse: 1.8689\n",
      "[2100]\ttraining's rmse: 2.31702\tvalid_1's rmse: 1.86852\n",
      "[2200]\ttraining's rmse: 2.31565\tvalid_1's rmse: 1.86785\n",
      "[2300]\ttraining's rmse: 2.31473\tvalid_1's rmse: 1.86731\n",
      "[2400]\ttraining's rmse: 2.31346\tvalid_1's rmse: 1.86681\n",
      "[2500]\ttraining's rmse: 2.31182\tvalid_1's rmse: 1.86621\n",
      "[2600]\ttraining's rmse: 2.31111\tvalid_1's rmse: 1.8661\n",
      "[2700]\ttraining's rmse: 2.30969\tvalid_1's rmse: 1.8657\n",
      "[2800]\ttraining's rmse: 2.30837\tvalid_1's rmse: 1.86546\n",
      "[2900]\ttraining's rmse: 2.30769\tvalid_1's rmse: 1.86487\n",
      "[3000]\ttraining's rmse: 2.30683\tvalid_1's rmse: 1.86452\n",
      "[3100]\ttraining's rmse: 2.30575\tvalid_1's rmse: 1.86367\n",
      "[3200]\ttraining's rmse: 2.30517\tvalid_1's rmse: 1.86326\n",
      "Early stopping, best iteration is:\n",
      "[3176]\ttraining's rmse: 2.30521\tvalid_1's rmse: 1.86319\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.863   \u001b[0m | \u001b[0m 0.6709  \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 0.8691  \u001b[0m | \u001b[0m 179.4   \u001b[0m | \u001b[0m 3.904   \u001b[0m | \u001b[0m 3.409e+0\u001b[0m | \u001b[0m 0.1745  \u001b[0m | \u001b[0m 2.191e+0\u001b[0m | \u001b[0m 0.6703  \u001b[0m | \u001b[0m 0.7611  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.59016\tvalid_1's rmse: 2.00323\n",
      "[200]\ttraining's rmse: 2.45224\tvalid_1's rmse: 1.90038\n",
      "[300]\ttraining's rmse: 2.40344\tvalid_1's rmse: 1.8796\n",
      "[400]\ttraining's rmse: 2.3725\tvalid_1's rmse: 1.86872\n",
      "[500]\ttraining's rmse: 2.35212\tvalid_1's rmse: 1.86209\n",
      "[600]\ttraining's rmse: 2.33821\tvalid_1's rmse: 1.8586\n",
      "[700]\ttraining's rmse: 2.32556\tvalid_1's rmse: 1.85524\n",
      "[800]\ttraining's rmse: 2.31637\tvalid_1's rmse: 1.85377\n",
      "[900]\ttraining's rmse: 2.30632\tvalid_1's rmse: 1.85105\n",
      "[1000]\ttraining's rmse: 2.2986\tvalid_1's rmse: 1.85025\n",
      "[1100]\ttraining's rmse: 2.2911\tvalid_1's rmse: 1.84722\n",
      "[1200]\ttraining's rmse: 2.28602\tvalid_1's rmse: 1.84757\n",
      "Early stopping, best iteration is:\n",
      "[1164]\ttraining's rmse: 2.28839\tvalid_1's rmse: 1.84703\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.847   \u001b[0m | \u001b[0m 0.4653  \u001b[0m | \u001b[0m 11.48   \u001b[0m | \u001b[0m 0.2172  \u001b[0m | \u001b[0m 285.2   \u001b[0m | \u001b[0m 8.183   \u001b[0m | \u001b[0m 5.995e+0\u001b[0m | \u001b[0m 0.6436  \u001b[0m | \u001b[0m 1.008e+0\u001b[0m | \u001b[0m 0.9231  \u001b[0m | \u001b[0m 0.3722  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.57322\tvalid_1's rmse: 2.02381\n",
      "[200]\ttraining's rmse: 2.44555\tvalid_1's rmse: 1.92972\n",
      "[300]\ttraining's rmse: 2.41087\tvalid_1's rmse: 1.90912\n",
      "[400]\ttraining's rmse: 2.39131\tvalid_1's rmse: 1.89656\n",
      "[500]\ttraining's rmse: 2.37641\tvalid_1's rmse: 1.89067\n",
      "[600]\ttraining's rmse: 2.36156\tvalid_1's rmse: 1.87842\n",
      "[700]\ttraining's rmse: 2.35304\tvalid_1's rmse: 1.87476\n",
      "[800]\ttraining's rmse: 2.3439\tvalid_1's rmse: 1.87033\n",
      "[900]\ttraining's rmse: 2.3391\tvalid_1's rmse: 1.86677\n",
      "[1000]\ttraining's rmse: 2.33511\tvalid_1's rmse: 1.86698\n",
      "[1100]\ttraining's rmse: 2.33098\tvalid_1's rmse: 1.86574\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttraining's rmse: 2.33289\tvalid_1's rmse: 1.86496\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.865   \u001b[0m | \u001b[0m 0.1281  \u001b[0m | \u001b[0m 19.21   \u001b[0m | \u001b[0m 0.3251  \u001b[0m | \u001b[0m 102.7   \u001b[0m | \u001b[0m 8.268   \u001b[0m | \u001b[0m 3.13e+03\u001b[0m | \u001b[0m 0.4451  \u001b[0m | \u001b[0m 1.003e+0\u001b[0m | \u001b[0m 0.1937  \u001b[0m | \u001b[0m 0.1833  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.49152\tvalid_1's rmse: 1.95478\n",
      "[200]\ttraining's rmse: 2.38972\tvalid_1's rmse: 1.89783\n",
      "[300]\ttraining's rmse: 2.36613\tvalid_1's rmse: 1.8917\n",
      "[400]\ttraining's rmse: 2.35386\tvalid_1's rmse: 1.88722\n",
      "[500]\ttraining's rmse: 2.34558\tvalid_1's rmse: 1.88476\n",
      "[600]\ttraining's rmse: 2.33945\tvalid_1's rmse: 1.88181\n",
      "[700]\ttraining's rmse: 2.334\tvalid_1's rmse: 1.87906\n",
      "[800]\ttraining's rmse: 2.32883\tvalid_1's rmse: 1.87712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's rmse: 2.32427\tvalid_1's rmse: 1.87496\n",
      "[1000]\ttraining's rmse: 2.32184\tvalid_1's rmse: 1.87402\n",
      "[1100]\ttraining's rmse: 2.31824\tvalid_1's rmse: 1.87278\n",
      "[1200]\ttraining's rmse: 2.31407\tvalid_1's rmse: 1.86967\n",
      "[1300]\ttraining's rmse: 2.31097\tvalid_1's rmse: 1.86868\n",
      "[1400]\ttraining's rmse: 2.30784\tvalid_1's rmse: 1.86681\n",
      "[1500]\ttraining's rmse: 2.30559\tvalid_1's rmse: 1.86575\n",
      "[1600]\ttraining's rmse: 2.30249\tvalid_1's rmse: 1.86499\n",
      "[1700]\ttraining's rmse: 2.2996\tvalid_1's rmse: 1.86382\n",
      "[1800]\ttraining's rmse: 2.29684\tvalid_1's rmse: 1.86185\n",
      "[1900]\ttraining's rmse: 2.29409\tvalid_1's rmse: 1.86059\n",
      "[2000]\ttraining's rmse: 2.2916\tvalid_1's rmse: 1.85946\n",
      "[2100]\ttraining's rmse: 2.28979\tvalid_1's rmse: 1.85932\n",
      "[2200]\ttraining's rmse: 2.28718\tvalid_1's rmse: 1.85784\n",
      "[2300]\ttraining's rmse: 2.28537\tvalid_1's rmse: 1.85704\n",
      "[2400]\ttraining's rmse: 2.28298\tvalid_1's rmse: 1.85593\n",
      "[2500]\ttraining's rmse: 2.2808\tvalid_1's rmse: 1.85484\n",
      "[2600]\ttraining's rmse: 2.27848\tvalid_1's rmse: 1.85424\n",
      "[2700]\ttraining's rmse: 2.27621\tvalid_1's rmse: 1.85298\n",
      "Early stopping, best iteration is:\n",
      "[2693]\ttraining's rmse: 2.27642\tvalid_1's rmse: 1.85281\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.853   \u001b[0m | \u001b[0m 0.7283  \u001b[0m | \u001b[0m 8.62    \u001b[0m | \u001b[0m 0.5107  \u001b[0m | \u001b[0m 299.2   \u001b[0m | \u001b[0m 4.738   \u001b[0m | \u001b[0m 5.962e+0\u001b[0m | \u001b[0m 0.5367  \u001b[0m | \u001b[0m 2.978e+0\u001b[0m | \u001b[0m 0.1028  \u001b[0m | \u001b[0m 0.225   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.62543\tvalid_1's rmse: 2.05977\n",
      "[200]\ttraining's rmse: 2.4781\tvalid_1's rmse: 1.94371\n",
      "[300]\ttraining's rmse: 2.44427\tvalid_1's rmse: 1.93116\n",
      "[400]\ttraining's rmse: 2.43286\tvalid_1's rmse: 1.92851\n",
      "[500]\ttraining's rmse: 2.42268\tvalid_1's rmse: 1.92587\n",
      "[600]\ttraining's rmse: 2.41741\tvalid_1's rmse: 1.92108\n",
      "[700]\ttraining's rmse: 2.41346\tvalid_1's rmse: 1.91843\n",
      "[800]\ttraining's rmse: 2.40951\tvalid_1's rmse: 1.9159\n",
      "[900]\ttraining's rmse: 2.40786\tvalid_1's rmse: 1.91517\n",
      "[1000]\ttraining's rmse: 2.4057\tvalid_1's rmse: 1.91417\n",
      "[1100]\ttraining's rmse: 2.40397\tvalid_1's rmse: 1.91287\n",
      "[1200]\ttraining's rmse: 2.40068\tvalid_1's rmse: 1.91129\n",
      "[1300]\ttraining's rmse: 2.39887\tvalid_1's rmse: 1.91095\n",
      "[1400]\ttraining's rmse: 2.39714\tvalid_1's rmse: 1.90891\n",
      "[1500]\ttraining's rmse: 2.39514\tvalid_1's rmse: 1.90891\n",
      "[1600]\ttraining's rmse: 2.39265\tvalid_1's rmse: 1.90747\n",
      "[1700]\ttraining's rmse: 2.39017\tvalid_1's rmse: 1.90643\n",
      "[1800]\ttraining's rmse: 2.38747\tvalid_1's rmse: 1.90551\n",
      "[1900]\ttraining's rmse: 2.38463\tvalid_1's rmse: 1.90472\n",
      "[2000]\ttraining's rmse: 2.38332\tvalid_1's rmse: 1.90343\n",
      "[2100]\ttraining's rmse: 2.38261\tvalid_1's rmse: 1.90313\n",
      "Early stopping, best iteration is:\n",
      "[2063]\ttraining's rmse: 2.38293\tvalid_1's rmse: 1.90299\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.903   \u001b[0m | \u001b[0m 0.1682  \u001b[0m | \u001b[0m 12.02   \u001b[0m | \u001b[0m 0.7725  \u001b[0m | \u001b[0m 299.9   \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 4.875e+0\u001b[0m | \u001b[0m 0.3395  \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.2321  \u001b[0m | \u001b[0m 0.2882  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.05416\tvalid_1's rmse: 2.4507\n",
      "[200]\ttraining's rmse: 2.73216\tvalid_1's rmse: 2.16855\n",
      "[300]\ttraining's rmse: 2.5921\tvalid_1's rmse: 2.03824\n",
      "[400]\ttraining's rmse: 2.53219\tvalid_1's rmse: 1.97859\n",
      "[500]\ttraining's rmse: 2.49599\tvalid_1's rmse: 1.95\n",
      "[600]\ttraining's rmse: 2.47717\tvalid_1's rmse: 1.93964\n",
      "[700]\ttraining's rmse: 2.46346\tvalid_1's rmse: 1.93236\n",
      "[800]\ttraining's rmse: 2.45379\tvalid_1's rmse: 1.92931\n",
      "[900]\ttraining's rmse: 2.44908\tvalid_1's rmse: 1.92724\n",
      "[1000]\ttraining's rmse: 2.44287\tvalid_1's rmse: 1.92575\n",
      "[1100]\ttraining's rmse: 2.43899\tvalid_1's rmse: 1.92475\n",
      "[1200]\ttraining's rmse: 2.43576\tvalid_1's rmse: 1.92375\n",
      "[1300]\ttraining's rmse: 2.43123\tvalid_1's rmse: 1.92266\n",
      "[1400]\ttraining's rmse: 2.42779\tvalid_1's rmse: 1.92216\n",
      "[1500]\ttraining's rmse: 2.42583\tvalid_1's rmse: 1.92193\n",
      "[1600]\ttraining's rmse: 2.42424\tvalid_1's rmse: 1.92166\n",
      "[1700]\ttraining's rmse: 2.42304\tvalid_1's rmse: 1.92118\n",
      "[1800]\ttraining's rmse: 2.42183\tvalid_1's rmse: 1.92042\n",
      "[1900]\ttraining's rmse: 2.42062\tvalid_1's rmse: 1.92012\n",
      "Early stopping, best iteration is:\n",
      "[1884]\ttraining's rmse: 2.42093\tvalid_1's rmse: 1.92004\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.92    \u001b[0m | \u001b[0m 0.4109  \u001b[0m | \u001b[0m 7.374   \u001b[0m | \u001b[0m 0.5592  \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 1.736   \u001b[0m | \u001b[0m 4.471e+0\u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 3e+03   \u001b[0m | \u001b[0m 0.8499  \u001b[0m | \u001b[0m 0.4421  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 2.58302\tvalid_1's rmse: 2.04054\n",
      "[200]\ttraining's rmse: 2.44559\tvalid_1's rmse: 1.93319\n",
      "[300]\ttraining's rmse: 2.41079\tvalid_1's rmse: 1.90831\n",
      "[400]\ttraining's rmse: 2.39353\tvalid_1's rmse: 1.89722\n",
      "[500]\ttraining's rmse: 2.37812\tvalid_1's rmse: 1.88295\n",
      "[600]\ttraining's rmse: 2.36729\tvalid_1's rmse: 1.87551\n",
      "[700]\ttraining's rmse: 2.36028\tvalid_1's rmse: 1.87071\n",
      "[800]\ttraining's rmse: 2.3501\tvalid_1's rmse: 1.86469\n",
      "[900]\ttraining's rmse: 2.34481\tvalid_1's rmse: 1.86167\n",
      "[1000]\ttraining's rmse: 2.34063\tvalid_1's rmse: 1.85963\n",
      "[1100]\ttraining's rmse: 2.3369\tvalid_1's rmse: 1.85947\n",
      "[1200]\ttraining's rmse: 2.33302\tvalid_1's rmse: 1.85799\n",
      "[1300]\ttraining's rmse: 2.32961\tvalid_1's rmse: 1.85634\n",
      "[1400]\ttraining's rmse: 2.32632\tvalid_1's rmse: 1.85512\n",
      "[1500]\ttraining's rmse: 2.32277\tvalid_1's rmse: 1.85545\n",
      "Early stopping, best iteration is:\n",
      "[1406]\ttraining's rmse: 2.32591\tvalid_1's rmse: 1.85462\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.855   \u001b[0m | \u001b[0m 0.2127  \u001b[0m | \u001b[0m 17.7    \u001b[0m | \u001b[0m 0.3981  \u001b[0m | \u001b[0m 296.4   \u001b[0m | \u001b[0m 8.479   \u001b[0m | \u001b[0m 5.996e+0\u001b[0m | \u001b[0m 0.4818  \u001b[0m | \u001b[0m 1.951e+0\u001b[0m | \u001b[0m 0.2661  \u001b[0m | \u001b[0m 0.517   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.17335\tvalid_1's rmse: 2.50585\n",
      "[200]\ttraining's rmse: 2.85544\tvalid_1's rmse: 2.20985\n",
      "[300]\ttraining's rmse: 2.73615\tvalid_1's rmse: 2.09312\n",
      "[400]\ttraining's rmse: 2.67939\tvalid_1's rmse: 2.04185\n",
      "[500]\ttraining's rmse: 2.64905\tvalid_1's rmse: 2.02442\n",
      "[600]\ttraining's rmse: 2.6282\tvalid_1's rmse: 2.01478\n",
      "[700]\ttraining's rmse: 2.61274\tvalid_1's rmse: 2.00636\n",
      "[800]\ttraining's rmse: 2.60071\tvalid_1's rmse: 1.99965\n",
      "[900]\ttraining's rmse: 2.59109\tvalid_1's rmse: 1.99219\n",
      "[1000]\ttraining's rmse: 2.58189\tvalid_1's rmse: 1.98711\n",
      "[1100]\ttraining's rmse: 2.57374\tvalid_1's rmse: 1.98258\n",
      "[1200]\ttraining's rmse: 2.56734\tvalid_1's rmse: 1.9786\n",
      "[1300]\ttraining's rmse: 2.56125\tvalid_1's rmse: 1.97515\n",
      "[1400]\ttraining's rmse: 2.5557\tvalid_1's rmse: 1.97197\n",
      "[1500]\ttraining's rmse: 2.54851\tvalid_1's rmse: 1.96873\n",
      "[1600]\ttraining's rmse: 2.5423\tvalid_1's rmse: 1.96589\n",
      "[1700]\ttraining's rmse: 2.53651\tvalid_1's rmse: 1.9623\n",
      "[1800]\ttraining's rmse: 2.53062\tvalid_1's rmse: 1.96009\n",
      "[1900]\ttraining's rmse: 2.52651\tvalid_1's rmse: 1.9585\n",
      "[2000]\ttraining's rmse: 2.5224\tvalid_1's rmse: 1.9566\n",
      "[2100]\ttraining's rmse: 2.51814\tvalid_1's rmse: 1.95537\n",
      "[2200]\ttraining's rmse: 2.51404\tvalid_1's rmse: 1.9538\n",
      "[2300]\ttraining's rmse: 2.50905\tvalid_1's rmse: 1.95184\n",
      "[2400]\ttraining's rmse: 2.50636\tvalid_1's rmse: 1.95072\n",
      "[2500]\ttraining's rmse: 2.50276\tvalid_1's rmse: 1.94949\n",
      "[2600]\ttraining's rmse: 2.49847\tvalid_1's rmse: 1.94804\n",
      "[2700]\ttraining's rmse: 2.49428\tvalid_1's rmse: 1.94745\n",
      "[2800]\ttraining's rmse: 2.49186\tvalid_1's rmse: 1.94658\n",
      "[2900]\ttraining's rmse: 2.48871\tvalid_1's rmse: 1.94527\n",
      "[3000]\ttraining's rmse: 2.48489\tvalid_1's rmse: 1.94385\n",
      "[3100]\ttraining's rmse: 2.48143\tvalid_1's rmse: 1.94285\n",
      "[3200]\ttraining's rmse: 2.4793\tvalid_1's rmse: 1.94184\n",
      "[3300]\ttraining's rmse: 2.47732\tvalid_1's rmse: 1.94102\n",
      "[3400]\ttraining's rmse: 2.47445\tvalid_1's rmse: 1.94049\n",
      "[3500]\ttraining's rmse: 2.47162\tvalid_1's rmse: 1.93939\n",
      "[3600]\ttraining's rmse: 2.4688\tvalid_1's rmse: 1.93894\n",
      "[3700]\ttraining's rmse: 2.46683\tvalid_1's rmse: 1.93836\n",
      "[3800]\ttraining's rmse: 2.46399\tvalid_1's rmse: 1.93722\n",
      "[3900]\ttraining's rmse: 2.46143\tvalid_1's rmse: 1.93657\n",
      "[4000]\ttraining's rmse: 2.45899\tvalid_1's rmse: 1.93549\n",
      "[4100]\ttraining's rmse: 2.45651\tvalid_1's rmse: 1.93501\n",
      "[4200]\ttraining's rmse: 2.4549\tvalid_1's rmse: 1.93437\n",
      "[4300]\ttraining's rmse: 2.4524\tvalid_1's rmse: 1.9333\n",
      "[4400]\ttraining's rmse: 2.45072\tvalid_1's rmse: 1.93273\n",
      "[4500]\ttraining's rmse: 2.44846\tvalid_1's rmse: 1.93198\n",
      "[4600]\ttraining's rmse: 2.44693\tvalid_1's rmse: 1.93108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4700]\ttraining's rmse: 2.44476\tvalid_1's rmse: 1.93033\n",
      "[4800]\ttraining's rmse: 2.4428\tvalid_1's rmse: 1.92965\n",
      "[4900]\ttraining's rmse: 2.44143\tvalid_1's rmse: 1.92916\n",
      "[5000]\ttraining's rmse: 2.44012\tvalid_1's rmse: 1.92866\n",
      "[5100]\ttraining's rmse: 2.43852\tvalid_1's rmse: 1.92845\n",
      "[5200]\ttraining's rmse: 2.43744\tvalid_1's rmse: 1.92795\n",
      "[5300]\ttraining's rmse: 2.43602\tvalid_1's rmse: 1.92773\n",
      "[5400]\ttraining's rmse: 2.43487\tvalid_1's rmse: 1.92735\n",
      "[5500]\ttraining's rmse: 2.43374\tvalid_1's rmse: 1.9271\n",
      "[5600]\ttraining's rmse: 2.43217\tvalid_1's rmse: 1.92704\n",
      "[5700]\ttraining's rmse: 2.43111\tvalid_1's rmse: 1.92617\n",
      "[5800]\ttraining's rmse: 2.4298\tvalid_1's rmse: 1.9263\n",
      "Early stopping, best iteration is:\n",
      "[5720]\ttraining's rmse: 2.43097\tvalid_1's rmse: 1.92606\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.926   \u001b[0m | \u001b[0m 0.6814  \u001b[0m | \u001b[0m 5.737   \u001b[0m | \u001b[0m 0.1786  \u001b[0m | \u001b[0m 105.6   \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 5.993e+0\u001b[0m | \u001b[0m 0.393   \u001b[0m | \u001b[0m 2.892e+0\u001b[0m | \u001b[0m 0.4791  \u001b[0m | \u001b[0m 0.4711  \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "init_points = 3\n",
    "n_iter = 7\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|  2        | -1.845    |  0.83     |  5.833    |  0.6944   |  270.7    |  7.194    |  4.013e+0 |  0.6251   |  1.352e+0 |  0.6124   |  0.83     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data, valid_data, X_valid, y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample':  0.83 ,\n",
    "                    'subsample_freq': 5,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 1352, \n",
    "                    'min_data_in_leaf': 4013, \n",
    "                    'feature_fraction': 0.6944,\n",
    "                    'max_bin': 270,\n",
    "                    'n_estimators': 2200,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                    'max_depth':7,\n",
    "                    'min_split_gain': 0.6251,\n",
    "                    'reg_alpha': 0.6124,\n",
    "                    'reg_lambda':  0.83,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.91709\n",
      "[200]\tvalid_0's rmse: 1.87335\n",
      "[300]\tvalid_0's rmse: 1.86237\n",
      "[400]\tvalid_0's rmse: 1.85703\n",
      "[500]\tvalid_0's rmse: 1.85066\n",
      "[600]\tvalid_0's rmse: 1.84598\n",
      "[700]\tvalid_0's rmse: 1.84332\n",
      "[800]\tvalid_0's rmse: 1.83943\n",
      "[900]\tvalid_0's rmse: 1.83649\n",
      "[1000]\tvalid_0's rmse: 1.835\n",
      "[1100]\tvalid_0's rmse: 1.83275\n",
      "[1200]\tvalid_0's rmse: 1.83058\n",
      "[1300]\tvalid_0's rmse: 1.828\n",
      "[1400]\tvalid_0's rmse: 1.82607\n",
      "[1500]\tvalid_0's rmse: 1.82547\n",
      "[1600]\tvalid_0's rmse: 1.82288\n",
      "[1700]\tvalid_0's rmse: 1.8216\n",
      "[1800]\tvalid_0's rmse: 1.81999\n",
      "[1900]\tvalid_0's rmse: 1.81763\n",
      "[2000]\tvalid_0's rmse: 1.81648\n",
      "[2100]\tvalid_0's rmse: 1.81538\n",
      "[2200]\tvalid_0's rmse: 1.81451\n"
     ]
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store('WI_3')\n",
    "store_id = 'WI_3'\n",
    "train_mask = grid_df['d']<=END_TRAIN\n",
    "valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "train_data = lgb.Dataset(grid_df[train_mask][features_columns], label=grid_df[train_mask][TARGET])\n",
    "train_data.save_binary('train_data.bin')\n",
    "train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "seed_everything(SEED)\n",
    "estimator = lgb.train(lgb_params,train_data,valid_sets = [valid_data],verbose_eval = 100,)\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "!rm train_data.bin\n",
    "del train_data, valid_data, estimator\n",
    "gc.collect()\n",
    "# \"Keep\" models features for predictions\n",
    "MODEL_FEATURES = features_columns\n",
    "#1.76026\n",
    "#100:1.92146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  0.65 min round |  0.65 min total |  37004.71 day sales |\n",
      "Predict | Day: 2\n",
      "##########  0.67 min round |  1.32 min total |  35473.49 day sales |\n",
      "Predict | Day: 3\n",
      "##########  0.64 min round |  1.96 min total |  34997.51 day sales |\n",
      "Predict | Day: 4\n",
      "##########  0.69 min round |  2.65 min total |  35528.85 day sales |\n",
      "Predict | Day: 5\n",
      "##########  0.64 min round |  3.29 min total |  41545.06 day sales |\n",
      "Predict | Day: 6\n",
      "##########  0.65 min round |  3.94 min total |  50514.43 day sales |\n",
      "Predict | Day: 7\n",
      "##########  0.68 min round |  4.62 min total |  53595.14 day sales |\n",
      "Predict | Day: 8\n",
      "##########  0.66 min round |  5.27 min total |  44255.78 day sales |\n",
      "Predict | Day: 9\n",
      "##########  0.65 min round |  5.92 min total |  44148.37 day sales |\n",
      "Predict | Day: 10\n",
      "##########  0.67 min round |  6.59 min total |  39039.16 day sales |\n",
      "Predict | Day: 11\n",
      "##########  0.67 min round |  7.25 min total |  40913.01 day sales |\n",
      "Predict | Day: 12\n",
      "##########  0.66 min round |  7.91 min total |  46259.46 day sales |\n",
      "Predict | Day: 13\n",
      "##########  0.67 min round |  8.59 min total |  54362.28 day sales |\n",
      "Predict | Day: 14\n",
      "##########  0.65 min round |  9.23 min total |  46688.14 day sales |\n",
      "Predict | Day: 15\n",
      "##########  0.64 min round |  9.88 min total |  44317.57 day sales |\n",
      "Predict | Day: 16\n",
      "##########  0.67 min round |  10.54 min total |  39023.37 day sales |\n",
      "Predict | Day: 17\n",
      "##########  0.65 min round |  11.19 min total |  40444.65 day sales |\n",
      "Predict | Day: 18\n",
      "##########  0.65 min round |  11.84 min total |  40794.90 day sales |\n",
      "Predict | Day: 19\n",
      "##########  0.65 min round |  12.49 min total |  43924.90 day sales |\n",
      "Predict | Day: 20\n",
      "##########  0.68 min round |  13.17 min total |  53979.98 day sales |\n",
      "Predict | Day: 21\n",
      "##########  0.66 min round |  13.83 min total |  55471.25 day sales |\n",
      "Predict | Day: 22\n",
      "##########  0.65 min round |  14.47 min total |  40956.35 day sales |\n",
      "Predict | Day: 23\n",
      "##########  0.66 min round |  15.13 min total |  37588.35 day sales |\n",
      "Predict | Day: 24\n",
      "##########  0.67 min round |  15.80 min total |  36945.32 day sales |\n",
      "Predict | Day: 25\n",
      "##########  0.67 min round |  16.47 min total |  36917.45 day sales |\n",
      "Predict | Day: 26\n",
      "##########  0.64 min round |  17.11 min total |  41723.81 day sales |\n",
      "Predict | Day: 27\n",
      "##########  0.67 min round |  17.78 min total |  50832.42 day sales |\n",
      "Predict | Day: 28\n",
      "##########  0.67 min round |  18.44 min total |  51045.09 day sales |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.351560</td>\n",
       "      <td>0.318356</td>\n",
       "      <td>0.335796</td>\n",
       "      <td>0.337141</td>\n",
       "      <td>0.370245</td>\n",
       "      <td>0.438981</td>\n",
       "      <td>0.433703</td>\n",
       "      <td>0.477256</td>\n",
       "      <td>0.474865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484331</td>\n",
       "      <td>0.620101</td>\n",
       "      <td>0.629389</td>\n",
       "      <td>0.454026</td>\n",
       "      <td>0.385747</td>\n",
       "      <td>0.389512</td>\n",
       "      <td>0.370834</td>\n",
       "      <td>0.435877</td>\n",
       "      <td>0.501518</td>\n",
       "      <td>0.493276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.265074</td>\n",
       "      <td>0.249082</td>\n",
       "      <td>0.257646</td>\n",
       "      <td>0.260829</td>\n",
       "      <td>0.304125</td>\n",
       "      <td>0.285260</td>\n",
       "      <td>0.298563</td>\n",
       "      <td>0.303073</td>\n",
       "      <td>0.301354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274593</td>\n",
       "      <td>0.320768</td>\n",
       "      <td>0.358263</td>\n",
       "      <td>0.273464</td>\n",
       "      <td>0.230210</td>\n",
       "      <td>0.220420</td>\n",
       "      <td>0.216433</td>\n",
       "      <td>0.244752</td>\n",
       "      <td>0.284998</td>\n",
       "      <td>0.285220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.710566</td>\n",
       "      <td>0.664698</td>\n",
       "      <td>0.632484</td>\n",
       "      <td>0.630833</td>\n",
       "      <td>0.792454</td>\n",
       "      <td>0.874996</td>\n",
       "      <td>1.002033</td>\n",
       "      <td>1.147045</td>\n",
       "      <td>1.115036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910525</td>\n",
       "      <td>1.317883</td>\n",
       "      <td>1.371702</td>\n",
       "      <td>0.939114</td>\n",
       "      <td>0.696098</td>\n",
       "      <td>0.662452</td>\n",
       "      <td>0.629567</td>\n",
       "      <td>0.732431</td>\n",
       "      <td>0.890117</td>\n",
       "      <td>0.903989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.846910</td>\n",
       "      <td>0.805053</td>\n",
       "      <td>0.761669</td>\n",
       "      <td>0.753137</td>\n",
       "      <td>0.888614</td>\n",
       "      <td>1.053512</td>\n",
       "      <td>1.120932</td>\n",
       "      <td>1.072092</td>\n",
       "      <td>1.083138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038968</td>\n",
       "      <td>1.371697</td>\n",
       "      <td>1.366273</td>\n",
       "      <td>0.938775</td>\n",
       "      <td>0.804774</td>\n",
       "      <td>0.770337</td>\n",
       "      <td>0.775346</td>\n",
       "      <td>0.959985</td>\n",
       "      <td>1.064001</td>\n",
       "      <td>1.061433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.149663</td>\n",
       "      <td>0.773651</td>\n",
       "      <td>0.892180</td>\n",
       "      <td>1.143053</td>\n",
       "      <td>1.422115</td>\n",
       "      <td>1.882513</td>\n",
       "      <td>1.766871</td>\n",
       "      <td>1.675501</td>\n",
       "      <td>2.004725</td>\n",
       "      <td>...</td>\n",
       "      <td>1.469069</td>\n",
       "      <td>1.929914</td>\n",
       "      <td>1.881762</td>\n",
       "      <td>1.362755</td>\n",
       "      <td>1.210466</td>\n",
       "      <td>1.171472</td>\n",
       "      <td>1.135632</td>\n",
       "      <td>1.299249</td>\n",
       "      <td>1.714112</td>\n",
       "      <td>1.672511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id        F1        F2        F3        F4  \\\n",
       "30485  FOODS_3_823_WI_3_validation  0.351560  0.318356  0.335796  0.337141   \n",
       "30486  FOODS_3_824_WI_3_validation  0.265074  0.249082  0.257646  0.260829   \n",
       "30487  FOODS_3_825_WI_3_validation  0.710566  0.664698  0.632484  0.630833   \n",
       "30488  FOODS_3_826_WI_3_validation  0.846910  0.805053  0.761669  0.753137   \n",
       "30489  FOODS_3_827_WI_3_validation  0.149663  0.773651  0.892180  1.143053   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "30485  0.370245  0.438981  0.433703  0.477256  0.474865  ...  0.484331   \n",
       "30486  0.304125  0.285260  0.298563  0.303073  0.301354  ...  0.274593   \n",
       "30487  0.792454  0.874996  1.002033  1.147045  1.115036  ...  0.910525   \n",
       "30488  0.888614  1.053512  1.120932  1.072092  1.083138  ...  1.038968   \n",
       "30489  1.422115  1.882513  1.766871  1.675501  2.004725  ...  1.469069   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "30485  0.620101  0.629389  0.454026  0.385747  0.389512  0.370834  0.435877   \n",
       "30486  0.320768  0.358263  0.273464  0.230210  0.220420  0.216433  0.244752   \n",
       "30487  1.317883  1.371702  0.939114  0.696098  0.662452  0.629567  0.732431   \n",
       "30488  1.371697  1.366273  0.938775  0.804774  0.770337  0.775346  0.959985   \n",
       "30489  1.929914  1.881762  1.362755  1.210466  1.171472  1.135632  1.299249   \n",
       "\n",
       "            F27       F28  \n",
       "30485  0.501518  0.493276  \n",
       "30486  0.284998  0.285220  \n",
       "30487  0.890117  0.903989  \n",
       "30488  1.064001  1.061433  \n",
       "30489  1.714112  1.672511  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dummy DataFrame to store predictions\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# Join back the Test dataset with \n",
    "# a small part of the training data \n",
    "# to make recursive features\n",
    "base_test = get_base_test()\n",
    "\n",
    "# Timer to measure predictions time \n",
    "main_time = time.time()\n",
    "\n",
    "# Loop over each prediction day\n",
    "# As rolling lags are the most timeconsuming\n",
    "# we will calculate it for whole day\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make temporary grid to calculate rolling lags\n",
    "    grid_df = base_test.copy()\n",
    "    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "        \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # Read all our models and make predictions\n",
    "        # for each day/store pairs\n",
    "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
    "        \n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask)&(store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # Make good column naming and add \n",
    "    # to all_preds DataFrame\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "all_preds.head()\n",
    "all_preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading competition sample submission and\n",
    "# merging our predictions\n",
    "# As we have predictions only for \"_validation\" data\n",
    "# we need to do fillna() for \"_evaluation\" items\n",
    "submission = pd.read_csv('sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv('submission_v2.csv', index=False)#0.49187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
